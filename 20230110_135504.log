2023-01-10 13:55:04,589 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.5 (default, Sep  4 2020, 07:30:14) [GCC 7.3.0]
CUDA available: True
GPU 0: NVIDIA GeForce RTX 3090
CUDA_HOME: None
GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0
PyTorch: 1.7.1+cu110
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.8.2+cu110
OpenCV: 4.4.0
MMCV: 1.3.7
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.0
MMSegmentation: 0.16.0+unknown
------------------------------------------------------------

2023-01-10 13:55:04,589 - mmseg - INFO - Distributed training: False
2023-01-10 13:55:05,176 - mmseg - INFO - Config:
log_config = dict(
    interval=50,
    img_interval=1000,
    hooks=[dict(type='TextLoggerHook', by_epoch=False)])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
cudnn_benchmark = True
norm_cfg = dict(type='BN', requires_grad=True)
find_unused_parameters = True
model = dict(
    type='EncoderDecoder',
    pretrained='pretrained/mit_b5.pth',
    backbone=dict(type='mit_b5', style='pytorch'),
    decode_head=dict(
        type='DAFormerHead',
        in_channels=[64, 128, 320, 512],
        in_index=[0, 1, 2, 3],
        channels=256,
        dropout_ratio=0.1,
        num_classes=19,
        norm_cfg=dict(type='BN', requires_grad=True),
        align_corners=False,
        decoder_params=dict(
            embed_dims=256,
            embed_cfg=dict(type='mlp', act_cfg=None, norm_cfg=None),
            embed_neck_cfg=dict(type='mlp', act_cfg=None, norm_cfg=None),
            fusion_cfg=dict(
                type='aspp',
                sep=True,
                dilations=(1, 6, 12, 18),
                pool=False,
                act_cfg=dict(type='ReLU'),
                norm_cfg=dict(type='BN', requires_grad=True))),
        loss_decode=dict(
            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
    train_cfg=dict(
        work_dir=
        'work_dirs/local-81/230110_1355_230110_1343_gta2cs_dacs_a999_fdthings_rcs001_cpl_m32-07-spta_daformer_sepaspp_mitb5_poly10warm_s0_2feea_f2bea',
        log_config=dict(
            interval=50,
            img_interval=1000,
            hooks=[dict(type='TextLoggerHook', by_epoch=False)])),
    test_cfg=dict(mode='whole'))
dataset_type = 'CityscapesDataset'
data_root = '/home/lkg/data/cityscapes/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
crop_size = (512, 512)
gta_train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(type='Resize', img_scale=(1280, 720)),
    dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),
    dict(type='RandomFlip', prob=0.5),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg'])
]
cityscapes_train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(type='Resize', img_scale=(1024, 512)),
    dict(type='RandomCrop', crop_size=(512, 512)),
    dict(type='RandomFlip', prob=0.5),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_semantic_seg'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(1024, 512),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=2,
    workers_per_gpu=1,
    train=dict(
        type='UDADataset',
        source=dict(
            type='GTADataset',
            data_root='/home/lkg/data/GTA5/',
            img_dir='images',
            ann_dir='labels',
            pipeline=[
                dict(type='LoadImageFromFile'),
                dict(type='LoadAnnotations'),
                dict(type='Resize', img_scale=(1280, 720)),
                dict(
                    type='RandomCrop',
                    crop_size=(512, 512),
                    cat_max_ratio=0.75),
                dict(type='RandomFlip', prob=0.5),
                dict(
                    type='Normalize',
                    mean=[123.675, 116.28, 103.53],
                    std=[58.395, 57.12, 57.375],
                    to_rgb=True),
                dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
                dict(type='DefaultFormatBundle'),
                dict(type='Collect', keys=['img', 'gt_semantic_seg'])
            ]),
        target=dict(
            type='CityscapesDataset',
            data_root='/home/lkg/data/cityscapes/',
            img_dir='leftImg8bit/train',
            ann_dir='gtFine/train',
            pipeline=[
                dict(type='LoadImageFromFile'),
                dict(type='LoadAnnotations'),
                dict(type='Resize', img_scale=(1024, 512)),
                dict(type='RandomCrop', crop_size=(512, 512)),
                dict(type='RandomFlip', prob=0.5),
                dict(
                    type='Normalize',
                    mean=[123.675, 116.28, 103.53],
                    std=[58.395, 57.12, 57.375],
                    to_rgb=True),
                dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),
                dict(type='DefaultFormatBundle'),
                dict(type='Collect', keys=['img', 'gt_semantic_seg'])
            ]),
        rare_class_sampling=dict(
            min_pixels=3000, class_temp=0.01, min_crop_ratio=0.5)),
    val=dict(
        type='CityscapesDataset',
        data_root='/home/lkg/data/cityscapes/',
        img_dir='leftImg8bit/val',
        ann_dir='gtFine/val',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1024, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='CityscapesDataset',
        data_root='/home/lkg/data/cityscapes/',
        img_dir='leftImg8bit/val',
        ann_dir='gtFine/val',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1024, 512),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
uda = dict(
    type='DACS',
    source_only=False,
    alpha=0.999,
    pseudo_threshold=0.968,
    pseudo_weight_ignore_top=15,
    pseudo_weight_ignore_bottom=120,
    imnet_feature_dist_lambda=0.005,
    imnet_feature_dist_classes=[6, 7, 11, 12, 13, 14, 15, 16, 17, 18],
    imnet_feature_dist_scale_min_ratio=0.75,
    mix='class',
    blur=True,
    color_jitter_strength=0.2,
    color_jitter_probability=0.2,
    mask_mode='separatetrgaug',
    mask_alpha='same',
    mask_pseudo_threshold='same',
    mask_lambda=1,
    mask_generator=dict(type='block', mask_ratio=0.7, mask_block_size=32),
    debug_img_interval=1000,
    print_grad_magnitude=False)
use_ddp_wrapper = True
optimizer = dict(
    type='AdamW',
    lr=6e-05,
    betas=(0.9, 0.999),
    weight_decay=0.01,
    paramwise_cfg=dict(
        custom_keys=dict(
            head=dict(lr_mult=10.0),
            pos_block=dict(decay_mult=0.0),
            norm=dict(decay_mult=0.0))))
optimizer_config = None
lr_config = dict(
    policy='poly',
    warmup='linear',
    warmup_iters=1500,
    warmup_ratio=1e-06,
    power=1.0,
    min_lr=0.0,
    by_epoch=False)
gpu_model = 'NVIDIAGeForceRTX2080Ti'
n_gpus = 1
seed = 0
runner = dict(type='IterBasedRunner', max_iters=40000)
checkpoint_config = dict(by_epoch=False, interval=40000, max_keep_ckpts=1)
evaluation = dict(interval=4000, metric='mIoU')
name = '230110_1355_230110_1343_gta2cs_dacs_a999_fdthings_rcs001_cpl_m32-07-spta_daformer_sepaspp_mitb5_poly10warm_s0_2feea_f2bea'
exp = 81
name_dataset = 'gta2cityscapes'
name_architecture = 'daformer_sepaspp_mitb5'
name_encoder = 'mitb5'
name_decoder = 'daformer_sepaspp'
name_uda = 'dacs_a999_fdthings_rcs0.01_cpl_m32-0.7-spta'
name_opt = 'adamw_6e-05_pmTrue_poly10warm_1x2_40k'
work_dir = 'work_dirs/local-81/230110_1355_230110_1343_gta2cs_dacs_a999_fdthings_rcs001_cpl_m32-07-spta_daformer_sepaspp_mitb5_poly10warm_s0_2feea_f2bea'
git_rev = 'unknown'
gpu_ids = [0]

2023-01-10 13:55:05,177 - mmseg - INFO - Set random seed to 0, deterministic: None
2023-01-10 13:55:06,714 - mmseg - INFO - Load mit checkpoint.
2023-01-10 13:55:06,714 - mmseg - INFO - Use load_from_local loader
2023-01-10 13:55:06,975 - mmseg - INFO - Load mit checkpoint.
2023-01-10 13:55:06,976 - mmseg - INFO - Use load_from_local loader
2023-01-10 13:55:07,201 - mmseg - INFO - Load mit checkpoint.
2023-01-10 13:55:07,201 - mmseg - INFO - Use load_from_local loader
2023-01-10 13:55:07,426 - mmseg - INFO - DACS(
  (model): EncoderDecoder(
    (backbone): mit_b5(
      (patch_embed1): OverlapPatchEmbed(
        (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      )
      (patch_embed2): OverlapPatchEmbed(
        (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (patch_embed3): OverlapPatchEmbed(
        (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
      )
      (patch_embed4): OverlapPatchEmbed(
        (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (block1): ModuleList(
        (0): Block(
          (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=64, out_features=64, bias=True)
            (kv): Linear(in_features=64, out_features=128, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=64, out_features=64, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=64, out_features=256, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            )
            (act): GELU()
            (fc2): Linear(in_features=256, out_features=64, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=64, out_features=64, bias=True)
            (kv): Linear(in_features=64, out_features=128, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=64, out_features=64, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=64, out_features=256, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            )
            (act): GELU()
            (fc2): Linear(in_features=256, out_features=64, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): Block(
          (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=64, out_features=64, bias=True)
            (kv): Linear(in_features=64, out_features=128, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=64, out_features=64, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=64, out_features=256, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            )
            (act): GELU()
            (fc2): Linear(in_features=256, out_features=64, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (block2): ModuleList(
        (0): Block(
          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=128, out_features=128, bias=True)
            (kv): Linear(in_features=128, out_features=256, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            )
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=128, out_features=128, bias=True)
            (kv): Linear(in_features=128, out_features=256, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            )
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): Block(
          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=128, out_features=128, bias=True)
            (kv): Linear(in_features=128, out_features=256, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            )
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): Block(
          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=128, out_features=128, bias=True)
            (kv): Linear(in_features=128, out_features=256, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            )
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (4): Block(
          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=128, out_features=128, bias=True)
            (kv): Linear(in_features=128, out_features=256, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            )
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (5): Block(
          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=128, out_features=128, bias=True)
            (kv): Linear(in_features=128, out_features=256, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            )
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
      (block3): ModuleList(
        (0): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (4): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (5): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (6): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (7): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (8): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (9): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (10): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (11): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (12): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (13): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (14): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (15): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (16): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (17): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (18): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (19): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (20): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (21): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (22): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (23): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (24): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (25): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (26): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (27): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (28): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (29): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (30): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (31): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (32): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (33): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (34): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (35): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (36): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (37): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (38): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (39): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
      (block4): ModuleList(
        (0): Block(
          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=512, out_features=512, bias=True)
            (kv): Linear(in_features=512, out_features=1024, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
            )
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=512, out_features=512, bias=True)
            (kv): Linear(in_features=512, out_features=1024, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
            )
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): Block(
          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=512, out_features=512, bias=True)
            (kv): Linear(in_features=512, out_features=1024, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
            )
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    )
    (decode_head): DAFormerHead(
      input_transform=multiple_select, ignore_index=255, align_corners=False
      (loss_decode): CrossEntropyLoss()
      (conv_seg): Conv2d(256, 19, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (embed_layers): ModuleDict(
        (0): MLP(
          (proj): Linear(in_features=64, out_features=256, bias=True)
        )
        (1): MLP(
          (proj): Linear(in_features=128, out_features=256, bias=True)
        )
        (2): MLP(
          (proj): Linear(in_features=320, out_features=256, bias=True)
        )
        (3): MLP(
          (proj): Linear(in_features=512, out_features=256, bias=True)
        )
      )
      (fuse_layer): ASPPWrapper(
        (aspp_modules): DepthwiseSeparableASPPModule(
          (0): ConvModule(
            (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (activate): ReLU(inplace=True)
          )
          (1): DepthwiseSeparableConvModule(
            (depthwise_conv): ConvModule(
              (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=1024, bias=False)
              (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (pointwise_conv): ConvModule(
              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
          )
          (2): DepthwiseSeparableConvModule(
            (depthwise_conv): ConvModule(
              (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=1024, bias=False)
              (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (pointwise_conv): ConvModule(
              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
          )
          (3): DepthwiseSeparableConvModule(
            (depthwise_conv): ConvModule(
              (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=1024, bias=False)
              (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (pointwise_conv): ConvModule(
              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
          )
        )
        (bottleneck): ConvModule(
          (conv): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
  )
  (ema_model): EncoderDecoder(
    (backbone): mit_b5(
      (patch_embed1): OverlapPatchEmbed(
        (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      )
      (patch_embed2): OverlapPatchEmbed(
        (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (patch_embed3): OverlapPatchEmbed(
        (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
      )
      (patch_embed4): OverlapPatchEmbed(
        (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (block1): ModuleList(
        (0): Block(
          (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=64, out_features=64, bias=True)
            (kv): Linear(in_features=64, out_features=128, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=64, out_features=64, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=64, out_features=256, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            )
            (act): GELU()
            (fc2): Linear(in_features=256, out_features=64, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=64, out_features=64, bias=True)
            (kv): Linear(in_features=64, out_features=128, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=64, out_features=64, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=64, out_features=256, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            )
            (act): GELU()
            (fc2): Linear(in_features=256, out_features=64, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): Block(
          (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=64, out_features=64, bias=True)
            (kv): Linear(in_features=64, out_features=128, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=64, out_features=64, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=64, out_features=256, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            )
            (act): GELU()
            (fc2): Linear(in_features=256, out_features=64, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (block2): ModuleList(
        (0): Block(
          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=128, out_features=128, bias=True)
            (kv): Linear(in_features=128, out_features=256, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            )
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=128, out_features=128, bias=True)
            (kv): Linear(in_features=128, out_features=256, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            )
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): Block(
          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=128, out_features=128, bias=True)
            (kv): Linear(in_features=128, out_features=256, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            )
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): Block(
          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=128, out_features=128, bias=True)
            (kv): Linear(in_features=128, out_features=256, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            )
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (4): Block(
          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=128, out_features=128, bias=True)
            (kv): Linear(in_features=128, out_features=256, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            )
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (5): Block(
          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=128, out_features=128, bias=True)
            (kv): Linear(in_features=128, out_features=256, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            )
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
      (block3): ModuleList(
        (0): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (4): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (5): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (6): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (7): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (8): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (9): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (10): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (11): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (12): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (13): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (14): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (15): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (16): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (17): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (18): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (19): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (20): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (21): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (22): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (23): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (24): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (25): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (26): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (27): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (28): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (29): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (30): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (31): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (32): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (33): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (34): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (35): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (36): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (37): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (38): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (39): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
      (block4): ModuleList(
        (0): Block(
          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=512, out_features=512, bias=True)
            (kv): Linear(in_features=512, out_features=1024, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
            )
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=512, out_features=512, bias=True)
            (kv): Linear(in_features=512, out_features=1024, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
            )
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): Block(
          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=512, out_features=512, bias=True)
            (kv): Linear(in_features=512, out_features=1024, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
            )
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    )
    (decode_head): DAFormerHead(
      input_transform=multiple_select, ignore_index=255, align_corners=False
      (loss_decode): CrossEntropyLoss()
      (conv_seg): Conv2d(256, 19, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (embed_layers): ModuleDict(
        (0): MLP(
          (proj): Linear(in_features=64, out_features=256, bias=True)
        )
        (1): MLP(
          (proj): Linear(in_features=128, out_features=256, bias=True)
        )
        (2): MLP(
          (proj): Linear(in_features=320, out_features=256, bias=True)
        )
        (3): MLP(
          (proj): Linear(in_features=512, out_features=256, bias=True)
        )
      )
      (fuse_layer): ASPPWrapper(
        (aspp_modules): DepthwiseSeparableASPPModule(
          (0): ConvModule(
            (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (activate): ReLU(inplace=True)
          )
          (1): DepthwiseSeparableConvModule(
            (depthwise_conv): ConvModule(
              (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=1024, bias=False)
              (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (pointwise_conv): ConvModule(
              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
          )
          (2): DepthwiseSeparableConvModule(
            (depthwise_conv): ConvModule(
              (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=1024, bias=False)
              (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (pointwise_conv): ConvModule(
              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
          )
          (3): DepthwiseSeparableConvModule(
            (depthwise_conv): ConvModule(
              (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=1024, bias=False)
              (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (pointwise_conv): ConvModule(
              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
          )
        )
        (bottleneck): ConvModule(
          (conv): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
  )
  (mic): MaskingConsistencyModule()
  (imnet_model): EncoderDecoder(
    (backbone): mit_b5(
      (patch_embed1): OverlapPatchEmbed(
        (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      )
      (patch_embed2): OverlapPatchEmbed(
        (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (patch_embed3): OverlapPatchEmbed(
        (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
      )
      (patch_embed4): OverlapPatchEmbed(
        (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (block1): ModuleList(
        (0): Block(
          (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=64, out_features=64, bias=True)
            (kv): Linear(in_features=64, out_features=128, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=64, out_features=64, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=64, out_features=256, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            )
            (act): GELU()
            (fc2): Linear(in_features=256, out_features=64, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=64, out_features=64, bias=True)
            (kv): Linear(in_features=64, out_features=128, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=64, out_features=64, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=64, out_features=256, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            )
            (act): GELU()
            (fc2): Linear(in_features=256, out_features=64, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): Block(
          (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=64, out_features=64, bias=True)
            (kv): Linear(in_features=64, out_features=128, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=64, out_features=64, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=64, out_features=256, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
            )
            (act): GELU()
            (fc2): Linear(in_features=256, out_features=64, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
      (block2): ModuleList(
        (0): Block(
          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=128, out_features=128, bias=True)
            (kv): Linear(in_features=128, out_features=256, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            )
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=128, out_features=128, bias=True)
            (kv): Linear(in_features=128, out_features=256, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            )
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): Block(
          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=128, out_features=128, bias=True)
            (kv): Linear(in_features=128, out_features=256, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            )
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): Block(
          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=128, out_features=128, bias=True)
            (kv): Linear(in_features=128, out_features=256, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            )
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (4): Block(
          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=128, out_features=128, bias=True)
            (kv): Linear(in_features=128, out_features=256, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            )
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (5): Block(
          (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=128, out_features=128, bias=True)
            (kv): Linear(in_features=128, out_features=256, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=128, out_features=128, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=128, out_features=512, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
            )
            (act): GELU()
            (fc2): Linear(in_features=512, out_features=128, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
      (block3): ModuleList(
        (0): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (4): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (5): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (6): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (7): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (8): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (9): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (10): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (11): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (12): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (13): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (14): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (15): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (16): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (17): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (18): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (19): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (20): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (21): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (22): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (23): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (24): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (25): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (26): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (27): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (28): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (29): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (30): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (31): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (32): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (33): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (34): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (35): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (36): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (37): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (38): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (39): Block(
          (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=320, out_features=320, bias=True)
            (kv): Linear(in_features=320, out_features=640, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=320, out_features=320, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=320, out_features=1280, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
            )
            (act): GELU()
            (fc2): Linear(in_features=1280, out_features=320, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm3): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
      (block4): ModuleList(
        (0): Block(
          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=512, out_features=512, bias=True)
            (kv): Linear(in_features=512, out_features=1024, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
            )
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=512, out_features=512, bias=True)
            (kv): Linear(in_features=512, out_features=1024, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
            )
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): Block(
          (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (q): Linear(in_features=512, out_features=512, bias=True)
            (kv): Linear(in_features=512, out_features=1024, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=512, out_features=512, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=512, out_features=2048, bias=True)
            (dwconv): DWConv(
              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
            )
            (act): GELU()
            (fc2): Linear(in_features=2048, out_features=512, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm4): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
    )
    (decode_head): DAFormerHead(
      input_transform=multiple_select, ignore_index=255, align_corners=False
      (loss_decode): CrossEntropyLoss()
      (conv_seg): Conv2d(256, 19, kernel_size=(1, 1), stride=(1, 1))
      (dropout): Dropout2d(p=0.1, inplace=False)
      (embed_layers): ModuleDict(
        (0): MLP(
          (proj): Linear(in_features=64, out_features=256, bias=True)
        )
        (1): MLP(
          (proj): Linear(in_features=128, out_features=256, bias=True)
        )
        (2): MLP(
          (proj): Linear(in_features=320, out_features=256, bias=True)
        )
        (3): MLP(
          (proj): Linear(in_features=512, out_features=256, bias=True)
        )
      )
      (fuse_layer): ASPPWrapper(
        (aspp_modules): DepthwiseSeparableASPPModule(
          (0): ConvModule(
            (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (activate): ReLU(inplace=True)
          )
          (1): DepthwiseSeparableConvModule(
            (depthwise_conv): ConvModule(
              (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), groups=1024, bias=False)
              (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (pointwise_conv): ConvModule(
              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
          )
          (2): DepthwiseSeparableConvModule(
            (depthwise_conv): ConvModule(
              (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=1024, bias=False)
              (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (pointwise_conv): ConvModule(
              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
          )
          (3): DepthwiseSeparableConvModule(
            (depthwise_conv): ConvModule(
              (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), groups=1024, bias=False)
              (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (pointwise_conv): ConvModule(
              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
          )
        )
        (bottleneck): ConvModule(
          (conv): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
      )
    )
    init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}
  )
)
2023-01-10 13:55:07,702 - mmseg - INFO - Loaded 24966 images from /home/lkg/data/GTA5/images
2023-01-10 13:55:07,727 - mmseg - INFO - Loaded 2975 images from /home/lkg/data/cityscapes/leftImg8bit/train
2023-01-10 13:55:07,836 - mmseg - INFO - RCS Classes: [18, 12, 17, 16, 7, 6, 11, 15, 4, 5, 14, 3, 9, 13, 8, 1, 10, 2, 0]
2023-01-10 13:55:07,836 - mmseg - INFO - RCS ClassProb: [1.19714215e-01 1.16374984e-01 1.16249859e-01 1.11966260e-01
 1.09987602e-01 1.03559762e-01 8.00773054e-02 7.95736536e-02
 5.90534136e-02 3.65313925e-02 3.38807479e-02 1.50848152e-02
 1.07839219e-02 7.12811761e-03 2.32089515e-05 1.06939860e-05
 2.92120657e-08 6.51985521e-10 2.41905827e-17]
2023-01-10 13:55:17,894 - mmseg - INFO - Loaded 500 images from /home/lkg/data/cityscapes/leftImg8bit/val
2023-01-10 13:55:17,895 - mmseg - INFO - Start running, host: lkg@lkg, work_dir: /home/lkg/data/MIC-master/seg/work_dirs/local-81/230110_1355_230110_1343_gta2cs_dacs_a999_fdthings_rcs001_cpl_m32-07-spta_daformer_sepaspp_mitb5_poly10warm_s0_2feea_f2bea
2023-01-10 13:55:17,895 - mmseg - INFO - workflow: [('train', 1)], max: 40000 iters
2023-01-10 13:56:30,459 - mmseg - INFO - Iter [50/40000]	lr: 1.958e-06, eta: 15:03:44, time: 1.357, data_time: 0.025, memory: 9807, decode.loss_seg: 2.7188, decode.acc_seg: 9.9933, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 1.3465, mix.decode.acc_seg: 20.2989, masked.decode.loss_seg: 0.0000, masked.decode.acc_seg: 23.5256
2023-01-10 13:57:31,448 - mmseg - INFO - Iter [100/40000]	lr: 3.950e-06, eta: 14:16:52, time: 1.220, data_time: 0.010, memory: 9807, decode.loss_seg: 2.4364, decode.acc_seg: 52.1856, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 1.2726, mix.decode.acc_seg: 42.6001, masked.decode.loss_seg: 0.0000, masked.decode.acc_seg: 31.9685
2023-01-10 13:58:32,271 - mmseg - INFO - Iter [150/40000]	lr: 5.938e-06, eta: 13:59:51, time: 1.216, data_time: 0.010, memory: 9807, decode.loss_seg: 1.9718, decode.acc_seg: 63.5453, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.9825, mix.decode.acc_seg: 57.7856, masked.decode.loss_seg: 0.0000, masked.decode.acc_seg: 52.9355
2023-01-10 13:59:33,245 - mmseg - INFO - Iter [200/40000]	lr: 7.920e-06, eta: 13:51:19, time: 1.219, data_time: 0.010, memory: 9807, decode.loss_seg: 1.6284, decode.acc_seg: 69.3428, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.8418, mix.decode.acc_seg: 68.6319, masked.decode.loss_seg: 0.0000, masked.decode.acc_seg: 69.8634
2023-01-10 14:00:34,139 - mmseg - INFO - Iter [250/40000]	lr: 9.898e-06, eta: 13:45:35, time: 1.218, data_time: 0.010, memory: 9807, decode.loss_seg: 1.2820, decode.acc_seg: 69.1808, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.6662, mix.decode.acc_seg: 71.6504, masked.decode.loss_seg: 0.0000, masked.decode.acc_seg: 74.0234
2023-01-10 14:01:34,889 - mmseg - INFO - Iter [300/40000]	lr: 1.187e-05, eta: 13:41:07, time: 1.215, data_time: 0.010, memory: 9807, decode.loss_seg: 1.0624, decode.acc_seg: 70.2015, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.5471, mix.decode.acc_seg: 73.1634, masked.decode.loss_seg: 0.0000, masked.decode.acc_seg: 75.6927
2023-01-10 14:02:35,963 - mmseg - INFO - Iter [350/40000]	lr: 1.384e-05, eta: 13:38:14, time: 1.221, data_time: 0.010, memory: 9807, decode.loss_seg: 0.9540, decode.acc_seg: 70.8725, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.4586, mix.decode.acc_seg: 74.5662, masked.decode.loss_seg: 0.0000, masked.decode.acc_seg: 75.2871
2023-01-10 14:03:37,086 - mmseg - INFO - Iter [400/40000]	lr: 1.580e-05, eta: 13:35:54, time: 1.222, data_time: 0.010, memory: 9807, decode.loss_seg: 0.8351, decode.acc_seg: 71.3622, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.4212, mix.decode.acc_seg: 74.2513, masked.decode.loss_seg: 0.0000, masked.decode.acc_seg: 74.4674
2023-01-10 14:04:38,171 - mmseg - INFO - Iter [450/40000]	lr: 1.776e-05, eta: 13:33:49, time: 1.222, data_time: 0.010, memory: 9807, decode.loss_seg: 0.8088, decode.acc_seg: 72.6395, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.3597, mix.decode.acc_seg: 76.5771, masked.decode.loss_seg: 0.0000, masked.decode.acc_seg: 76.1181
2023-01-10 14:05:38,832 - mmseg - INFO - Iter [500/40000]	lr: 1.971e-05, eta: 13:31:22, time: 1.213, data_time: 0.010, memory: 9807, decode.loss_seg: 0.7147, decode.acc_seg: 74.6531, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.3716, mix.decode.acc_seg: 76.3711, masked.decode.loss_seg: 0.0000, masked.decode.acc_seg: 74.8078
2023-01-10 14:06:39,939 - mmseg - INFO - Iter [550/40000]	lr: 2.166e-05, eta: 13:29:44, time: 1.222, data_time: 0.010, memory: 9807, decode.loss_seg: 0.6739, decode.acc_seg: 73.5057, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.3796, mix.decode.acc_seg: 73.9461, masked.decode.loss_seg: 0.0000, masked.decode.acc_seg: 71.1606
2023-01-10 14:07:40,885 - mmseg - INFO - Iter [600/40000]	lr: 2.360e-05, eta: 13:28:01, time: 1.219, data_time: 0.010, memory: 9807, decode.loss_seg: 0.5789, decode.acc_seg: 76.5322, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.3178, mix.decode.acc_seg: 76.7226, masked.decode.loss_seg: 0.0000, masked.decode.acc_seg: 71.5066
2023-01-10 14:08:41,909 - mmseg - INFO - Iter [650/40000]	lr: 2.554e-05, eta: 13:26:29, time: 1.220, data_time: 0.010, memory: 9807, decode.loss_seg: 0.5264, decode.acc_seg: 78.7210, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.2951, mix.decode.acc_seg: 78.9768, masked.decode.loss_seg: 0.0000, masked.decode.acc_seg: 74.1046
2023-01-10 14:09:42,931 - mmseg - INFO - Iter [700/40000]	lr: 2.747e-05, eta: 13:25:01, time: 1.220, data_time: 0.011, memory: 9807, decode.loss_seg: 0.5676, decode.acc_seg: 75.6129, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.3019, mix.decode.acc_seg: 76.1083, masked.decode.loss_seg: 0.0000, masked.decode.acc_seg: 71.8901
2023-01-10 14:10:43,808 - mmseg - INFO - Iter [750/40000]	lr: 2.940e-05, eta: 13:23:30, time: 1.218, data_time: 0.010, memory: 9807, decode.loss_seg: 0.5303, decode.acc_seg: 78.6095, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.2436, mix.decode.acc_seg: 78.6265, masked.decode.loss_seg: 0.0002, masked.decode.acc_seg: 71.8385
2023-01-10 14:11:44,803 - mmseg - INFO - Iter [800/40000]	lr: 3.132e-05, eta: 13:22:08, time: 1.220, data_time: 0.010, memory: 9807, decode.loss_seg: 0.5161, decode.acc_seg: 78.1607, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.2450, mix.decode.acc_seg: 78.4073, masked.decode.loss_seg: 0.0002, masked.decode.acc_seg: 72.2808
2023-01-10 14:12:45,847 - mmseg - INFO - Iter [850/40000]	lr: 3.324e-05, eta: 13:20:50, time: 1.221, data_time: 0.010, memory: 9807, decode.loss_seg: 0.4779, decode.acc_seg: 79.3417, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.2684, mix.decode.acc_seg: 77.8448, masked.decode.loss_seg: 0.0013, masked.decode.acc_seg: 69.0694
2023-01-10 14:13:46,897 - mmseg - INFO - Iter [900/40000]	lr: 3.515e-05, eta: 13:19:35, time: 1.221, data_time: 0.010, memory: 9807, decode.loss_seg: 0.3770, decode.acc_seg: 81.7025, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.2117, mix.decode.acc_seg: 79.8080, masked.decode.loss_seg: 0.0024, masked.decode.acc_seg: 73.9966
2023-01-10 14:14:48,215 - mmseg - INFO - Iter [950/40000]	lr: 3.706e-05, eta: 13:18:33, time: 1.226, data_time: 0.010, memory: 9807, decode.loss_seg: 0.3696, decode.acc_seg: 81.4314, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.2023, mix.decode.acc_seg: 79.9277, masked.decode.loss_seg: 0.0048, masked.decode.acc_seg: 77.4191
2023-01-10 14:15:49,444 - mmseg - INFO - Exp name: 230110_1355_230110_1343_gta2cs_dacs_a999_fdthings_rcs001_cpl_m32-07-spta_daformer_sepaspp_mitb5_poly10warm_s0_2feea_f2bea
2023-01-10 14:15:49,444 - mmseg - INFO - Iter [1000/40000]	lr: 3.896e-05, eta: 13:17:27, time: 1.225, data_time: 0.011, memory: 9807, decode.loss_seg: 0.3932, decode.acc_seg: 80.8546, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.2115, mix.decode.acc_seg: 78.7989, masked.decode.loss_seg: 0.0044, masked.decode.acc_seg: 77.4391
2023-01-10 14:16:54,466 - mmseg - INFO - Iter [1050/40000]	lr: 4.086e-05, eta: 13:18:42, time: 1.300, data_time: 0.010, memory: 9807, decode.loss_seg: 0.4284, decode.acc_seg: 78.5448, src.loss_imnet_feat_dist: 0.1222, mix.decode.loss_seg: 0.1999, mix.decode.acc_seg: 80.1981, masked.decode.loss_seg: 0.0092, masked.decode.acc_seg: 77.7104
2023-01-10 14:17:55,727 - mmseg - INFO - Iter [1100/40000]	lr: 4.275e-05, eta: 13:17:31, time: 1.225, data_time: 0.011, memory: 9807, decode.loss_seg: 0.4147, decode.acc_seg: 80.2716, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.2255, mix.decode.acc_seg: 79.5462, masked.decode.loss_seg: 0.0103, masked.decode.acc_seg: 80.2724
2023-01-10 14:18:56,978 - mmseg - INFO - Iter [1150/40000]	lr: 4.464e-05, eta: 13:16:21, time: 1.225, data_time: 0.011, memory: 9807, decode.loss_seg: 0.3097, decode.acc_seg: 83.7285, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1633, mix.decode.acc_seg: 81.5380, masked.decode.loss_seg: 0.0168, masked.decode.acc_seg: 81.3435
2023-01-10 14:19:58,317 - mmseg - INFO - Iter [1200/40000]	lr: 4.652e-05, eta: 13:15:14, time: 1.227, data_time: 0.011, memory: 9807, decode.loss_seg: 0.3414, decode.acc_seg: 82.3308, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1963, mix.decode.acc_seg: 81.0286, masked.decode.loss_seg: 0.0215, masked.decode.acc_seg: 82.8390
2023-01-10 14:20:59,777 - mmseg - INFO - Iter [1250/40000]	lr: 4.840e-05, eta: 13:14:12, time: 1.229, data_time: 0.011, memory: 9807, decode.loss_seg: 0.2941, decode.acc_seg: 85.5621, src.loss_imnet_feat_dist: 0.1099, mix.decode.loss_seg: 0.1639, mix.decode.acc_seg: 83.3492, masked.decode.loss_seg: 0.0207, masked.decode.acc_seg: 85.6133
2023-01-10 14:22:01,130 - mmseg - INFO - Iter [1300/40000]	lr: 5.027e-05, eta: 13:13:07, time: 1.227, data_time: 0.011, memory: 9807, decode.loss_seg: 0.3239, decode.acc_seg: 82.3644, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.2215, mix.decode.acc_seg: 80.6740, masked.decode.loss_seg: 0.0333, masked.decode.acc_seg: 83.7267
2023-01-10 14:23:02,561 - mmseg - INFO - Iter [1350/40000]	lr: 5.214e-05, eta: 13:12:04, time: 1.229, data_time: 0.011, memory: 9807, decode.loss_seg: 0.3211, decode.acc_seg: 81.2600, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1975, mix.decode.acc_seg: 81.1930, masked.decode.loss_seg: 0.0270, masked.decode.acc_seg: 85.5238
2023-01-10 14:24:03,590 - mmseg - INFO - Iter [1400/40000]	lr: 5.400e-05, eta: 13:10:50, time: 1.221, data_time: 0.011, memory: 9807, decode.loss_seg: 0.3489, decode.acc_seg: 83.7378, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.2075, mix.decode.acc_seg: 81.8842, masked.decode.loss_seg: 0.0368, masked.decode.acc_seg: 84.8331
2023-01-10 14:25:04,661 - mmseg - INFO - Iter [1450/40000]	lr: 5.586e-05, eta: 13:09:38, time: 1.221, data_time: 0.011, memory: 9807, decode.loss_seg: 0.3165, decode.acc_seg: 83.5298, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.2350, mix.decode.acc_seg: 80.0402, masked.decode.loss_seg: 0.0412, masked.decode.acc_seg: 84.2495
2023-01-10 14:26:05,936 - mmseg - INFO - Iter [1500/40000]	lr: 5.771e-05, eta: 13:08:32, time: 1.225, data_time: 0.011, memory: 9807, decode.loss_seg: 0.2774, decode.acc_seg: 84.5371, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1926, mix.decode.acc_seg: 82.2506, masked.decode.loss_seg: 0.0465, masked.decode.acc_seg: 85.0989
2023-01-10 14:27:07,173 - mmseg - INFO - Iter [1550/40000]	lr: 5.768e-05, eta: 13:07:25, time: 1.225, data_time: 0.011, memory: 9807, decode.loss_seg: 0.3270, decode.acc_seg: 82.6296, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.2077, mix.decode.acc_seg: 81.0147, masked.decode.loss_seg: 0.0594, masked.decode.acc_seg: 82.0932
2023-01-10 14:28:08,151 - mmseg - INFO - Iter [1600/40000]	lr: 5.760e-05, eta: 13:06:13, time: 1.220, data_time: 0.010, memory: 9807, decode.loss_seg: 0.3214, decode.acc_seg: 83.6140, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1772, mix.decode.acc_seg: 83.5382, masked.decode.loss_seg: 0.0601, masked.decode.acc_seg: 85.2267
2023-01-10 14:29:09,388 - mmseg - INFO - Iter [1650/40000]	lr: 5.753e-05, eta: 13:05:07, time: 1.225, data_time: 0.011, memory: 9807, decode.loss_seg: 0.2863, decode.acc_seg: 81.9408, src.loss_imnet_feat_dist: 0.1201, mix.decode.loss_seg: 0.1849, mix.decode.acc_seg: 82.6788, masked.decode.loss_seg: 0.0694, masked.decode.acc_seg: 84.5329
2023-01-10 14:30:10,958 - mmseg - INFO - Iter [1700/40000]	lr: 5.745e-05, eta: 13:04:09, time: 1.231, data_time: 0.011, memory: 9807, decode.loss_seg: 0.3274, decode.acc_seg: 80.5803, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.2638, mix.decode.acc_seg: 79.7544, masked.decode.loss_seg: 0.0806, masked.decode.acc_seg: 83.7144
2023-01-10 14:31:12,296 - mmseg - INFO - Iter [1750/40000]	lr: 5.738e-05, eta: 13:03:06, time: 1.227, data_time: 0.010, memory: 9807, decode.loss_seg: 0.3107, decode.acc_seg: 83.1767, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.2320, mix.decode.acc_seg: 83.7023, masked.decode.loss_seg: 0.0780, masked.decode.acc_seg: 85.8261
2023-01-10 14:32:13,441 - mmseg - INFO - Iter [1800/40000]	lr: 5.730e-05, eta: 13:01:59, time: 1.223, data_time: 0.010, memory: 9807, decode.loss_seg: 0.3372, decode.acc_seg: 81.6572, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.2484, mix.decode.acc_seg: 81.7649, masked.decode.loss_seg: 0.0926, masked.decode.acc_seg: 84.8855
2023-01-10 14:33:14,475 - mmseg - INFO - Iter [1850/40000]	lr: 5.723e-05, eta: 13:00:49, time: 1.221, data_time: 0.010, memory: 9807, decode.loss_seg: 0.3313, decode.acc_seg: 82.6974, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.2638, mix.decode.acc_seg: 80.7391, masked.decode.loss_seg: 0.1090, masked.decode.acc_seg: 83.8357
2023-01-10 14:34:15,817 - mmseg - INFO - Iter [1900/40000]	lr: 5.715e-05, eta: 12:59:47, time: 1.227, data_time: 0.011, memory: 9807, decode.loss_seg: 0.2942, decode.acc_seg: 83.5114, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.2318, mix.decode.acc_seg: 82.8034, masked.decode.loss_seg: 0.1143, masked.decode.acc_seg: 84.5943
2023-01-10 14:35:16,971 - mmseg - INFO - Iter [1950/40000]	lr: 5.708e-05, eta: 12:58:40, time: 1.223, data_time: 0.010, memory: 9807, decode.loss_seg: 0.2546, decode.acc_seg: 82.6557, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1892, mix.decode.acc_seg: 84.0897, masked.decode.loss_seg: 0.0972, masked.decode.acc_seg: 87.7421
2023-01-10 14:36:18,056 - mmseg - INFO - Exp name: 230110_1355_230110_1343_gta2cs_dacs_a999_fdthings_rcs001_cpl_m32-07-spta_daformer_sepaspp_mitb5_poly10warm_s0_2feea_f2bea
2023-01-10 14:36:18,056 - mmseg - INFO - Iter [2000/40000]	lr: 5.700e-05, eta: 12:57:33, time: 1.222, data_time: 0.011, memory: 9807, decode.loss_seg: 0.2310, decode.acc_seg: 84.7650, src.loss_imnet_feat_dist: 0.1238, mix.decode.loss_seg: 0.1952, mix.decode.acc_seg: 84.9952, masked.decode.loss_seg: 0.1039, masked.decode.acc_seg: 87.5852
2023-01-10 14:37:23,365 - mmseg - INFO - Iter [2050/40000]	lr: 5.693e-05, eta: 12:57:44, time: 1.306, data_time: 0.011, memory: 9807, decode.loss_seg: 0.2287, decode.acc_seg: 85.0977, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1841, mix.decode.acc_seg: 86.4759, masked.decode.loss_seg: 0.1100, masked.decode.acc_seg: 87.9493
2023-01-10 14:38:24,578 - mmseg - INFO - Iter [2100/40000]	lr: 5.685e-05, eta: 12:56:38, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.2172, decode.acc_seg: 83.8546, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1788, mix.decode.acc_seg: 84.0106, masked.decode.loss_seg: 0.1129, masked.decode.acc_seg: 87.4200
2023-01-10 14:39:26,151 - mmseg - INFO - Iter [2150/40000]	lr: 5.678e-05, eta: 12:55:38, time: 1.231, data_time: 0.011, memory: 9807, decode.loss_seg: 0.2278, decode.acc_seg: 85.1813, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1923, mix.decode.acc_seg: 84.6224, masked.decode.loss_seg: 0.1137, masked.decode.acc_seg: 87.9206
2023-01-10 14:40:27,462 - mmseg - INFO - Iter [2200/40000]	lr: 5.670e-05, eta: 12:54:34, time: 1.226, data_time: 0.011, memory: 9807, decode.loss_seg: 0.2549, decode.acc_seg: 82.6071, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.2448, mix.decode.acc_seg: 82.5160, masked.decode.loss_seg: 0.1252, masked.decode.acc_seg: 87.6636
2023-01-10 14:41:28,668 - mmseg - INFO - Iter [2250/40000]	lr: 5.663e-05, eta: 12:53:28, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.2622, decode.acc_seg: 83.8987, src.loss_imnet_feat_dist: 0.1285, mix.decode.loss_seg: 0.2135, mix.decode.acc_seg: 84.6219, masked.decode.loss_seg: 0.1310, masked.decode.acc_seg: 86.8079
2023-01-10 14:42:30,098 - mmseg - INFO - Iter [2300/40000]	lr: 5.655e-05, eta: 12:52:26, time: 1.229, data_time: 0.011, memory: 9807, decode.loss_seg: 0.2049, decode.acc_seg: 85.6409, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1796, mix.decode.acc_seg: 86.4544, masked.decode.loss_seg: 0.1259, masked.decode.acc_seg: 87.4956
2023-01-10 14:43:31,512 - mmseg - INFO - Iter [2350/40000]	lr: 5.648e-05, eta: 12:51:24, time: 1.228, data_time: 0.011, memory: 9807, decode.loss_seg: 0.2589, decode.acc_seg: 83.2862, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.2189, mix.decode.acc_seg: 83.0769, masked.decode.loss_seg: 0.1388, masked.decode.acc_seg: 86.7847
2023-01-10 14:44:32,600 - mmseg - INFO - Iter [2400/40000]	lr: 5.640e-05, eta: 12:50:16, time: 1.222, data_time: 0.011, memory: 9807, decode.loss_seg: 0.2157, decode.acc_seg: 84.5540, src.loss_imnet_feat_dist: 0.1206, mix.decode.loss_seg: 0.1877, mix.decode.acc_seg: 85.1886, masked.decode.loss_seg: 0.1491, masked.decode.acc_seg: 86.2082
2023-01-10 14:45:33,828 - mmseg - INFO - Iter [2450/40000]	lr: 5.633e-05, eta: 12:49:11, time: 1.225, data_time: 0.011, memory: 9807, decode.loss_seg: 0.2679, decode.acc_seg: 84.7200, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.2287, mix.decode.acc_seg: 85.4913, masked.decode.loss_seg: 0.1361, masked.decode.acc_seg: 87.3589
2023-01-10 14:46:35,009 - mmseg - INFO - Iter [2500/40000]	lr: 5.625e-05, eta: 12:48:06, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.2493, decode.acc_seg: 84.3041, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.2298, mix.decode.acc_seg: 84.4467, masked.decode.loss_seg: 0.1463, masked.decode.acc_seg: 87.4252
2023-01-10 14:47:36,460 - mmseg - INFO - Iter [2550/40000]	lr: 5.618e-05, eta: 12:47:04, time: 1.229, data_time: 0.011, memory: 9807, decode.loss_seg: 0.2879, decode.acc_seg: 83.6617, src.loss_imnet_feat_dist: 0.1293, mix.decode.loss_seg: 0.2789, mix.decode.acc_seg: 84.0234, masked.decode.loss_seg: 0.1519, masked.decode.acc_seg: 87.6784
2023-01-10 14:48:37,925 - mmseg - INFO - Iter [2600/40000]	lr: 5.610e-05, eta: 12:46:03, time: 1.229, data_time: 0.011, memory: 9807, decode.loss_seg: 0.2805, decode.acc_seg: 84.1540, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.2461, mix.decode.acc_seg: 85.2282, masked.decode.loss_seg: 0.1449, masked.decode.acc_seg: 88.0444
2023-01-10 14:49:39,045 - mmseg - INFO - Iter [2650/40000]	lr: 5.603e-05, eta: 12:44:57, time: 1.222, data_time: 0.010, memory: 9807, decode.loss_seg: 0.2581, decode.acc_seg: 83.8832, src.loss_imnet_feat_dist: 0.1250, mix.decode.loss_seg: 0.1991, mix.decode.acc_seg: 85.4539, masked.decode.loss_seg: 0.1518, masked.decode.acc_seg: 86.9641
2023-01-10 14:50:40,292 - mmseg - INFO - Iter [2700/40000]	lr: 5.595e-05, eta: 12:43:53, time: 1.225, data_time: 0.011, memory: 9807, decode.loss_seg: 0.2439, decode.acc_seg: 83.0917, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.2232, mix.decode.acc_seg: 83.8967, masked.decode.loss_seg: 0.1424, masked.decode.acc_seg: 88.9111
2023-01-10 14:51:41,926 - mmseg - INFO - Iter [2750/40000]	lr: 5.588e-05, eta: 12:42:54, time: 1.233, data_time: 0.012, memory: 9807, decode.loss_seg: 0.2456, decode.acc_seg: 84.7598, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.2355, mix.decode.acc_seg: 85.7808, masked.decode.loss_seg: 0.1467, masked.decode.acc_seg: 88.5327
2023-01-10 14:52:42,977 - mmseg - INFO - Iter [2800/40000]	lr: 5.580e-05, eta: 12:41:47, time: 1.221, data_time: 0.011, memory: 9807, decode.loss_seg: 0.2694, decode.acc_seg: 83.2979, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.2361, mix.decode.acc_seg: 85.4162, masked.decode.loss_seg: 0.1550, masked.decode.acc_seg: 88.1059
2023-01-10 14:53:44,378 - mmseg - INFO - Iter [2850/40000]	lr: 5.573e-05, eta: 12:40:45, time: 1.228, data_time: 0.011, memory: 9807, decode.loss_seg: 0.2923, decode.acc_seg: 84.0672, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.2554, mix.decode.acc_seg: 85.1439, masked.decode.loss_seg: 0.1630, masked.decode.acc_seg: 87.9213
2023-01-10 14:54:45,623 - mmseg - INFO - Iter [2900/40000]	lr: 5.565e-05, eta: 12:39:42, time: 1.225, data_time: 0.011, memory: 9807, decode.loss_seg: 0.2587, decode.acc_seg: 84.3095, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.2365, mix.decode.acc_seg: 84.8698, masked.decode.loss_seg: 0.1553, masked.decode.acc_seg: 87.8169
2023-01-10 14:55:46,940 - mmseg - INFO - Iter [2950/40000]	lr: 5.558e-05, eta: 12:38:39, time: 1.226, data_time: 0.011, memory: 9807, decode.loss_seg: 0.2118, decode.acc_seg: 87.0192, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.2063, mix.decode.acc_seg: 86.9642, masked.decode.loss_seg: 0.1610, masked.decode.acc_seg: 88.2723
2023-01-10 14:56:48,202 - mmseg - INFO - Exp name: 230110_1355_230110_1343_gta2cs_dacs_a999_fdthings_rcs001_cpl_m32-07-spta_daformer_sepaspp_mitb5_poly10warm_s0_2feea_f2bea
2023-01-10 14:56:48,202 - mmseg - INFO - Iter [3000/40000]	lr: 5.550e-05, eta: 12:37:35, time: 1.225, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1976, decode.acc_seg: 85.0135, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1835, mix.decode.acc_seg: 86.5583, masked.decode.loss_seg: 0.1488, masked.decode.acc_seg: 88.6402
2023-01-10 14:57:53,085 - mmseg - INFO - Iter [3050/40000]	lr: 5.543e-05, eta: 12:37:16, time: 1.298, data_time: 0.011, memory: 9807, decode.loss_seg: 0.2153, decode.acc_seg: 83.5292, src.loss_imnet_feat_dist: 0.1264, mix.decode.loss_seg: 0.2243, mix.decode.acc_seg: 84.7156, masked.decode.loss_seg: 0.1613, masked.decode.acc_seg: 88.2568
2023-01-10 14:58:54,127 - mmseg - INFO - Iter [3100/40000]	lr: 5.535e-05, eta: 12:36:09, time: 1.221, data_time: 0.011, memory: 9807, decode.loss_seg: 0.2519, decode.acc_seg: 85.2045, src.loss_imnet_feat_dist: 0.1287, mix.decode.loss_seg: 0.2121, mix.decode.acc_seg: 86.6026, masked.decode.loss_seg: 0.1866, masked.decode.acc_seg: 87.1575
2023-01-10 14:59:55,333 - mmseg - INFO - Iter [3150/40000]	lr: 5.528e-05, eta: 12:35:04, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.2098, decode.acc_seg: 84.3236, src.loss_imnet_feat_dist: 0.1201, mix.decode.loss_seg: 0.1943, mix.decode.acc_seg: 86.9459, masked.decode.loss_seg: 0.1613, masked.decode.acc_seg: 89.2663
2023-01-10 15:00:56,616 - mmseg - INFO - Iter [3200/40000]	lr: 5.520e-05, eta: 12:34:01, time: 1.226, data_time: 0.011, memory: 9807, decode.loss_seg: 0.2029, decode.acc_seg: 85.9679, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1941, mix.decode.acc_seg: 87.3449, masked.decode.loss_seg: 0.1603, masked.decode.acc_seg: 89.0069
2023-01-10 15:01:57,787 - mmseg - INFO - Iter [3250/40000]	lr: 5.513e-05, eta: 12:32:56, time: 1.223, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1818, decode.acc_seg: 86.2514, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1746, mix.decode.acc_seg: 87.9388, masked.decode.loss_seg: 0.1527, masked.decode.acc_seg: 89.3218
2023-01-10 15:02:58,938 - mmseg - INFO - Iter [3300/40000]	lr: 5.505e-05, eta: 12:31:51, time: 1.223, data_time: 0.011, memory: 9807, decode.loss_seg: 0.2451, decode.acc_seg: 84.6063, src.loss_imnet_feat_dist: 0.1225, mix.decode.loss_seg: 0.2515, mix.decode.acc_seg: 85.8945, masked.decode.loss_seg: 0.1640, masked.decode.acc_seg: 88.0662
2023-01-10 15:04:00,111 - mmseg - INFO - Iter [3350/40000]	lr: 5.498e-05, eta: 12:30:46, time: 1.223, data_time: 0.011, memory: 9807, decode.loss_seg: 0.2372, decode.acc_seg: 84.9003, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.2354, mix.decode.acc_seg: 85.0686, masked.decode.loss_seg: 0.1632, masked.decode.acc_seg: 88.8267
2023-01-10 15:05:01,564 - mmseg - INFO - Iter [3400/40000]	lr: 5.490e-05, eta: 12:29:45, time: 1.229, data_time: 0.011, memory: 9807, decode.loss_seg: 0.2027, decode.acc_seg: 83.6976, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.2053, mix.decode.acc_seg: 84.8877, masked.decode.loss_seg: 0.1558, masked.decode.acc_seg: 89.2759
2023-01-10 15:06:02,783 - mmseg - INFO - Iter [3450/40000]	lr: 5.483e-05, eta: 12:28:41, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1817, decode.acc_seg: 86.5801, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1844, mix.decode.acc_seg: 88.0708, masked.decode.loss_seg: 0.1558, masked.decode.acc_seg: 89.6613
2023-01-10 15:07:04,094 - mmseg - INFO - Iter [3500/40000]	lr: 5.475e-05, eta: 12:27:38, time: 1.226, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1996, decode.acc_seg: 84.7276, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1910, mix.decode.acc_seg: 87.4320, masked.decode.loss_seg: 0.1508, masked.decode.acc_seg: 89.9671
2023-01-10 15:08:05,543 - mmseg - INFO - Iter [3550/40000]	lr: 5.468e-05, eta: 12:26:36, time: 1.229, data_time: 0.011, memory: 9807, decode.loss_seg: 0.2113, decode.acc_seg: 85.3788, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.2256, mix.decode.acc_seg: 86.6639, masked.decode.loss_seg: 0.1661, masked.decode.acc_seg: 88.8215
2023-01-10 15:09:06,742 - mmseg - INFO - Iter [3600/40000]	lr: 5.460e-05, eta: 12:25:32, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.2098, decode.acc_seg: 84.4586, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.2059, mix.decode.acc_seg: 87.4425, masked.decode.loss_seg: 0.1600, masked.decode.acc_seg: 89.7064
2023-01-10 15:10:07,777 - mmseg - INFO - Iter [3650/40000]	lr: 5.453e-05, eta: 12:24:27, time: 1.221, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1898, decode.acc_seg: 87.5918, src.loss_imnet_feat_dist: 0.1218, mix.decode.loss_seg: 0.1878, mix.decode.acc_seg: 87.8534, masked.decode.loss_seg: 0.1600, masked.decode.acc_seg: 90.0021
2023-01-10 15:11:08,871 - mmseg - INFO - Iter [3700/40000]	lr: 5.445e-05, eta: 12:23:22, time: 1.222, data_time: 0.011, memory: 9807, decode.loss_seg: 0.2195, decode.acc_seg: 84.6019, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.2218, mix.decode.acc_seg: 85.7885, masked.decode.loss_seg: 0.1603, masked.decode.acc_seg: 89.1435
2023-01-10 15:12:09,702 - mmseg - INFO - Iter [3750/40000]	lr: 5.438e-05, eta: 12:22:15, time: 1.217, data_time: 0.011, memory: 9807, decode.loss_seg: 0.2019, decode.acc_seg: 85.8144, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1807, mix.decode.acc_seg: 88.4424, masked.decode.loss_seg: 0.1579, masked.decode.acc_seg: 90.1642
2023-01-10 15:13:10,697 - mmseg - INFO - Iter [3800/40000]	lr: 5.430e-05, eta: 12:21:09, time: 1.220, data_time: 0.011, memory: 9807, decode.loss_seg: 0.2090, decode.acc_seg: 85.3736, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1986, mix.decode.acc_seg: 86.6681, masked.decode.loss_seg: 0.1692, masked.decode.acc_seg: 89.2487
2023-01-10 15:14:11,685 - mmseg - INFO - Iter [3850/40000]	lr: 5.423e-05, eta: 12:20:04, time: 1.220, data_time: 0.011, memory: 9807, decode.loss_seg: 0.2197, decode.acc_seg: 84.6381, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.2048, mix.decode.acc_seg: 86.1625, masked.decode.loss_seg: 0.1741, masked.decode.acc_seg: 89.6652
2023-01-10 15:15:12,577 - mmseg - INFO - Iter [3900/40000]	lr: 5.415e-05, eta: 12:18:57, time: 1.218, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1990, decode.acc_seg: 86.7814, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1848, mix.decode.acc_seg: 87.9092, masked.decode.loss_seg: 0.1633, masked.decode.acc_seg: 89.2127
2023-01-10 15:16:13,352 - mmseg - INFO - Iter [3950/40000]	lr: 5.408e-05, eta: 12:17:50, time: 1.215, data_time: 0.011, memory: 9807, decode.loss_seg: 0.2290, decode.acc_seg: 84.7042, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.2212, mix.decode.acc_seg: 86.4976, masked.decode.loss_seg: 0.1909, masked.decode.acc_seg: 88.0817
2023-01-10 15:18:31,350 - mmseg - INFO - per class results:
2023-01-10 15:18:31,420 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      road     | 91.66 | 98.08 |
|    sidewalk   | 46.71 | 53.12 |
|    building   | 86.47 | 92.78 |
|      wall     | 47.96 | 56.56 |
|     fence     | 25.99 | 29.54 |
|      pole     |  40.3 |  50.4 |
| traffic light | 45.43 | 57.02 |
|  traffic sign | 44.25 | 47.65 |
|   vegetation  | 86.99 | 94.49 |
|    terrain    | 44.06 | 62.96 |
|      sky      | 88.53 | 98.35 |
|     person    | 63.91 | 75.19 |
|     rider     | 35.67 | 61.06 |
|      car      | 87.37 |  96.9 |
|     truck     | 65.33 | 76.42 |
|      bus      | 64.99 | 70.37 |
|     train     | 64.31 | 85.22 |
|   motorcycle  | 44.79 | 66.64 |
|    bicycle    | 55.87 | 66.18 |
+---------------+-------+-------+
2023-01-10 15:18:31,420 - mmseg - INFO - Summary:
2023-01-10 15:18:31,421 - mmseg - INFO - 
+------+-------+-------+
| aAcc |  mIoU |  mAcc |
+------+-------+-------+
| 90.7 | 59.51 | 70.47 |
+------+-------+-------+
2023-01-10 15:18:31,469 - mmseg - INFO - Exp name: 230110_1355_230110_1343_gta2cs_dacs_a999_fdthings_rcs001_cpl_m32-07-spta_daformer_sepaspp_mitb5_poly10warm_s0_2feea_f2bea
2023-01-10 15:18:31,471 - mmseg - INFO - Iter [500/40000]	lr: 5.400e-05, eta: 12:16:46, time: 1.221, data_time: 0.011, memory: 9807, aAcc: 0.9070, mIoU: 0.5951, mAcc: 0.7047, IoU.road: 0.9166, IoU.sidewalk: 0.4671, IoU.building: 0.8647, IoU.wall: 0.4796, IoU.fence: 0.2599, IoU.pole: 0.4030, IoU.traffic light: 0.4543, IoU.traffic sign: 0.4425, IoU.vegetation: 0.8699, IoU.terrain: 0.4406, IoU.sky: 0.8853, IoU.person: 0.6391, IoU.rider: 0.3567, IoU.car: 0.8737, IoU.truck: 0.6533, IoU.bus: 0.6499, IoU.train: 0.6431, IoU.motorcycle: 0.4479, IoU.bicycle: 0.5587, Acc.road: 0.9808, Acc.sidewalk: 0.5312, Acc.building: 0.9278, Acc.wall: 0.5656, Acc.fence: 0.2954, Acc.pole: 0.5040, Acc.traffic light: 0.5702, Acc.traffic sign: 0.4765, Acc.vegetation: 0.9449, Acc.terrain: 0.6296, Acc.sky: 0.9835, Acc.person: 0.7519, Acc.rider: 0.6106, Acc.car: 0.9690, Acc.truck: 0.7642, Acc.bus: 0.7037, Acc.train: 0.8522, Acc.motorcycle: 0.6664, Acc.bicycle: 0.6618, decode.loss_seg: 0.1724, decode.acc_seg: 86.2034, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1720, mix.decode.acc_seg: 88.3695, masked.decode.loss_seg: 0.1646, masked.decode.acc_seg: 89.8558
2023-01-10 15:19:38,637 - mmseg - INFO - Iter [4050/40000]	lr: 5.393e-05, eta: 12:28:00, time: 2.885, data_time: 1.554, memory: 9807, decode.loss_seg: 0.1939, decode.acc_seg: 85.8153, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1795, mix.decode.acc_seg: 87.7662, masked.decode.loss_seg: 0.1570, masked.decode.acc_seg: 89.6878
2023-01-10 15:20:40,000 - mmseg - INFO - Iter [4100/40000]	lr: 5.385e-05, eta: 12:26:48, time: 1.227, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1899, decode.acc_seg: 86.8846, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1782, mix.decode.acc_seg: 88.8737, masked.decode.loss_seg: 0.1551, masked.decode.acc_seg: 90.6314
2023-01-10 15:21:41,314 - mmseg - INFO - Iter [4150/40000]	lr: 5.378e-05, eta: 12:25:36, time: 1.226, data_time: 0.010, memory: 9807, decode.loss_seg: 0.1592, decode.acc_seg: 87.0933, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1641, mix.decode.acc_seg: 89.2558, masked.decode.loss_seg: 0.1644, masked.decode.acc_seg: 90.1628
2023-01-10 15:22:42,302 - mmseg - INFO - Iter [4200/40000]	lr: 5.370e-05, eta: 12:24:22, time: 1.220, data_time: 0.010, memory: 9807, decode.loss_seg: 0.1874, decode.acc_seg: 87.2036, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1762, mix.decode.acc_seg: 88.4273, masked.decode.loss_seg: 0.1516, masked.decode.acc_seg: 90.3767
2023-01-10 15:23:43,303 - mmseg - INFO - Iter [4250/40000]	lr: 5.363e-05, eta: 12:23:08, time: 1.220, data_time: 0.011, memory: 9807, decode.loss_seg: 0.2219, decode.acc_seg: 85.5654, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.2257, mix.decode.acc_seg: 86.2590, masked.decode.loss_seg: 0.1712, masked.decode.acc_seg: 89.4782
2023-01-10 15:24:44,211 - mmseg - INFO - Iter [4300/40000]	lr: 5.355e-05, eta: 12:21:53, time: 1.218, data_time: 0.011, memory: 9807, decode.loss_seg: 0.2185, decode.acc_seg: 83.8918, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.2089, mix.decode.acc_seg: 87.3646, masked.decode.loss_seg: 0.1732, masked.decode.acc_seg: 89.4454
2023-01-10 15:25:45,401 - mmseg - INFO - Iter [4350/40000]	lr: 5.348e-05, eta: 12:20:42, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.2003, decode.acc_seg: 86.1378, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1831, mix.decode.acc_seg: 87.7445, masked.decode.loss_seg: 0.1823, masked.decode.acc_seg: 87.9658
2023-01-10 15:26:46,611 - mmseg - INFO - Iter [4400/40000]	lr: 5.340e-05, eta: 12:19:30, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1787, decode.acc_seg: 85.2632, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1845, mix.decode.acc_seg: 88.2742, masked.decode.loss_seg: 0.1798, masked.decode.acc_seg: 89.4871
2023-01-10 15:27:47,798 - mmseg - INFO - Iter [4450/40000]	lr: 5.333e-05, eta: 12:18:19, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1685, decode.acc_seg: 86.8212, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1874, mix.decode.acc_seg: 87.3920, masked.decode.loss_seg: 0.1786, masked.decode.acc_seg: 88.7551
2023-01-10 15:28:48,971 - mmseg - INFO - Iter [4500/40000]	lr: 5.325e-05, eta: 12:17:08, time: 1.223, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1911, decode.acc_seg: 87.3255, src.loss_imnet_feat_dist: 0.1205, mix.decode.loss_seg: 0.1832, mix.decode.acc_seg: 89.0535, masked.decode.loss_seg: 0.1794, masked.decode.acc_seg: 89.3138
2023-01-10 15:29:50,249 - mmseg - INFO - Iter [4550/40000]	lr: 5.318e-05, eta: 12:15:57, time: 1.226, data_time: 0.011, memory: 9807, decode.loss_seg: 0.2348, decode.acc_seg: 84.9409, src.loss_imnet_feat_dist: 0.1211, mix.decode.loss_seg: 0.2276, mix.decode.acc_seg: 86.9597, masked.decode.loss_seg: 0.1655, masked.decode.acc_seg: 89.8927
2023-01-10 15:30:51,218 - mmseg - INFO - Iter [4600/40000]	lr: 5.310e-05, eta: 12:14:45, time: 1.219, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1839, decode.acc_seg: 83.6820, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1802, mix.decode.acc_seg: 86.3153, masked.decode.loss_seg: 0.1643, masked.decode.acc_seg: 89.9648
2023-01-10 15:31:52,137 - mmseg - INFO - Iter [4650/40000]	lr: 5.303e-05, eta: 12:13:32, time: 1.218, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1882, decode.acc_seg: 87.0808, src.loss_imnet_feat_dist: 0.1212, mix.decode.loss_seg: 0.1986, mix.decode.acc_seg: 88.3399, masked.decode.loss_seg: 0.1783, masked.decode.acc_seg: 88.9838
2023-01-10 15:32:53,534 - mmseg - INFO - Iter [4700/40000]	lr: 5.295e-05, eta: 12:12:24, time: 1.228, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1917, decode.acc_seg: 84.7265, src.loss_imnet_feat_dist: 0.1264, mix.decode.loss_seg: 0.1964, mix.decode.acc_seg: 87.1477, masked.decode.loss_seg: 0.1732, masked.decode.acc_seg: 89.2578
2023-01-10 15:33:54,868 - mmseg - INFO - Iter [4750/40000]	lr: 5.288e-05, eta: 12:11:15, time: 1.227, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1769, decode.acc_seg: 86.6071, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.2161, mix.decode.acc_seg: 87.0056, masked.decode.loss_seg: 0.1854, masked.decode.acc_seg: 88.0807
2023-01-10 15:34:56,352 - mmseg - INFO - Iter [4800/40000]	lr: 5.280e-05, eta: 12:10:07, time: 1.230, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1763, decode.acc_seg: 83.7704, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1862, mix.decode.acc_seg: 88.7703, masked.decode.loss_seg: 0.1868, masked.decode.acc_seg: 89.1111
2023-01-10 15:35:57,696 - mmseg - INFO - Iter [4850/40000]	lr: 5.273e-05, eta: 12:08:58, time: 1.227, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1878, decode.acc_seg: 85.6388, src.loss_imnet_feat_dist: 0.1209, mix.decode.loss_seg: 0.1935, mix.decode.acc_seg: 88.1140, masked.decode.loss_seg: 0.1676, masked.decode.acc_seg: 90.0434
2023-01-10 15:36:59,065 - mmseg - INFO - Iter [4900/40000]	lr: 5.265e-05, eta: 12:07:50, time: 1.227, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1842, decode.acc_seg: 87.2995, src.loss_imnet_feat_dist: 0.1291, mix.decode.loss_seg: 0.1732, mix.decode.acc_seg: 89.1518, masked.decode.loss_seg: 0.1736, masked.decode.acc_seg: 89.9646
2023-01-10 15:38:00,574 - mmseg - INFO - Iter [4950/40000]	lr: 5.258e-05, eta: 12:06:43, time: 1.230, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1937, decode.acc_seg: 84.8927, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1879, mix.decode.acc_seg: 87.8714, masked.decode.loss_seg: 0.1711, masked.decode.acc_seg: 89.6279
2023-01-10 15:39:01,756 - mmseg - INFO - Exp name: 230110_1355_230110_1343_gta2cs_dacs_a999_fdthings_rcs001_cpl_m32-07-spta_daformer_sepaspp_mitb5_poly10warm_s0_2feea_f2bea
2023-01-10 15:39:01,756 - mmseg - INFO - Iter [5000/40000]	lr: 5.250e-05, eta: 12:05:34, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1760, decode.acc_seg: 86.9150, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1809, mix.decode.acc_seg: 88.3898, masked.decode.loss_seg: 0.1656, masked.decode.acc_seg: 90.5223
2023-01-10 15:40:08,237 - mmseg - INFO - Iter [5050/40000]	lr: 5.243e-05, eta: 12:05:01, time: 1.330, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1628, decode.acc_seg: 86.9796, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1731, mix.decode.acc_seg: 88.8949, masked.decode.loss_seg: 0.1716, masked.decode.acc_seg: 89.9767
2023-01-10 15:41:09,750 - mmseg - INFO - Iter [5100/40000]	lr: 5.235e-05, eta: 12:03:54, time: 1.230, data_time: 0.011, memory: 9807, decode.loss_seg: 0.2142, decode.acc_seg: 85.5279, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.2275, mix.decode.acc_seg: 86.6483, masked.decode.loss_seg: 0.1889, masked.decode.acc_seg: 88.6679
2023-01-10 15:42:11,139 - mmseg - INFO - Iter [5150/40000]	lr: 5.228e-05, eta: 12:02:46, time: 1.228, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1761, decode.acc_seg: 87.2539, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1854, mix.decode.acc_seg: 88.6671, masked.decode.loss_seg: 0.1646, masked.decode.acc_seg: 89.9182
2023-01-10 15:43:12,760 - mmseg - INFO - Iter [5200/40000]	lr: 5.220e-05, eta: 12:01:40, time: 1.232, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1764, decode.acc_seg: 86.7887, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1932, mix.decode.acc_seg: 89.0436, masked.decode.loss_seg: 0.1781, masked.decode.acc_seg: 89.5829
2023-01-10 15:44:14,171 - mmseg - INFO - Iter [5250/40000]	lr: 5.213e-05, eta: 12:00:32, time: 1.228, data_time: 0.011, memory: 9807, decode.loss_seg: 0.2020, decode.acc_seg: 85.0404, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.2010, mix.decode.acc_seg: 86.6389, masked.decode.loss_seg: 0.1800, masked.decode.acc_seg: 89.7895
2023-01-10 15:45:15,844 - mmseg - INFO - Iter [5300/40000]	lr: 5.205e-05, eta: 11:59:27, time: 1.233, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1669, decode.acc_seg: 87.6970, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1659, mix.decode.acc_seg: 88.4636, masked.decode.loss_seg: 0.1778, masked.decode.acc_seg: 89.2626
2023-01-10 15:46:16,971 - mmseg - INFO - Iter [5350/40000]	lr: 5.198e-05, eta: 11:58:17, time: 1.223, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1946, decode.acc_seg: 86.0609, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1902, mix.decode.acc_seg: 88.2965, masked.decode.loss_seg: 0.1721, masked.decode.acc_seg: 89.3479
2023-01-10 15:47:18,034 - mmseg - INFO - Iter [5400/40000]	lr: 5.190e-05, eta: 11:57:08, time: 1.221, data_time: 0.011, memory: 9807, decode.loss_seg: 0.2160, decode.acc_seg: 87.3419, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.2197, mix.decode.acc_seg: 87.6664, masked.decode.loss_seg: 0.1717, masked.decode.acc_seg: 89.8780
2023-01-10 15:48:19,210 - mmseg - INFO - Iter [5450/40000]	lr: 5.183e-05, eta: 11:55:59, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1889, decode.acc_seg: 86.3611, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1857, mix.decode.acc_seg: 88.9600, masked.decode.loss_seg: 0.1826, masked.decode.acc_seg: 89.5032
2023-01-10 15:49:20,581 - mmseg - INFO - Iter [5500/40000]	lr: 5.175e-05, eta: 11:54:52, time: 1.227, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1667, decode.acc_seg: 88.0481, src.loss_imnet_feat_dist: 0.1262, mix.decode.loss_seg: 0.1653, mix.decode.acc_seg: 89.7094, masked.decode.loss_seg: 0.1736, masked.decode.acc_seg: 90.0534
2023-01-10 15:50:21,990 - mmseg - INFO - Iter [5550/40000]	lr: 5.168e-05, eta: 11:53:45, time: 1.228, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1734, decode.acc_seg: 85.4683, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1797, mix.decode.acc_seg: 88.0390, masked.decode.loss_seg: 0.1727, masked.decode.acc_seg: 90.2175
2023-01-10 15:51:23,456 - mmseg - INFO - Iter [5600/40000]	lr: 5.160e-05, eta: 11:52:39, time: 1.229, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1690, decode.acc_seg: 85.4695, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1998, mix.decode.acc_seg: 87.7217, masked.decode.loss_seg: 0.1842, masked.decode.acc_seg: 89.3141
2023-01-10 15:52:25,025 - mmseg - INFO - Iter [5650/40000]	lr: 5.153e-05, eta: 11:51:33, time: 1.231, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1988, decode.acc_seg: 86.8161, src.loss_imnet_feat_dist: 0.1197, mix.decode.loss_seg: 0.1891, mix.decode.acc_seg: 88.8414, masked.decode.loss_seg: 0.1835, masked.decode.acc_seg: 89.3568
2023-01-10 15:53:26,351 - mmseg - INFO - Iter [5700/40000]	lr: 5.145e-05, eta: 11:50:26, time: 1.227, data_time: 0.010, memory: 9807, decode.loss_seg: 0.1906, decode.acc_seg: 84.8200, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1791, mix.decode.acc_seg: 88.6804, masked.decode.loss_seg: 0.1760, masked.decode.acc_seg: 90.1998
2023-01-10 15:54:27,507 - mmseg - INFO - Iter [5750/40000]	lr: 5.138e-05, eta: 11:49:18, time: 1.223, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1471, decode.acc_seg: 87.4186, src.loss_imnet_feat_dist: 0.1198, mix.decode.loss_seg: 0.1756, mix.decode.acc_seg: 89.6480, masked.decode.loss_seg: 0.1795, masked.decode.acc_seg: 89.8281
2023-01-10 15:55:28,741 - mmseg - INFO - Iter [5800/40000]	lr: 5.130e-05, eta: 11:48:11, time: 1.225, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1763, decode.acc_seg: 84.5105, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1811, mix.decode.acc_seg: 87.9524, masked.decode.loss_seg: 0.1770, masked.decode.acc_seg: 89.5624
2023-01-10 15:56:29,994 - mmseg - INFO - Iter [5850/40000]	lr: 5.123e-05, eta: 11:47:04, time: 1.225, data_time: 0.011, memory: 9807, decode.loss_seg: 0.2271, decode.acc_seg: 86.1252, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1885, mix.decode.acc_seg: 87.8071, masked.decode.loss_seg: 0.1646, masked.decode.acc_seg: 90.0863
2023-01-10 15:57:31,205 - mmseg - INFO - Iter [5900/40000]	lr: 5.115e-05, eta: 11:45:56, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1941, decode.acc_seg: 86.9506, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1705, mix.decode.acc_seg: 89.7620, masked.decode.loss_seg: 0.1739, masked.decode.acc_seg: 90.4916
2023-01-10 15:58:32,769 - mmseg - INFO - Iter [5950/40000]	lr: 5.108e-05, eta: 11:44:51, time: 1.231, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1627, decode.acc_seg: 86.7235, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1636, mix.decode.acc_seg: 88.8131, masked.decode.loss_seg: 0.1723, masked.decode.acc_seg: 90.4666
2023-01-10 15:59:34,239 - mmseg - INFO - Exp name: 230110_1355_230110_1343_gta2cs_dacs_a999_fdthings_rcs001_cpl_m32-07-spta_daformer_sepaspp_mitb5_poly10warm_s0_2feea_f2bea
2023-01-10 15:59:34,239 - mmseg - INFO - Iter [6000/40000]	lr: 5.100e-05, eta: 11:43:45, time: 1.229, data_time: 0.010, memory: 9807, decode.loss_seg: 0.1680, decode.acc_seg: 86.3363, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1645, mix.decode.acc_seg: 88.8269, masked.decode.loss_seg: 0.1862, masked.decode.acc_seg: 89.5799
2023-01-10 16:00:39,819 - mmseg - INFO - Iter [6050/40000]	lr: 5.093e-05, eta: 11:43:03, time: 1.312, data_time: 0.010, memory: 9807, decode.loss_seg: 0.1603, decode.acc_seg: 88.9432, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1589, mix.decode.acc_seg: 90.4182, masked.decode.loss_seg: 0.1750, masked.decode.acc_seg: 90.4094
2023-01-10 16:01:41,298 - mmseg - INFO - Iter [6100/40000]	lr: 5.085e-05, eta: 11:41:57, time: 1.230, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1764, decode.acc_seg: 87.7929, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1841, mix.decode.acc_seg: 89.2728, masked.decode.loss_seg: 0.1693, masked.decode.acc_seg: 90.9788
2023-01-10 16:02:42,624 - mmseg - INFO - Iter [6150/40000]	lr: 5.078e-05, eta: 11:40:51, time: 1.226, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1473, decode.acc_seg: 87.6602, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1638, mix.decode.acc_seg: 90.4881, masked.decode.loss_seg: 0.1763, masked.decode.acc_seg: 90.2642
2023-01-10 16:03:44,271 - mmseg - INFO - Iter [6200/40000]	lr: 5.070e-05, eta: 11:39:46, time: 1.233, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1672, decode.acc_seg: 86.3792, src.loss_imnet_feat_dist: 0.1169, mix.decode.loss_seg: 0.1730, mix.decode.acc_seg: 88.9486, masked.decode.loss_seg: 0.1764, masked.decode.acc_seg: 90.1243
2023-01-10 16:04:45,679 - mmseg - INFO - Iter [6250/40000]	lr: 5.063e-05, eta: 11:38:40, time: 1.228, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1739, decode.acc_seg: 87.6436, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1736, mix.decode.acc_seg: 89.2648, masked.decode.loss_seg: 0.1745, masked.decode.acc_seg: 90.0433
2023-01-10 16:05:47,222 - mmseg - INFO - Iter [6300/40000]	lr: 5.055e-05, eta: 11:37:35, time: 1.231, data_time: 0.011, memory: 9807, decode.loss_seg: 0.2036, decode.acc_seg: 84.9031, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.2545, mix.decode.acc_seg: 85.4783, masked.decode.loss_seg: 0.1808, masked.decode.acc_seg: 88.6600
2023-01-10 16:06:48,868 - mmseg - INFO - Iter [6350/40000]	lr: 5.048e-05, eta: 11:36:30, time: 1.233, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1599, decode.acc_seg: 86.9190, src.loss_imnet_feat_dist: 0.1158, mix.decode.loss_seg: 0.1799, mix.decode.acc_seg: 88.2470, masked.decode.loss_seg: 0.1874, masked.decode.acc_seg: 89.0938
2023-01-10 16:07:50,086 - mmseg - INFO - Iter [6400/40000]	lr: 5.040e-05, eta: 11:35:24, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1676, decode.acc_seg: 85.8516, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1704, mix.decode.acc_seg: 88.9661, masked.decode.loss_seg: 0.1641, masked.decode.acc_seg: 90.4754
2023-01-10 16:08:51,438 - mmseg - INFO - Iter [6450/40000]	lr: 5.033e-05, eta: 11:34:18, time: 1.227, data_time: 0.011, memory: 9807, decode.loss_seg: 0.2159, decode.acc_seg: 84.5186, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1763, mix.decode.acc_seg: 88.3858, masked.decode.loss_seg: 0.1800, masked.decode.acc_seg: 89.6114
2023-01-10 16:09:52,769 - mmseg - INFO - Iter [6500/40000]	lr: 5.025e-05, eta: 11:33:12, time: 1.227, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1840, decode.acc_seg: 87.1543, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1877, mix.decode.acc_seg: 89.0044, masked.decode.loss_seg: 0.1694, masked.decode.acc_seg: 90.8211
2023-01-10 16:10:54,171 - mmseg - INFO - Iter [6550/40000]	lr: 5.018e-05, eta: 11:32:06, time: 1.228, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1586, decode.acc_seg: 84.9033, src.loss_imnet_feat_dist: 0.1239, mix.decode.loss_seg: 0.1714, mix.decode.acc_seg: 88.2171, masked.decode.loss_seg: 0.1675, masked.decode.acc_seg: 90.8066
2023-01-10 16:11:55,877 - mmseg - INFO - Iter [6600/40000]	lr: 5.010e-05, eta: 11:31:02, time: 1.234, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1709, decode.acc_seg: 86.6791, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1762, mix.decode.acc_seg: 88.5979, masked.decode.loss_seg: 0.1618, masked.decode.acc_seg: 90.8307
2023-01-10 16:12:57,319 - mmseg - INFO - Iter [6650/40000]	lr: 5.003e-05, eta: 11:29:57, time: 1.229, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1630, decode.acc_seg: 86.7777, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1594, mix.decode.acc_seg: 87.8973, masked.decode.loss_seg: 0.1702, masked.decode.acc_seg: 90.0613
2023-01-10 16:13:58,649 - mmseg - INFO - Iter [6700/40000]	lr: 4.995e-05, eta: 11:28:51, time: 1.227, data_time: 0.010, memory: 9807, decode.loss_seg: 0.1631, decode.acc_seg: 86.9783, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1923, mix.decode.acc_seg: 89.2699, masked.decode.loss_seg: 0.1795, masked.decode.acc_seg: 90.0498
2023-01-10 16:14:59,993 - mmseg - INFO - Iter [6750/40000]	lr: 4.988e-05, eta: 11:27:46, time: 1.227, data_time: 0.011, memory: 9807, decode.loss_seg: 0.2267, decode.acc_seg: 83.8697, src.loss_imnet_feat_dist: 0.1170, mix.decode.loss_seg: 0.1949, mix.decode.acc_seg: 87.2311, masked.decode.loss_seg: 0.1718, masked.decode.acc_seg: 90.4084
2023-01-10 16:16:01,423 - mmseg - INFO - Iter [6800/40000]	lr: 4.980e-05, eta: 11:26:41, time: 1.229, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1646, decode.acc_seg: 86.1506, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1610, mix.decode.acc_seg: 89.1276, masked.decode.loss_seg: 0.1741, masked.decode.acc_seg: 90.3403
2023-01-10 16:17:03,011 - mmseg - INFO - Iter [6850/40000]	lr: 4.973e-05, eta: 11:25:36, time: 1.232, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1652, decode.acc_seg: 86.7941, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1843, mix.decode.acc_seg: 88.2551, masked.decode.loss_seg: 0.2055, masked.decode.acc_seg: 88.4590
2023-01-10 16:18:04,388 - mmseg - INFO - Iter [6900/40000]	lr: 4.965e-05, eta: 11:24:31, time: 1.228, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1650, decode.acc_seg: 85.4349, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1781, mix.decode.acc_seg: 87.2916, masked.decode.loss_seg: 0.1768, masked.decode.acc_seg: 90.2335
2023-01-10 16:19:05,651 - mmseg - INFO - Iter [6950/40000]	lr: 4.958e-05, eta: 11:23:25, time: 1.225, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1723, decode.acc_seg: 87.6229, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1801, mix.decode.acc_seg: 89.0284, masked.decode.loss_seg: 0.1802, masked.decode.acc_seg: 89.9437
2023-01-10 16:20:07,238 - mmseg - INFO - Exp name: 230110_1355_230110_1343_gta2cs_dacs_a999_fdthings_rcs001_cpl_m32-07-spta_daformer_sepaspp_mitb5_poly10warm_s0_2feea_f2bea
2023-01-10 16:20:07,238 - mmseg - INFO - Iter [7000/40000]	lr: 4.950e-05, eta: 11:22:21, time: 1.232, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1768, decode.acc_seg: 88.0078, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1602, mix.decode.acc_seg: 89.6112, masked.decode.loss_seg: 0.1679, masked.decode.acc_seg: 90.7520
2023-01-10 16:21:13,128 - mmseg - INFO - Iter [7050/40000]	lr: 4.943e-05, eta: 11:21:37, time: 1.318, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1742, decode.acc_seg: 85.9022, src.loss_imnet_feat_dist: 0.1230, mix.decode.loss_seg: 0.1689, mix.decode.acc_seg: 88.3836, masked.decode.loss_seg: 0.1836, masked.decode.acc_seg: 89.1749
2023-01-10 16:22:14,478 - mmseg - INFO - Iter [7100/40000]	lr: 4.935e-05, eta: 11:20:32, time: 1.227, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1618, decode.acc_seg: 86.9674, src.loss_imnet_feat_dist: 0.1145, mix.decode.loss_seg: 0.1619, mix.decode.acc_seg: 88.8801, masked.decode.loss_seg: 0.1921, masked.decode.acc_seg: 89.9178
2023-01-10 16:23:15,570 - mmseg - INFO - Iter [7150/40000]	lr: 4.928e-05, eta: 11:19:25, time: 1.222, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1510, decode.acc_seg: 87.9979, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1661, mix.decode.acc_seg: 88.8122, masked.decode.loss_seg: 0.1675, masked.decode.acc_seg: 90.8254
2023-01-10 16:24:17,045 - mmseg - INFO - Iter [7200/40000]	lr: 4.920e-05, eta: 11:18:21, time: 1.230, data_time: 0.011, memory: 9807, decode.loss_seg: 0.2017, decode.acc_seg: 84.5402, src.loss_imnet_feat_dist: 0.1142, mix.decode.loss_seg: 0.1674, mix.decode.acc_seg: 88.4590, masked.decode.loss_seg: 0.1689, masked.decode.acc_seg: 90.6965
2023-01-10 16:25:18,479 - mmseg - INFO - Iter [7250/40000]	lr: 4.913e-05, eta: 11:17:16, time: 1.229, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1694, decode.acc_seg: 85.7434, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1794, mix.decode.acc_seg: 88.6216, masked.decode.loss_seg: 0.1695, masked.decode.acc_seg: 90.7078
2023-01-10 16:26:20,090 - mmseg - INFO - Iter [7300/40000]	lr: 4.905e-05, eta: 11:16:12, time: 1.232, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1774, decode.acc_seg: 86.5147, src.loss_imnet_feat_dist: 0.1157, mix.decode.loss_seg: 0.1812, mix.decode.acc_seg: 89.2234, masked.decode.loss_seg: 0.1744, masked.decode.acc_seg: 90.3623
2023-01-10 16:27:21,337 - mmseg - INFO - Iter [7350/40000]	lr: 4.898e-05, eta: 11:15:06, time: 1.225, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1631, decode.acc_seg: 85.4930, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1587, mix.decode.acc_seg: 87.7959, masked.decode.loss_seg: 0.1679, masked.decode.acc_seg: 90.1207
2023-01-10 16:28:22,821 - mmseg - INFO - Iter [7400/40000]	lr: 4.890e-05, eta: 11:14:02, time: 1.230, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1631, decode.acc_seg: 86.8987, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1514, mix.decode.acc_seg: 89.5401, masked.decode.loss_seg: 0.1695, masked.decode.acc_seg: 91.1635
2023-01-10 16:29:23,922 - mmseg - INFO - Iter [7450/40000]	lr: 4.883e-05, eta: 11:12:56, time: 1.222, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1494, decode.acc_seg: 88.2035, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1527, mix.decode.acc_seg: 89.4800, masked.decode.loss_seg: 0.1800, masked.decode.acc_seg: 89.7555
2023-01-10 16:30:25,078 - mmseg - INFO - Iter [7500/40000]	lr: 4.875e-05, eta: 11:11:50, time: 1.223, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1616, decode.acc_seg: 85.5031, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1711, mix.decode.acc_seg: 88.8684, masked.decode.loss_seg: 0.1831, masked.decode.acc_seg: 90.1757
2023-01-10 16:31:26,360 - mmseg - INFO - Iter [7550/40000]	lr: 4.868e-05, eta: 11:10:45, time: 1.226, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1694, decode.acc_seg: 87.0717, src.loss_imnet_feat_dist: 0.1179, mix.decode.loss_seg: 0.1816, mix.decode.acc_seg: 90.0444, masked.decode.loss_seg: 0.1731, masked.decode.acc_seg: 91.0721
2023-01-10 16:32:27,588 - mmseg - INFO - Iter [7600/40000]	lr: 4.860e-05, eta: 11:09:40, time: 1.225, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1640, decode.acc_seg: 87.2189, src.loss_imnet_feat_dist: 0.1143, mix.decode.loss_seg: 0.1659, mix.decode.acc_seg: 89.7746, masked.decode.loss_seg: 0.1657, masked.decode.acc_seg: 90.9182
2023-01-10 16:33:29,012 - mmseg - INFO - Iter [7650/40000]	lr: 4.853e-05, eta: 11:08:35, time: 1.228, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1628, decode.acc_seg: 88.7473, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1716, mix.decode.acc_seg: 89.5260, masked.decode.loss_seg: 0.1809, masked.decode.acc_seg: 90.7876
2023-01-10 16:34:30,280 - mmseg - INFO - Iter [7700/40000]	lr: 4.845e-05, eta: 11:07:30, time: 1.225, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1970, decode.acc_seg: 84.6677, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1878, mix.decode.acc_seg: 86.9143, masked.decode.loss_seg: 0.1776, masked.decode.acc_seg: 90.8074
2023-01-10 16:35:31,492 - mmseg - INFO - Iter [7750/40000]	lr: 4.838e-05, eta: 11:06:25, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1567, decode.acc_seg: 87.6346, src.loss_imnet_feat_dist: 0.1223, mix.decode.loss_seg: 0.1717, mix.decode.acc_seg: 88.0197, masked.decode.loss_seg: 0.1835, masked.decode.acc_seg: 89.5469
2023-01-10 16:36:32,703 - mmseg - INFO - Iter [7800/40000]	lr: 4.830e-05, eta: 11:05:20, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1603, decode.acc_seg: 87.5384, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1581, mix.decode.acc_seg: 88.2750, masked.decode.loss_seg: 0.1983, masked.decode.acc_seg: 88.8446
2023-01-10 16:37:34,160 - mmseg - INFO - Iter [7850/40000]	lr: 4.823e-05, eta: 11:04:15, time: 1.229, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1753, decode.acc_seg: 87.4513, src.loss_imnet_feat_dist: 0.1207, mix.decode.loss_seg: 0.1690, mix.decode.acc_seg: 88.9900, masked.decode.loss_seg: 0.1717, masked.decode.acc_seg: 90.4899
2023-01-10 16:38:35,419 - mmseg - INFO - Iter [7900/40000]	lr: 4.815e-05, eta: 11:03:11, time: 1.225, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1629, decode.acc_seg: 87.2510, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1701, mix.decode.acc_seg: 88.0461, masked.decode.loss_seg: 0.1829, masked.decode.acc_seg: 89.6488
2023-01-10 16:39:36,706 - mmseg - INFO - Iter [7950/40000]	lr: 4.808e-05, eta: 11:02:06, time: 1.226, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1584, decode.acc_seg: 86.5905, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1664, mix.decode.acc_seg: 87.3095, masked.decode.loss_seg: 0.1733, masked.decode.acc_seg: 90.3324
2023-01-10 16:41:52,422 - mmseg - INFO - per class results:
2023-01-10 16:41:52,446 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      road     |  95.5 | 98.73 |
|    sidewalk   | 68.53 | 76.87 |
|    building   | 88.16 | 93.59 |
|      wall     | 48.14 | 66.83 |
|     fence     | 30.17 | 32.24 |
|      pole     | 43.21 | 52.26 |
| traffic light | 46.94 | 67.58 |
|  traffic sign | 54.36 |  62.2 |
|   vegetation  |  88.6 | 94.46 |
|    terrain    | 48.89 | 60.55 |
|      sky      |  87.1 |  99.5 |
|     person    | 67.08 | 78.56 |
|     rider     | 39.48 | 57.27 |
|      car      | 89.64 | 96.77 |
|     truck     | 74.12 | 82.78 |
|      bus      | 64.57 | 77.97 |
|     train     | 44.77 | 51.78 |
|   motorcycle  | 50.12 | 65.74 |
|    bicycle    | 60.38 | 81.89 |
+---------------+-------+-------+
2023-01-10 16:41:52,446 - mmseg - INFO - Summary:
2023-01-10 16:41:52,447 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 92.81 | 62.62 | 73.56 |
+-------+-------+-------+
2023-01-10 16:41:52,455 - mmseg - INFO - Exp name: 230110_1355_230110_1343_gta2cs_dacs_a999_fdthings_rcs001_cpl_m32-07-spta_daformer_sepaspp_mitb5_poly10warm_s0_2feea_f2bea
2023-01-10 16:41:52,456 - mmseg - INFO - Iter [500/40000]	lr: 4.800e-05, eta: 11:01:02, time: 1.228, data_time: 0.011, memory: 9807, aAcc: 0.9281, mIoU: 0.6262, mAcc: 0.7356, IoU.road: 0.9550, IoU.sidewalk: 0.6853, IoU.building: 0.8816, IoU.wall: 0.4814, IoU.fence: 0.3017, IoU.pole: 0.4321, IoU.traffic light: 0.4694, IoU.traffic sign: 0.5436, IoU.vegetation: 0.8860, IoU.terrain: 0.4889, IoU.sky: 0.8710, IoU.person: 0.6708, IoU.rider: 0.3948, IoU.car: 0.8964, IoU.truck: 0.7412, IoU.bus: 0.6457, IoU.train: 0.4477, IoU.motorcycle: 0.5012, IoU.bicycle: 0.6038, Acc.road: 0.9873, Acc.sidewalk: 0.7687, Acc.building: 0.9359, Acc.wall: 0.6683, Acc.fence: 0.3224, Acc.pole: 0.5226, Acc.traffic light: 0.6758, Acc.traffic sign: 0.6220, Acc.vegetation: 0.9446, Acc.terrain: 0.6055, Acc.sky: 0.9950, Acc.person: 0.7856, Acc.rider: 0.5727, Acc.car: 0.9677, Acc.truck: 0.8278, Acc.bus: 0.7797, Acc.train: 0.5178, Acc.motorcycle: 0.6574, Acc.bicycle: 0.8189, decode.loss_seg: 0.1812, decode.acc_seg: 86.2756, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1908, mix.decode.acc_seg: 87.9509, masked.decode.loss_seg: 0.1732, masked.decode.acc_seg: 90.1242
2023-01-10 16:42:59,307 - mmseg - INFO - Iter [8050/40000]	lr: 4.793e-05, eta: 11:05:14, time: 2.824, data_time: 1.499, memory: 9807, decode.loss_seg: 0.1826, decode.acc_seg: 84.1181, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.2067, mix.decode.acc_seg: 86.4751, masked.decode.loss_seg: 0.1763, masked.decode.acc_seg: 90.4738
2023-01-10 16:44:03,245 - mmseg - INFO - Iter [8100/40000]	lr: 4.785e-05, eta: 11:04:17, time: 1.279, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1665, decode.acc_seg: 86.7912, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1779, mix.decode.acc_seg: 88.6603, masked.decode.loss_seg: 0.1824, masked.decode.acc_seg: 89.5191
2023-01-10 16:45:06,507 - mmseg - INFO - Iter [8150/40000]	lr: 4.778e-05, eta: 11:03:18, time: 1.265, data_time: 0.013, memory: 9807, decode.loss_seg: 0.1465, decode.acc_seg: 86.6130, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1572, mix.decode.acc_seg: 88.9009, masked.decode.loss_seg: 0.1934, masked.decode.acc_seg: 89.6938
2023-01-10 16:46:09,914 - mmseg - INFO - Iter [8200/40000]	lr: 4.770e-05, eta: 11:02:19, time: 1.268, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1643, decode.acc_seg: 85.5617, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1700, mix.decode.acc_seg: 88.5290, masked.decode.loss_seg: 0.1885, masked.decode.acc_seg: 89.1116
2023-01-10 16:47:13,217 - mmseg - INFO - Iter [8250/40000]	lr: 4.763e-05, eta: 11:01:20, time: 1.266, data_time: 0.013, memory: 9807, decode.loss_seg: 0.1501, decode.acc_seg: 85.8652, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1754, mix.decode.acc_seg: 87.6374, masked.decode.loss_seg: 0.1828, masked.decode.acc_seg: 90.0353
2023-01-10 16:48:16,607 - mmseg - INFO - Iter [8300/40000]	lr: 4.755e-05, eta: 11:00:21, time: 1.268, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1795, decode.acc_seg: 84.3588, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1939, mix.decode.acc_seg: 88.5573, masked.decode.loss_seg: 0.1841, masked.decode.acc_seg: 90.0278
2023-01-10 16:49:19,601 - mmseg - INFO - Iter [8350/40000]	lr: 4.748e-05, eta: 10:59:20, time: 1.260, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1531, decode.acc_seg: 87.2806, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1631, mix.decode.acc_seg: 88.7819, masked.decode.loss_seg: 0.1895, masked.decode.acc_seg: 90.1372
2023-01-10 16:50:22,883 - mmseg - INFO - Iter [8400/40000]	lr: 4.740e-05, eta: 10:58:21, time: 1.266, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1570, decode.acc_seg: 87.1481, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1589, mix.decode.acc_seg: 88.9155, masked.decode.loss_seg: 0.1655, masked.decode.acc_seg: 90.9303
2023-01-10 16:51:26,337 - mmseg - INFO - Iter [8450/40000]	lr: 4.733e-05, eta: 10:57:22, time: 1.269, data_time: 0.013, memory: 9807, decode.loss_seg: 0.1441, decode.acc_seg: 88.4371, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1512, mix.decode.acc_seg: 89.2267, masked.decode.loss_seg: 0.1705, masked.decode.acc_seg: 90.5180
2023-01-10 16:52:29,614 - mmseg - INFO - Iter [8500/40000]	lr: 4.725e-05, eta: 10:56:22, time: 1.266, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1638, decode.acc_seg: 86.7575, src.loss_imnet_feat_dist: 0.1230, mix.decode.loss_seg: 0.1603, mix.decode.acc_seg: 88.8855, masked.decode.loss_seg: 0.1676, masked.decode.acc_seg: 90.4817
2023-01-10 16:53:32,682 - mmseg - INFO - Iter [8550/40000]	lr: 4.718e-05, eta: 10:55:21, time: 1.261, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1646, decode.acc_seg: 86.2909, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1636, mix.decode.acc_seg: 89.4566, masked.decode.loss_seg: 0.1725, masked.decode.acc_seg: 90.4793
2023-01-10 16:54:35,900 - mmseg - INFO - Iter [8600/40000]	lr: 4.710e-05, eta: 10:54:21, time: 1.264, data_time: 0.013, memory: 9807, decode.loss_seg: 0.2058, decode.acc_seg: 85.6305, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.2442, mix.decode.acc_seg: 86.8106, masked.decode.loss_seg: 0.1903, masked.decode.acc_seg: 89.4851
2023-01-10 16:55:39,041 - mmseg - INFO - Iter [8650/40000]	lr: 4.703e-05, eta: 10:53:21, time: 1.263, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1864, decode.acc_seg: 85.2987, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1902, mix.decode.acc_seg: 87.0090, masked.decode.loss_seg: 0.1945, masked.decode.acc_seg: 89.1144
2023-01-10 16:56:42,214 - mmseg - INFO - Iter [8700/40000]	lr: 4.695e-05, eta: 10:52:21, time: 1.263, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1602, decode.acc_seg: 86.3404, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1538, mix.decode.acc_seg: 87.8561, masked.decode.loss_seg: 0.1816, masked.decode.acc_seg: 89.8306
2023-01-10 16:57:45,691 - mmseg - INFO - Iter [8750/40000]	lr: 4.688e-05, eta: 10:51:22, time: 1.270, data_time: 0.013, memory: 9807, decode.loss_seg: 0.1389, decode.acc_seg: 87.0306, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1486, mix.decode.acc_seg: 88.9144, masked.decode.loss_seg: 0.1666, masked.decode.acc_seg: 90.7546
2023-01-10 16:58:48,954 - mmseg - INFO - Iter [8800/40000]	lr: 4.680e-05, eta: 10:50:22, time: 1.265, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1749, decode.acc_seg: 86.1326, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.2026, mix.decode.acc_seg: 88.3385, masked.decode.loss_seg: 0.1649, masked.decode.acc_seg: 90.4045
2023-01-10 16:59:52,229 - mmseg - INFO - Iter [8850/40000]	lr: 4.673e-05, eta: 10:49:22, time: 1.265, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1640, decode.acc_seg: 88.3284, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.2048, mix.decode.acc_seg: 88.9815, masked.decode.loss_seg: 0.1820, masked.decode.acc_seg: 89.6565
2023-01-10 17:00:55,454 - mmseg - INFO - Iter [8900/40000]	lr: 4.665e-05, eta: 10:48:22, time: 1.264, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1633, decode.acc_seg: 86.2755, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1540, mix.decode.acc_seg: 88.4390, masked.decode.loss_seg: 0.1712, masked.decode.acc_seg: 89.7451
2023-01-10 17:01:58,569 - mmseg - INFO - Iter [8950/40000]	lr: 4.658e-05, eta: 10:47:21, time: 1.262, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1433, decode.acc_seg: 88.9887, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1672, mix.decode.acc_seg: 89.1572, masked.decode.loss_seg: 0.1728, masked.decode.acc_seg: 90.1392
2023-01-10 17:03:01,552 - mmseg - INFO - Exp name: 230110_1355_230110_1343_gta2cs_dacs_a999_fdthings_rcs001_cpl_m32-07-spta_daformer_sepaspp_mitb5_poly10warm_s0_2feea_f2bea
2023-01-10 17:03:01,582 - mmseg - INFO - Iter [9000/40000]	lr: 4.650e-05, eta: 10:46:20, time: 1.260, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1665, decode.acc_seg: 85.4938, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1590, mix.decode.acc_seg: 88.3137, masked.decode.loss_seg: 0.1743, masked.decode.acc_seg: 89.7875
2023-01-10 17:04:11,425 - mmseg - INFO - Iter [9050/40000]	lr: 4.643e-05, eta: 10:45:43, time: 1.397, data_time: 0.013, memory: 9807, decode.loss_seg: 0.1718, decode.acc_seg: 88.0194, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1562, mix.decode.acc_seg: 90.1675, masked.decode.loss_seg: 0.1732, masked.decode.acc_seg: 90.5171
2023-01-10 17:05:14,771 - mmseg - INFO - Iter [9100/40000]	lr: 4.635e-05, eta: 10:44:43, time: 1.267, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1357, decode.acc_seg: 87.5275, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1585, mix.decode.acc_seg: 89.5906, masked.decode.loss_seg: 0.1742, masked.decode.acc_seg: 90.9477
2023-01-10 17:06:17,939 - mmseg - INFO - Iter [9150/40000]	lr: 4.628e-05, eta: 10:43:42, time: 1.263, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1908, decode.acc_seg: 85.2322, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1908, mix.decode.acc_seg: 87.6130, masked.decode.loss_seg: 0.1725, masked.decode.acc_seg: 91.1007
2023-01-10 17:07:21,176 - mmseg - INFO - Iter [9200/40000]	lr: 4.620e-05, eta: 10:42:42, time: 1.265, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1456, decode.acc_seg: 86.7470, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1533, mix.decode.acc_seg: 89.4605, masked.decode.loss_seg: 0.1742, masked.decode.acc_seg: 90.8117
2023-01-10 17:08:24,226 - mmseg - INFO - Iter [9250/40000]	lr: 4.613e-05, eta: 10:41:41, time: 1.261, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1408, decode.acc_seg: 87.3186, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1519, mix.decode.acc_seg: 88.2272, masked.decode.loss_seg: 0.1647, masked.decode.acc_seg: 91.0753
2023-01-10 17:09:27,395 - mmseg - INFO - Iter [9300/40000]	lr: 4.605e-05, eta: 10:40:40, time: 1.263, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1634, decode.acc_seg: 86.2384, src.loss_imnet_feat_dist: 0.1179, mix.decode.loss_seg: 0.1569, mix.decode.acc_seg: 89.1039, masked.decode.loss_seg: 0.1733, masked.decode.acc_seg: 90.3967
2023-01-10 17:10:30,601 - mmseg - INFO - Iter [9350/40000]	lr: 4.598e-05, eta: 10:39:39, time: 1.264, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1697, decode.acc_seg: 86.7204, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1777, mix.decode.acc_seg: 89.6465, masked.decode.loss_seg: 0.1726, masked.decode.acc_seg: 90.8586
2023-01-10 17:11:33,639 - mmseg - INFO - Iter [9400/40000]	lr: 4.590e-05, eta: 10:38:38, time: 1.261, data_time: 0.012, memory: 9807, decode.loss_seg: 0.2356, decode.acc_seg: 86.2048, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1651, mix.decode.acc_seg: 88.9415, masked.decode.loss_seg: 0.1671, masked.decode.acc_seg: 90.9385
2023-01-10 17:12:36,826 - mmseg - INFO - Iter [9450/40000]	lr: 4.583e-05, eta: 10:37:37, time: 1.264, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1603, decode.acc_seg: 86.5210, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1820, mix.decode.acc_seg: 88.8643, masked.decode.loss_seg: 0.1762, masked.decode.acc_seg: 90.8617
2023-01-10 17:13:40,271 - mmseg - INFO - Iter [9500/40000]	lr: 4.575e-05, eta: 10:36:37, time: 1.269, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1410, decode.acc_seg: 87.1875, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1597, mix.decode.acc_seg: 88.8645, masked.decode.loss_seg: 0.1757, masked.decode.acc_seg: 90.4412
2023-01-10 17:14:43,826 - mmseg - INFO - Iter [9550/40000]	lr: 4.568e-05, eta: 10:35:38, time: 1.271, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1578, decode.acc_seg: 87.6399, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1572, mix.decode.acc_seg: 89.8905, masked.decode.loss_seg: 0.1757, masked.decode.acc_seg: 90.4985
2023-01-10 17:15:47,033 - mmseg - INFO - Iter [9600/40000]	lr: 4.560e-05, eta: 10:34:37, time: 1.264, data_time: 0.012, memory: 9807, decode.loss_seg: 0.2154, decode.acc_seg: 85.1397, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1992, mix.decode.acc_seg: 87.6139, masked.decode.loss_seg: 0.1842, masked.decode.acc_seg: 89.5669
2023-01-10 17:16:50,289 - mmseg - INFO - Iter [9650/40000]	lr: 4.553e-05, eta: 10:33:36, time: 1.265, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1476, decode.acc_seg: 87.9860, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1621, mix.decode.acc_seg: 89.2778, masked.decode.loss_seg: 0.1805, masked.decode.acc_seg: 90.0941
2023-01-10 17:17:53,659 - mmseg - INFO - Iter [9700/40000]	lr: 4.545e-05, eta: 10:32:36, time: 1.267, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1576, decode.acc_seg: 86.4487, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1651, mix.decode.acc_seg: 89.2600, masked.decode.loss_seg: 0.1849, masked.decode.acc_seg: 90.1293
2023-01-10 17:18:56,861 - mmseg - INFO - Iter [9750/40000]	lr: 4.538e-05, eta: 10:31:35, time: 1.264, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1839, decode.acc_seg: 87.2653, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1748, mix.decode.acc_seg: 89.6116, masked.decode.loss_seg: 0.1695, masked.decode.acc_seg: 90.5963
2023-01-10 17:20:00,064 - mmseg - INFO - Iter [9800/40000]	lr: 4.530e-05, eta: 10:30:34, time: 1.264, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1609, decode.acc_seg: 87.1850, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1551, mix.decode.acc_seg: 90.4845, masked.decode.loss_seg: 0.1630, masked.decode.acc_seg: 90.9003
2023-01-10 17:21:03,345 - mmseg - INFO - Iter [9850/40000]	lr: 4.523e-05, eta: 10:29:33, time: 1.266, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1454, decode.acc_seg: 87.0657, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1520, mix.decode.acc_seg: 89.6706, masked.decode.loss_seg: 0.1723, masked.decode.acc_seg: 90.4995
2023-01-10 17:22:05,333 - mmseg - INFO - Iter [9900/40000]	lr: 4.515e-05, eta: 10:28:29, time: 1.240, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1390, decode.acc_seg: 87.0767, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1500, mix.decode.acc_seg: 89.1971, masked.decode.loss_seg: 0.1676, masked.decode.acc_seg: 90.3181
2023-01-10 17:23:06,227 - mmseg - INFO - Iter [9950/40000]	lr: 4.508e-05, eta: 10:27:21, time: 1.218, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1504, decode.acc_seg: 86.8481, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1673, mix.decode.acc_seg: 88.5990, masked.decode.loss_seg: 0.1707, masked.decode.acc_seg: 91.2382
2023-01-10 17:24:07,501 - mmseg - INFO - Exp name: 230110_1355_230110_1343_gta2cs_dacs_a999_fdthings_rcs001_cpl_m32-07-spta_daformer_sepaspp_mitb5_poly10warm_s0_2feea_f2bea
2023-01-10 17:24:07,501 - mmseg - INFO - Iter [10000/40000]	lr: 4.500e-05, eta: 10:26:14, time: 1.225, data_time: 0.010, memory: 9807, decode.loss_seg: 0.1647, decode.acc_seg: 87.3504, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1737, mix.decode.acc_seg: 88.7234, masked.decode.loss_seg: 0.1753, masked.decode.acc_seg: 90.5901
2023-01-10 17:25:12,617 - mmseg - INFO - Iter [10050/40000]	lr: 4.493e-05, eta: 10:25:19, time: 1.302, data_time: 0.010, memory: 9807, decode.loss_seg: 0.1589, decode.acc_seg: 87.1254, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1580, mix.decode.acc_seg: 89.3498, masked.decode.loss_seg: 0.1779, masked.decode.acc_seg: 90.3393
2023-01-10 17:26:13,587 - mmseg - INFO - Iter [10100/40000]	lr: 4.485e-05, eta: 10:24:11, time: 1.219, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1677, decode.acc_seg: 86.9261, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1704, mix.decode.acc_seg: 88.9785, masked.decode.loss_seg: 0.1745, masked.decode.acc_seg: 91.2199
2023-01-10 17:27:14,785 - mmseg - INFO - Iter [10150/40000]	lr: 4.478e-05, eta: 10:23:05, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1516, decode.acc_seg: 87.0208, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1648, mix.decode.acc_seg: 89.1608, masked.decode.loss_seg: 0.1733, masked.decode.acc_seg: 90.0781
2023-01-10 17:28:16,062 - mmseg - INFO - Iter [10200/40000]	lr: 4.470e-05, eta: 10:21:58, time: 1.226, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1524, decode.acc_seg: 87.5275, src.loss_imnet_feat_dist: 0.1176, mix.decode.loss_seg: 0.1506, mix.decode.acc_seg: 89.3823, masked.decode.loss_seg: 0.1661, masked.decode.acc_seg: 90.5477
2023-01-10 17:29:17,482 - mmseg - INFO - Iter [10250/40000]	lr: 4.463e-05, eta: 10:20:52, time: 1.228, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1475, decode.acc_seg: 86.5419, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1693, mix.decode.acc_seg: 87.7611, masked.decode.loss_seg: 0.1825, masked.decode.acc_seg: 90.3252
2023-01-10 17:30:18,682 - mmseg - INFO - Iter [10300/40000]	lr: 4.455e-05, eta: 10:19:45, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1560, decode.acc_seg: 87.7553, src.loss_imnet_feat_dist: 0.1177, mix.decode.loss_seg: 0.1660, mix.decode.acc_seg: 89.0686, masked.decode.loss_seg: 0.1627, masked.decode.acc_seg: 91.1645
2023-01-10 17:31:20,068 - mmseg - INFO - Iter [10350/40000]	lr: 4.448e-05, eta: 10:18:39, time: 1.228, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1418, decode.acc_seg: 89.0646, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1475, mix.decode.acc_seg: 90.4278, masked.decode.loss_seg: 0.1759, masked.decode.acc_seg: 91.1017
2023-01-10 17:32:21,406 - mmseg - INFO - Iter [10400/40000]	lr: 4.440e-05, eta: 10:17:33, time: 1.227, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1483, decode.acc_seg: 87.6325, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1497, mix.decode.acc_seg: 89.4854, masked.decode.loss_seg: 0.1821, masked.decode.acc_seg: 90.2402
2023-01-10 17:33:22,840 - mmseg - INFO - Iter [10450/40000]	lr: 4.433e-05, eta: 10:16:27, time: 1.229, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1415, decode.acc_seg: 88.0731, src.loss_imnet_feat_dist: 0.1196, mix.decode.loss_seg: 0.1486, mix.decode.acc_seg: 90.9543, masked.decode.loss_seg: 0.1771, masked.decode.acc_seg: 90.5879
2023-01-10 17:34:24,000 - mmseg - INFO - Iter [10500/40000]	lr: 4.425e-05, eta: 10:15:21, time: 1.223, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1460, decode.acc_seg: 86.4906, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1420, mix.decode.acc_seg: 89.0404, masked.decode.loss_seg: 0.1732, masked.decode.acc_seg: 90.1932
2023-01-10 17:35:25,421 - mmseg - INFO - Iter [10550/40000]	lr: 4.418e-05, eta: 10:14:15, time: 1.228, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1597, decode.acc_seg: 86.6895, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1394, mix.decode.acc_seg: 90.0207, masked.decode.loss_seg: 0.1736, masked.decode.acc_seg: 90.8255
2023-01-10 17:36:26,696 - mmseg - INFO - Iter [10600/40000]	lr: 4.410e-05, eta: 10:13:09, time: 1.225, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1347, decode.acc_seg: 87.3466, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1545, mix.decode.acc_seg: 89.7232, masked.decode.loss_seg: 0.1659, masked.decode.acc_seg: 90.6756
2023-01-10 17:37:27,762 - mmseg - INFO - Iter [10650/40000]	lr: 4.403e-05, eta: 10:12:02, time: 1.221, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1294, decode.acc_seg: 87.6168, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1501, mix.decode.acc_seg: 89.7854, masked.decode.loss_seg: 0.1788, masked.decode.acc_seg: 90.2885
2023-01-10 17:38:28,738 - mmseg - INFO - Iter [10700/40000]	lr: 4.395e-05, eta: 10:10:55, time: 1.219, data_time: 0.010, memory: 9807, decode.loss_seg: 0.1287, decode.acc_seg: 87.5226, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1525, mix.decode.acc_seg: 89.3518, masked.decode.loss_seg: 0.1687, masked.decode.acc_seg: 90.9851
2023-01-10 17:39:29,885 - mmseg - INFO - Iter [10750/40000]	lr: 4.388e-05, eta: 10:09:49, time: 1.223, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1338, decode.acc_seg: 88.0552, src.loss_imnet_feat_dist: 0.1177, mix.decode.loss_seg: 0.1473, mix.decode.acc_seg: 89.5426, masked.decode.loss_seg: 0.1806, masked.decode.acc_seg: 90.5098
2023-01-10 17:40:31,014 - mmseg - INFO - Iter [10800/40000]	lr: 4.380e-05, eta: 10:08:42, time: 1.223, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1481, decode.acc_seg: 86.3282, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1533, mix.decode.acc_seg: 88.4371, masked.decode.loss_seg: 0.1874, masked.decode.acc_seg: 89.7308
2023-01-10 17:41:31,900 - mmseg - INFO - Iter [10850/40000]	lr: 4.373e-05, eta: 10:07:35, time: 1.218, data_time: 0.010, memory: 9807, decode.loss_seg: 0.1268, decode.acc_seg: 85.4649, src.loss_imnet_feat_dist: 0.1080, mix.decode.loss_seg: 0.1347, mix.decode.acc_seg: 87.5906, masked.decode.loss_seg: 0.1747, masked.decode.acc_seg: 90.8281
2023-01-10 17:42:33,487 - mmseg - INFO - Iter [10900/40000]	lr: 4.365e-05, eta: 10:06:30, time: 1.232, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1282, decode.acc_seg: 87.7310, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1489, mix.decode.acc_seg: 89.3196, masked.decode.loss_seg: 0.1684, masked.decode.acc_seg: 91.1623
2023-01-10 17:43:34,474 - mmseg - INFO - Iter [10950/40000]	lr: 4.358e-05, eta: 10:05:24, time: 1.220, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1309, decode.acc_seg: 86.9946, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1420, mix.decode.acc_seg: 88.7518, masked.decode.loss_seg: 0.1741, masked.decode.acc_seg: 91.1546
2023-01-10 17:44:35,411 - mmseg - INFO - Exp name: 230110_1355_230110_1343_gta2cs_dacs_a999_fdthings_rcs001_cpl_m32-07-spta_daformer_sepaspp_mitb5_poly10warm_s0_2feea_f2bea
2023-01-10 17:44:35,411 - mmseg - INFO - Iter [11000/40000]	lr: 4.350e-05, eta: 10:04:17, time: 1.219, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1294, decode.acc_seg: 88.3979, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1389, mix.decode.acc_seg: 91.1912, masked.decode.loss_seg: 0.1648, masked.decode.acc_seg: 91.6619
2023-01-10 17:45:40,547 - mmseg - INFO - Iter [11050/40000]	lr: 4.343e-05, eta: 10:03:21, time: 1.303, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1675, decode.acc_seg: 84.6376, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1734, mix.decode.acc_seg: 86.2315, masked.decode.loss_seg: 0.1767, masked.decode.acc_seg: 89.5271
2023-01-10 17:46:41,532 - mmseg - INFO - Iter [11100/40000]	lr: 4.335e-05, eta: 10:02:15, time: 1.220, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1276, decode.acc_seg: 87.4360, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1450, mix.decode.acc_seg: 89.1751, masked.decode.loss_seg: 0.1755, masked.decode.acc_seg: 90.5227
2023-01-10 17:47:42,817 - mmseg - INFO - Iter [11150/40000]	lr: 4.328e-05, eta: 10:01:09, time: 1.226, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1333, decode.acc_seg: 88.1521, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1574, mix.decode.acc_seg: 88.8411, masked.decode.loss_seg: 0.1853, masked.decode.acc_seg: 89.8661
2023-01-10 17:48:44,053 - mmseg - INFO - Iter [11200/40000]	lr: 4.320e-05, eta: 10:00:03, time: 1.225, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1415, decode.acc_seg: 88.8623, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1585, mix.decode.acc_seg: 90.6258, masked.decode.loss_seg: 0.1663, masked.decode.acc_seg: 90.8173
2023-01-10 17:49:45,484 - mmseg - INFO - Iter [11250/40000]	lr: 4.313e-05, eta: 9:58:58, time: 1.229, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1438, decode.acc_seg: 87.5681, src.loss_imnet_feat_dist: 0.1191, mix.decode.loss_seg: 0.1483, mix.decode.acc_seg: 90.4314, masked.decode.loss_seg: 0.1657, masked.decode.acc_seg: 90.6267
2023-01-10 17:50:47,104 - mmseg - INFO - Iter [11300/40000]	lr: 4.305e-05, eta: 9:57:53, time: 1.232, data_time: 0.018, memory: 9807, decode.loss_seg: 0.1302, decode.acc_seg: 86.6498, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1446, mix.decode.acc_seg: 89.4015, masked.decode.loss_seg: 0.1767, masked.decode.acc_seg: 90.8083
2023-01-10 17:51:48,370 - mmseg - INFO - Iter [11350/40000]	lr: 4.298e-05, eta: 9:56:48, time: 1.225, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1654, decode.acc_seg: 86.6512, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1702, mix.decode.acc_seg: 88.7957, masked.decode.loss_seg: 0.1718, masked.decode.acc_seg: 90.9488
2023-01-10 17:52:49,471 - mmseg - INFO - Iter [11400/40000]	lr: 4.290e-05, eta: 9:55:42, time: 1.222, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1609, decode.acc_seg: 85.8532, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1525, mix.decode.acc_seg: 88.2245, masked.decode.loss_seg: 0.1728, masked.decode.acc_seg: 90.1094
2023-01-10 17:53:50,572 - mmseg - INFO - Iter [11450/40000]	lr: 4.283e-05, eta: 9:54:36, time: 1.222, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1671, decode.acc_seg: 88.1222, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.2010, mix.decode.acc_seg: 88.9500, masked.decode.loss_seg: 0.2068, masked.decode.acc_seg: 90.5674
2023-01-10 17:54:51,684 - mmseg - INFO - Iter [11500/40000]	lr: 4.275e-05, eta: 9:53:30, time: 1.222, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1291, decode.acc_seg: 87.6620, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1555, mix.decode.acc_seg: 90.5534, masked.decode.loss_seg: 0.1784, masked.decode.acc_seg: 90.6244
2023-01-10 17:55:52,546 - mmseg - INFO - Iter [11550/40000]	lr: 4.268e-05, eta: 9:52:23, time: 1.217, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1265, decode.acc_seg: 88.0605, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1356, mix.decode.acc_seg: 90.4736, masked.decode.loss_seg: 0.1561, masked.decode.acc_seg: 91.7316
2023-01-10 17:56:53,975 - mmseg - INFO - Iter [11600/40000]	lr: 4.260e-05, eta: 9:51:18, time: 1.229, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1377, decode.acc_seg: 87.2359, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1503, mix.decode.acc_seg: 88.7401, masked.decode.loss_seg: 0.1677, masked.decode.acc_seg: 91.6002
2023-01-10 17:57:55,161 - mmseg - INFO - Iter [11650/40000]	lr: 4.253e-05, eta: 9:50:13, time: 1.224, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1534, decode.acc_seg: 86.6392, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1553, mix.decode.acc_seg: 89.2906, masked.decode.loss_seg: 0.1730, masked.decode.acc_seg: 90.9937
2023-01-10 17:58:56,129 - mmseg - INFO - Iter [11700/40000]	lr: 4.245e-05, eta: 9:49:07, time: 1.219, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1503, decode.acc_seg: 87.8826, src.loss_imnet_feat_dist: 0.1125, mix.decode.loss_seg: 0.1651, mix.decode.acc_seg: 90.6431, masked.decode.loss_seg: 0.1783, masked.decode.acc_seg: 90.9715
2023-01-10 17:59:57,730 - mmseg - INFO - Iter [11750/40000]	lr: 4.238e-05, eta: 9:48:02, time: 1.232, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1641, decode.acc_seg: 87.6057, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1557, mix.decode.acc_seg: 90.4389, masked.decode.loss_seg: 0.1777, masked.decode.acc_seg: 90.6992
2023-01-10 18:00:59,242 - mmseg - INFO - Iter [11800/40000]	lr: 4.230e-05, eta: 9:46:58, time: 1.230, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1324, decode.acc_seg: 87.5144, src.loss_imnet_feat_dist: 0.1107, mix.decode.loss_seg: 0.1623, mix.decode.acc_seg: 89.4088, masked.decode.loss_seg: 0.1861, masked.decode.acc_seg: 90.9583
2023-01-10 18:02:00,354 - mmseg - INFO - Iter [11850/40000]	lr: 4.223e-05, eta: 9:45:52, time: 1.222, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1552, decode.acc_seg: 85.8827, src.loss_imnet_feat_dist: 0.1166, mix.decode.loss_seg: 0.1622, mix.decode.acc_seg: 89.2602, masked.decode.loss_seg: 0.1675, masked.decode.acc_seg: 91.8216
2023-01-10 18:03:01,352 - mmseg - INFO - Iter [11900/40000]	lr: 4.215e-05, eta: 9:44:46, time: 1.220, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1552, decode.acc_seg: 86.5617, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1656, mix.decode.acc_seg: 88.9012, masked.decode.loss_seg: 0.1794, masked.decode.acc_seg: 90.8172
2023-01-10 18:04:02,568 - mmseg - INFO - Iter [11950/40000]	lr: 4.208e-05, eta: 9:43:41, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1356, decode.acc_seg: 86.7026, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1366, mix.decode.acc_seg: 90.0083, masked.decode.loss_seg: 0.1700, masked.decode.acc_seg: 91.0993
2023-01-10 18:06:17,324 - mmseg - INFO - per class results:
2023-01-10 18:06:17,374 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      road     | 95.87 | 98.84 |
|    sidewalk   | 70.59 | 78.81 |
|    building   |  88.0 | 93.37 |
|      wall     | 53.41 | 68.32 |
|     fence     |  28.9 | 30.69 |
|      pole     | 45.25 | 53.19 |
| traffic light | 52.05 | 65.09 |
|  traffic sign | 55.51 | 60.47 |
|   vegetation  |  88.9 | 95.54 |
|    terrain    | 50.34 | 60.96 |
|      sky      | 87.33 | 99.49 |
|     person    | 69.56 | 81.36 |
|     rider     | 41.52 | 60.44 |
|      car      | 90.92 | 96.27 |
|     truck     | 74.38 | 86.78 |
|      bus      | 75.59 | 83.51 |
|     train     | 70.29 | 75.83 |
|   motorcycle  | 47.99 | 62.75 |
|    bicycle    | 59.13 | 84.28 |
+---------------+-------+-------+
2023-01-10 18:06:17,375 - mmseg - INFO - Summary:
2023-01-10 18:06:17,375 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 93.18 | 65.55 | 75.58 |
+-------+-------+-------+
2023-01-10 18:06:17,389 - mmseg - INFO - Exp name: 230110_1355_230110_1343_gta2cs_dacs_a999_fdthings_rcs001_cpl_m32-07-spta_daformer_sepaspp_mitb5_poly10warm_s0_2feea_f2bea
2023-01-10 18:06:17,390 - mmseg - INFO - Iter [500/40000]	lr: 4.200e-05, eta: 9:42:35, time: 1.224, data_time: 0.011, memory: 9807, aAcc: 0.9318, mIoU: 0.6555, mAcc: 0.7558, IoU.road: 0.9587, IoU.sidewalk: 0.7059, IoU.building: 0.8800, IoU.wall: 0.5341, IoU.fence: 0.2890, IoU.pole: 0.4525, IoU.traffic light: 0.5205, IoU.traffic sign: 0.5551, IoU.vegetation: 0.8890, IoU.terrain: 0.5034, IoU.sky: 0.8733, IoU.person: 0.6956, IoU.rider: 0.4152, IoU.car: 0.9092, IoU.truck: 0.7438, IoU.bus: 0.7559, IoU.train: 0.7029, IoU.motorcycle: 0.4799, IoU.bicycle: 0.5913, Acc.road: 0.9884, Acc.sidewalk: 0.7881, Acc.building: 0.9337, Acc.wall: 0.6832, Acc.fence: 0.3069, Acc.pole: 0.5319, Acc.traffic light: 0.6509, Acc.traffic sign: 0.6047, Acc.vegetation: 0.9554, Acc.terrain: 0.6096, Acc.sky: 0.9949, Acc.person: 0.8136, Acc.rider: 0.6044, Acc.car: 0.9627, Acc.truck: 0.8678, Acc.bus: 0.8351, Acc.train: 0.7583, Acc.motorcycle: 0.6275, Acc.bicycle: 0.8428, decode.loss_seg: 0.1575, decode.acc_seg: 84.8017, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1403, mix.decode.acc_seg: 89.1457, masked.decode.loss_seg: 0.1768, masked.decode.acc_seg: 91.2327
2023-01-10 18:07:24,424 - mmseg - INFO - Iter [12050/40000]	lr: 4.193e-05, eta: 9:44:35, time: 2.813, data_time: 1.485, memory: 9807, decode.loss_seg: 0.1370, decode.acc_seg: 87.3140, src.loss_imnet_feat_dist: 0.1160, mix.decode.loss_seg: 0.1483, mix.decode.acc_seg: 89.7695, masked.decode.loss_seg: 0.1773, masked.decode.acc_seg: 90.9886
2023-01-10 18:08:25,640 - mmseg - INFO - Iter [12100/40000]	lr: 4.185e-05, eta: 9:43:28, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1334, decode.acc_seg: 88.4515, src.loss_imnet_feat_dist: 0.1156, mix.decode.loss_seg: 0.1424, mix.decode.acc_seg: 90.7700, masked.decode.loss_seg: 0.1763, masked.decode.acc_seg: 91.4515
2023-01-10 18:09:27,330 - mmseg - INFO - Iter [12150/40000]	lr: 4.178e-05, eta: 9:42:23, time: 1.234, data_time: 0.010, memory: 9807, decode.loss_seg: 0.1438, decode.acc_seg: 86.0413, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1575, mix.decode.acc_seg: 90.5536, masked.decode.loss_seg: 0.1925, masked.decode.acc_seg: 91.0729
2023-01-10 18:10:28,775 - mmseg - INFO - Iter [12200/40000]	lr: 4.170e-05, eta: 9:41:17, time: 1.229, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1577, decode.acc_seg: 86.9873, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1620, mix.decode.acc_seg: 89.7707, masked.decode.loss_seg: 0.1920, masked.decode.acc_seg: 90.7928
2023-01-10 18:11:30,209 - mmseg - INFO - Iter [12250/40000]	lr: 4.163e-05, eta: 9:40:12, time: 1.229, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1471, decode.acc_seg: 87.3380, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1659, mix.decode.acc_seg: 89.5058, masked.decode.loss_seg: 0.1794, masked.decode.acc_seg: 91.4402
2023-01-10 18:12:31,178 - mmseg - INFO - Iter [12300/40000]	lr: 4.155e-05, eta: 9:39:05, time: 1.219, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1409, decode.acc_seg: 87.4623, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1569, mix.decode.acc_seg: 89.7049, masked.decode.loss_seg: 0.1804, masked.decode.acc_seg: 90.9511
2023-01-10 18:13:32,717 - mmseg - INFO - Iter [12350/40000]	lr: 4.148e-05, eta: 9:38:00, time: 1.231, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1332, decode.acc_seg: 87.1490, src.loss_imnet_feat_dist: 0.1123, mix.decode.loss_seg: 0.1473, mix.decode.acc_seg: 90.1771, masked.decode.loss_seg: 0.1801, masked.decode.acc_seg: 91.2196
2023-01-10 18:14:34,316 - mmseg - INFO - Iter [12400/40000]	lr: 4.140e-05, eta: 9:36:55, time: 1.232, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1313, decode.acc_seg: 87.1019, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1451, mix.decode.acc_seg: 89.5445, masked.decode.loss_seg: 0.1860, masked.decode.acc_seg: 90.2711
2023-01-10 18:15:35,548 - mmseg - INFO - Iter [12450/40000]	lr: 4.133e-05, eta: 9:35:49, time: 1.225, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1222, decode.acc_seg: 87.9784, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1419, mix.decode.acc_seg: 90.6329, masked.decode.loss_seg: 0.1785, masked.decode.acc_seg: 91.1120
2023-01-10 18:16:36,746 - mmseg - INFO - Iter [12500/40000]	lr: 4.125e-05, eta: 9:34:43, time: 1.224, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1743, decode.acc_seg: 87.1594, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1511, mix.decode.acc_seg: 89.7865, masked.decode.loss_seg: 0.1907, masked.decode.acc_seg: 90.7231
2023-01-10 18:17:38,197 - mmseg - INFO - Iter [12550/40000]	lr: 4.118e-05, eta: 9:33:37, time: 1.229, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1453, decode.acc_seg: 87.5611, src.loss_imnet_feat_dist: 0.1160, mix.decode.loss_seg: 0.1792, mix.decode.acc_seg: 89.1219, masked.decode.loss_seg: 0.1688, masked.decode.acc_seg: 91.3250
2023-01-10 18:18:39,458 - mmseg - INFO - Iter [12600/40000]	lr: 4.110e-05, eta: 9:32:31, time: 1.225, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1519, decode.acc_seg: 85.6649, src.loss_imnet_feat_dist: 0.1178, mix.decode.loss_seg: 0.1683, mix.decode.acc_seg: 88.9005, masked.decode.loss_seg: 0.1784, masked.decode.acc_seg: 91.6154
2023-01-10 18:19:40,582 - mmseg - INFO - Iter [12650/40000]	lr: 4.103e-05, eta: 9:31:25, time: 1.222, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1320, decode.acc_seg: 88.0727, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1552, mix.decode.acc_seg: 90.9656, masked.decode.loss_seg: 0.1844, masked.decode.acc_seg: 91.0729
2023-01-10 18:20:41,611 - mmseg - INFO - Iter [12700/40000]	lr: 4.095e-05, eta: 9:30:19, time: 1.221, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1181, decode.acc_seg: 86.5978, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1410, mix.decode.acc_seg: 88.5903, masked.decode.loss_seg: 0.1618, masked.decode.acc_seg: 91.5643
2023-01-10 18:21:42,755 - mmseg - INFO - Iter [12750/40000]	lr: 4.088e-05, eta: 9:29:13, time: 1.223, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1223, decode.acc_seg: 87.8780, src.loss_imnet_feat_dist: 0.1184, mix.decode.loss_seg: 0.1337, mix.decode.acc_seg: 91.5377, masked.decode.loss_seg: 0.1640, masked.decode.acc_seg: 92.0913
2023-01-10 18:22:44,309 - mmseg - INFO - Iter [12800/40000]	lr: 4.080e-05, eta: 9:28:08, time: 1.231, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1464, decode.acc_seg: 86.8126, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1718, mix.decode.acc_seg: 88.4995, masked.decode.loss_seg: 0.1782, masked.decode.acc_seg: 91.5784
2023-01-10 18:23:45,761 - mmseg - INFO - Iter [12850/40000]	lr: 4.073e-05, eta: 9:27:03, time: 1.229, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1492, decode.acc_seg: 88.2451, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1716, mix.decode.acc_seg: 90.1572, masked.decode.loss_seg: 0.1870, masked.decode.acc_seg: 90.8738
2023-01-10 18:24:47,008 - mmseg - INFO - Iter [12900/40000]	lr: 4.065e-05, eta: 9:25:57, time: 1.225, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1412, decode.acc_seg: 87.7889, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1599, mix.decode.acc_seg: 89.9283, masked.decode.loss_seg: 0.1681, masked.decode.acc_seg: 91.9207
2023-01-10 18:25:48,522 - mmseg - INFO - Iter [12950/40000]	lr: 4.058e-05, eta: 9:24:52, time: 1.230, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1483, decode.acc_seg: 88.2697, src.loss_imnet_feat_dist: 0.1135, mix.decode.loss_seg: 0.1837, mix.decode.acc_seg: 89.9661, masked.decode.loss_seg: 0.1723, masked.decode.acc_seg: 91.8109
2023-01-10 18:26:49,958 - mmseg - INFO - Exp name: 230110_1355_230110_1343_gta2cs_dacs_a999_fdthings_rcs001_cpl_m32-07-spta_daformer_sepaspp_mitb5_poly10warm_s0_2feea_f2bea
2023-01-10 18:26:49,958 - mmseg - INFO - Iter [13000/40000]	lr: 4.050e-05, eta: 9:23:47, time: 1.229, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1306, decode.acc_seg: 85.6087, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1445, mix.decode.acc_seg: 88.4828, masked.decode.loss_seg: 0.1795, masked.decode.acc_seg: 90.8097
2023-01-10 18:27:56,401 - mmseg - INFO - Iter [13050/40000]	lr: 4.043e-05, eta: 9:22:52, time: 1.329, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1790, decode.acc_seg: 86.8667, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1813, mix.decode.acc_seg: 90.1334, masked.decode.loss_seg: 0.1757, masked.decode.acc_seg: 90.7838
2023-01-10 18:28:57,681 - mmseg - INFO - Iter [13100/40000]	lr: 4.035e-05, eta: 9:21:47, time: 1.226, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1371, decode.acc_seg: 87.2613, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1508, mix.decode.acc_seg: 89.8123, masked.decode.loss_seg: 0.1681, masked.decode.acc_seg: 91.7679
2023-01-10 18:29:59,260 - mmseg - INFO - Iter [13150/40000]	lr: 4.028e-05, eta: 9:20:42, time: 1.232, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1347, decode.acc_seg: 86.3340, src.loss_imnet_feat_dist: 0.1145, mix.decode.loss_seg: 0.1400, mix.decode.acc_seg: 90.0142, masked.decode.loss_seg: 0.1691, masked.decode.acc_seg: 92.1516
2023-01-10 18:31:00,704 - mmseg - INFO - Iter [13200/40000]	lr: 4.020e-05, eta: 9:19:37, time: 1.229, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1426, decode.acc_seg: 87.2817, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1416, mix.decode.acc_seg: 90.5493, masked.decode.loss_seg: 0.1797, masked.decode.acc_seg: 91.7947
2023-01-10 18:32:01,718 - mmseg - INFO - Iter [13250/40000]	lr: 4.013e-05, eta: 9:18:31, time: 1.220, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1476, decode.acc_seg: 86.4824, src.loss_imnet_feat_dist: 0.1147, mix.decode.loss_seg: 0.1464, mix.decode.acc_seg: 88.1876, masked.decode.loss_seg: 0.1705, masked.decode.acc_seg: 91.9485
2023-01-10 18:33:02,908 - mmseg - INFO - Iter [13300/40000]	lr: 4.005e-05, eta: 9:17:25, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1415, decode.acc_seg: 86.0757, src.loss_imnet_feat_dist: 0.1232, mix.decode.loss_seg: 0.1376, mix.decode.acc_seg: 88.4583, masked.decode.loss_seg: 0.1809, masked.decode.acc_seg: 91.0505
2023-01-10 18:34:03,913 - mmseg - INFO - Iter [13350/40000]	lr: 3.998e-05, eta: 9:16:19, time: 1.220, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1423, decode.acc_seg: 88.3409, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1487, mix.decode.acc_seg: 90.0649, masked.decode.loss_seg: 0.1702, masked.decode.acc_seg: 91.0020
2023-01-10 18:35:05,297 - mmseg - INFO - Iter [13400/40000]	lr: 3.990e-05, eta: 9:15:14, time: 1.228, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1878, decode.acc_seg: 86.2053, src.loss_imnet_feat_dist: 0.1236, mix.decode.loss_seg: 0.1951, mix.decode.acc_seg: 88.5760, masked.decode.loss_seg: 0.1733, masked.decode.acc_seg: 90.5133
2023-01-10 18:36:06,591 - mmseg - INFO - Iter [13450/40000]	lr: 3.983e-05, eta: 9:14:09, time: 1.226, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1733, decode.acc_seg: 87.5071, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1721, mix.decode.acc_seg: 89.5247, masked.decode.loss_seg: 0.1843, masked.decode.acc_seg: 90.8975
2023-01-10 18:37:08,121 - mmseg - INFO - Iter [13500/40000]	lr: 3.975e-05, eta: 9:13:04, time: 1.231, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1382, decode.acc_seg: 87.7907, src.loss_imnet_feat_dist: 0.1062, mix.decode.loss_seg: 0.1493, mix.decode.acc_seg: 90.4688, masked.decode.loss_seg: 0.1727, masked.decode.acc_seg: 91.4028
2023-01-10 18:38:09,547 - mmseg - INFO - Iter [13550/40000]	lr: 3.968e-05, eta: 9:11:59, time: 1.229, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1265, decode.acc_seg: 86.4161, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1401, mix.decode.acc_seg: 88.5071, masked.decode.loss_seg: 0.1682, masked.decode.acc_seg: 91.7292
2023-01-10 18:39:10,646 - mmseg - INFO - Iter [13600/40000]	lr: 3.960e-05, eta: 9:10:54, time: 1.222, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1348, decode.acc_seg: 87.8422, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1560, mix.decode.acc_seg: 89.0951, masked.decode.loss_seg: 0.1685, masked.decode.acc_seg: 91.4064
2023-01-10 18:40:11,983 - mmseg - INFO - Iter [13650/40000]	lr: 3.953e-05, eta: 9:09:49, time: 1.227, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1299, decode.acc_seg: 87.3728, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1404, mix.decode.acc_seg: 89.7411, masked.decode.loss_seg: 0.1701, masked.decode.acc_seg: 92.0302
2023-01-10 18:41:13,117 - mmseg - INFO - Iter [13700/40000]	lr: 3.945e-05, eta: 9:08:43, time: 1.223, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1389, decode.acc_seg: 87.2386, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1319, mix.decode.acc_seg: 90.2202, masked.decode.loss_seg: 0.1691, masked.decode.acc_seg: 91.7589
2023-01-10 18:42:14,682 - mmseg - INFO - Iter [13750/40000]	lr: 3.938e-05, eta: 9:07:39, time: 1.231, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1182, decode.acc_seg: 88.8258, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1218, mix.decode.acc_seg: 90.4424, masked.decode.loss_seg: 0.1635, masked.decode.acc_seg: 91.8749
2023-01-10 18:43:15,731 - mmseg - INFO - Iter [13800/40000]	lr: 3.930e-05, eta: 9:06:33, time: 1.221, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1420, decode.acc_seg: 86.9062, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1454, mix.decode.acc_seg: 90.3279, masked.decode.loss_seg: 0.1715, masked.decode.acc_seg: 91.6192
2023-01-10 18:44:17,296 - mmseg - INFO - Iter [13850/40000]	lr: 3.923e-05, eta: 9:05:29, time: 1.231, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1259, decode.acc_seg: 88.9159, src.loss_imnet_feat_dist: 0.1166, mix.decode.loss_seg: 0.1411, mix.decode.acc_seg: 89.9591, masked.decode.loss_seg: 0.1785, masked.decode.acc_seg: 90.7729
2023-01-10 18:45:19,383 - mmseg - INFO - Iter [13900/40000]	lr: 3.915e-05, eta: 9:04:25, time: 1.242, data_time: 0.018, memory: 9807, decode.loss_seg: 0.1610, decode.acc_seg: 85.3089, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1752, mix.decode.acc_seg: 88.7041, masked.decode.loss_seg: 0.1775, masked.decode.acc_seg: 90.6259
2023-01-10 18:46:21,143 - mmseg - INFO - Iter [13950/40000]	lr: 3.908e-05, eta: 9:03:21, time: 1.235, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1260, decode.acc_seg: 88.1826, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1444, mix.decode.acc_seg: 90.0964, masked.decode.loss_seg: 0.1769, masked.decode.acc_seg: 90.9145
2023-01-10 18:47:22,624 - mmseg - INFO - Exp name: 230110_1355_230110_1343_gta2cs_dacs_a999_fdthings_rcs001_cpl_m32-07-spta_daformer_sepaspp_mitb5_poly10warm_s0_2feea_f2bea
2023-01-10 18:47:22,625 - mmseg - INFO - Iter [14000/40000]	lr: 3.900e-05, eta: 9:02:17, time: 1.230, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1262, decode.acc_seg: 86.0738, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1417, mix.decode.acc_seg: 88.4706, masked.decode.loss_seg: 0.1668, masked.decode.acc_seg: 91.9648
2023-01-10 18:48:28,370 - mmseg - INFO - Iter [14050/40000]	lr: 3.893e-05, eta: 9:01:20, time: 1.315, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1610, decode.acc_seg: 84.9896, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1668, mix.decode.acc_seg: 87.6808, masked.decode.loss_seg: 0.1736, masked.decode.acc_seg: 91.8452
2023-01-10 18:49:29,544 - mmseg - INFO - Iter [14100/40000]	lr: 3.885e-05, eta: 9:00:15, time: 1.223, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1585, decode.acc_seg: 86.7303, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1470, mix.decode.acc_seg: 90.2989, masked.decode.loss_seg: 0.1627, masked.decode.acc_seg: 92.4077
2023-01-10 18:50:30,519 - mmseg - INFO - Iter [14150/40000]	lr: 3.878e-05, eta: 8:59:09, time: 1.219, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1234, decode.acc_seg: 87.6696, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1330, mix.decode.acc_seg: 90.1318, masked.decode.loss_seg: 0.1714, masked.decode.acc_seg: 91.0129
2023-01-10 18:51:31,539 - mmseg - INFO - Iter [14200/40000]	lr: 3.870e-05, eta: 8:58:04, time: 1.220, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1523, decode.acc_seg: 87.9610, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1615, mix.decode.acc_seg: 90.6094, masked.decode.loss_seg: 0.1621, masked.decode.acc_seg: 92.2049
2023-01-10 18:52:32,752 - mmseg - INFO - Iter [14250/40000]	lr: 3.863e-05, eta: 8:56:59, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1259, decode.acc_seg: 87.8759, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1367, mix.decode.acc_seg: 90.6477, masked.decode.loss_seg: 0.1778, masked.decode.acc_seg: 91.6154
2023-01-10 18:53:34,072 - mmseg - INFO - Iter [14300/40000]	lr: 3.855e-05, eta: 8:55:54, time: 1.226, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1385, decode.acc_seg: 87.3227, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1412, mix.decode.acc_seg: 89.8958, masked.decode.loss_seg: 0.1690, masked.decode.acc_seg: 91.9068
2023-01-10 18:54:35,250 - mmseg - INFO - Iter [14350/40000]	lr: 3.848e-05, eta: 8:54:49, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1197, decode.acc_seg: 88.7106, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1243, mix.decode.acc_seg: 90.4802, masked.decode.loss_seg: 0.1706, masked.decode.acc_seg: 91.4039
2023-01-10 18:55:36,733 - mmseg - INFO - Iter [14400/40000]	lr: 3.840e-05, eta: 8:53:45, time: 1.230, data_time: 0.014, memory: 9807, decode.loss_seg: 0.1468, decode.acc_seg: 88.3881, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1582, mix.decode.acc_seg: 89.3940, masked.decode.loss_seg: 0.1759, masked.decode.acc_seg: 90.8675
2023-01-10 18:56:38,076 - mmseg - INFO - Iter [14450/40000]	lr: 3.833e-05, eta: 8:52:40, time: 1.227, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1337, decode.acc_seg: 87.8922, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1420, mix.decode.acc_seg: 90.0501, masked.decode.loss_seg: 0.1700, masked.decode.acc_seg: 91.1569
2023-01-10 18:57:39,295 - mmseg - INFO - Iter [14500/40000]	lr: 3.825e-05, eta: 8:51:35, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1273, decode.acc_seg: 88.2254, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1438, mix.decode.acc_seg: 90.1249, masked.decode.loss_seg: 0.1724, masked.decode.acc_seg: 90.6890
2023-01-10 18:58:40,106 - mmseg - INFO - Iter [14550/40000]	lr: 3.818e-05, eta: 8:50:29, time: 1.216, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1180, decode.acc_seg: 87.1884, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1350, mix.decode.acc_seg: 88.6402, masked.decode.loss_seg: 0.1792, masked.decode.acc_seg: 91.3544
2023-01-10 18:59:41,592 - mmseg - INFO - Iter [14600/40000]	lr: 3.810e-05, eta: 8:49:25, time: 1.230, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1320, decode.acc_seg: 86.5613, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1609, mix.decode.acc_seg: 88.8898, masked.decode.loss_seg: 0.1785, masked.decode.acc_seg: 91.2385
2023-01-10 19:00:42,760 - mmseg - INFO - Iter [14650/40000]	lr: 3.803e-05, eta: 8:48:20, time: 1.223, data_time: 0.010, memory: 9807, decode.loss_seg: 0.1252, decode.acc_seg: 88.4454, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1475, mix.decode.acc_seg: 89.4280, masked.decode.loss_seg: 0.1880, masked.decode.acc_seg: 90.0287
2023-01-10 19:01:44,192 - mmseg - INFO - Iter [14700/40000]	lr: 3.795e-05, eta: 8:47:16, time: 1.229, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1372, decode.acc_seg: 86.5722, src.loss_imnet_feat_dist: 0.1170, mix.decode.loss_seg: 0.1564, mix.decode.acc_seg: 89.1368, masked.decode.loss_seg: 0.1870, masked.decode.acc_seg: 90.7800
2023-01-10 19:02:45,517 - mmseg - INFO - Iter [14750/40000]	lr: 3.788e-05, eta: 8:46:11, time: 1.226, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1278, decode.acc_seg: 87.7834, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1373, mix.decode.acc_seg: 89.6749, masked.decode.loss_seg: 0.1785, masked.decode.acc_seg: 91.6594
2023-01-10 19:03:46,906 - mmseg - INFO - Iter [14800/40000]	lr: 3.780e-05, eta: 8:45:07, time: 1.228, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1470, decode.acc_seg: 87.4540, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1542, mix.decode.acc_seg: 89.7028, masked.decode.loss_seg: 0.1790, masked.decode.acc_seg: 90.7402
2023-01-10 19:04:48,043 - mmseg - INFO - Iter [14850/40000]	lr: 3.773e-05, eta: 8:44:02, time: 1.223, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1781, decode.acc_seg: 88.2607, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1720, mix.decode.acc_seg: 90.3021, masked.decode.loss_seg: 0.1788, masked.decode.acc_seg: 91.0902
2023-01-10 19:05:49,253 - mmseg - INFO - Iter [14900/40000]	lr: 3.765e-05, eta: 8:42:57, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1302, decode.acc_seg: 88.6160, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1400, mix.decode.acc_seg: 90.8358, masked.decode.loss_seg: 0.1862, masked.decode.acc_seg: 90.6015
2023-01-10 19:06:50,269 - mmseg - INFO - Iter [14950/40000]	lr: 3.758e-05, eta: 8:41:52, time: 1.220, data_time: 0.010, memory: 9807, decode.loss_seg: 0.1325, decode.acc_seg: 87.8422, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1411, mix.decode.acc_seg: 90.5681, masked.decode.loss_seg: 0.1689, masked.decode.acc_seg: 91.6116
2023-01-10 19:07:51,474 - mmseg - INFO - Exp name: 230110_1355_230110_1343_gta2cs_dacs_a999_fdthings_rcs001_cpl_m32-07-spta_daformer_sepaspp_mitb5_poly10warm_s0_2feea_f2bea
2023-01-10 19:07:51,474 - mmseg - INFO - Iter [15000/40000]	lr: 3.750e-05, eta: 8:40:48, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1434, decode.acc_seg: 88.9433, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1522, mix.decode.acc_seg: 90.2256, masked.decode.loss_seg: 0.1762, masked.decode.acc_seg: 91.1786
2023-01-10 19:08:57,067 - mmseg - INFO - Iter [15050/40000]	lr: 3.743e-05, eta: 8:39:50, time: 1.312, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1502, decode.acc_seg: 87.8693, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1315, mix.decode.acc_seg: 89.9073, masked.decode.loss_seg: 0.1697, masked.decode.acc_seg: 91.6175
2023-01-10 19:09:58,205 - mmseg - INFO - Iter [15100/40000]	lr: 3.735e-05, eta: 8:38:45, time: 1.223, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1238, decode.acc_seg: 88.6353, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1476, mix.decode.acc_seg: 90.6008, masked.decode.loss_seg: 0.2012, masked.decode.acc_seg: 91.1319
2023-01-10 19:10:59,254 - mmseg - INFO - Iter [15150/40000]	lr: 3.728e-05, eta: 8:37:41, time: 1.221, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1137, decode.acc_seg: 88.8359, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1331, mix.decode.acc_seg: 91.7740, masked.decode.loss_seg: 0.1769, masked.decode.acc_seg: 91.6597
2023-01-10 19:12:00,752 - mmseg - INFO - Iter [15200/40000]	lr: 3.720e-05, eta: 8:36:36, time: 1.230, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1201, decode.acc_seg: 86.3241, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1318, mix.decode.acc_seg: 88.8441, masked.decode.loss_seg: 0.1796, masked.decode.acc_seg: 91.3827
2023-01-10 19:13:02,023 - mmseg - INFO - Iter [15250/40000]	lr: 3.713e-05, eta: 8:35:32, time: 1.225, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1880, decode.acc_seg: 85.4473, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1338, mix.decode.acc_seg: 88.9079, masked.decode.loss_seg: 0.1624, masked.decode.acc_seg: 91.8379
2023-01-10 19:14:03,988 - mmseg - INFO - Iter [15300/40000]	lr: 3.705e-05, eta: 8:34:29, time: 1.239, data_time: 0.028, memory: 9807, decode.loss_seg: 0.1465, decode.acc_seg: 87.1478, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1631, mix.decode.acc_seg: 88.7698, masked.decode.loss_seg: 0.1768, masked.decode.acc_seg: 91.0285
2023-01-10 19:15:04,943 - mmseg - INFO - Iter [15350/40000]	lr: 3.698e-05, eta: 8:33:24, time: 1.219, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1283, decode.acc_seg: 89.9375, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1523, mix.decode.acc_seg: 90.3775, masked.decode.loss_seg: 0.1763, masked.decode.acc_seg: 90.8910
2023-01-10 19:16:06,226 - mmseg - INFO - Iter [15400/40000]	lr: 3.690e-05, eta: 8:32:19, time: 1.226, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1331, decode.acc_seg: 87.6483, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1409, mix.decode.acc_seg: 90.8785, masked.decode.loss_seg: 0.1845, masked.decode.acc_seg: 90.6684
2023-01-10 19:17:07,308 - mmseg - INFO - Iter [15450/40000]	lr: 3.683e-05, eta: 8:31:15, time: 1.222, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1274, decode.acc_seg: 88.5382, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1371, mix.decode.acc_seg: 89.9430, masked.decode.loss_seg: 0.1861, masked.decode.acc_seg: 91.1924
2023-01-10 19:18:08,429 - mmseg - INFO - Iter [15500/40000]	lr: 3.675e-05, eta: 8:30:10, time: 1.222, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1318, decode.acc_seg: 88.0474, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1362, mix.decode.acc_seg: 90.7135, masked.decode.loss_seg: 0.1755, masked.decode.acc_seg: 91.3799
2023-01-10 19:19:09,883 - mmseg - INFO - Iter [15550/40000]	lr: 3.668e-05, eta: 8:29:06, time: 1.229, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1169, decode.acc_seg: 88.4654, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1345, mix.decode.acc_seg: 90.0872, masked.decode.loss_seg: 0.1738, masked.decode.acc_seg: 91.4254
2023-01-10 19:20:11,475 - mmseg - INFO - Iter [15600/40000]	lr: 3.660e-05, eta: 8:28:02, time: 1.232, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1287, decode.acc_seg: 87.7424, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1490, mix.decode.acc_seg: 89.7341, masked.decode.loss_seg: 0.1805, masked.decode.acc_seg: 91.1502
2023-01-10 19:21:12,563 - mmseg - INFO - Iter [15650/40000]	lr: 3.653e-05, eta: 8:26:57, time: 1.222, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1207, decode.acc_seg: 87.7196, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1431, mix.decode.acc_seg: 89.4072, masked.decode.loss_seg: 0.1701, masked.decode.acc_seg: 91.4396
2023-01-10 19:22:13,534 - mmseg - INFO - Iter [15700/40000]	lr: 3.645e-05, eta: 8:25:53, time: 1.219, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1258, decode.acc_seg: 87.0598, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1394, mix.decode.acc_seg: 89.1369, masked.decode.loss_seg: 0.1706, masked.decode.acc_seg: 91.5823
2023-01-10 19:23:14,579 - mmseg - INFO - Iter [15750/40000]	lr: 3.638e-05, eta: 8:24:48, time: 1.221, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1120, decode.acc_seg: 87.9307, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1283, mix.decode.acc_seg: 89.8751, masked.decode.loss_seg: 0.1596, masked.decode.acc_seg: 92.6913
2023-01-10 19:24:16,325 - mmseg - INFO - Iter [15800/40000]	lr: 3.630e-05, eta: 8:23:45, time: 1.235, data_time: 0.015, memory: 9807, decode.loss_seg: 0.1286, decode.acc_seg: 86.6627, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1397, mix.decode.acc_seg: 89.2734, masked.decode.loss_seg: 0.1731, masked.decode.acc_seg: 91.8065
2023-01-10 19:25:17,954 - mmseg - INFO - Iter [15850/40000]	lr: 3.623e-05, eta: 8:22:41, time: 1.233, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1263, decode.acc_seg: 89.9217, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1300, mix.decode.acc_seg: 91.1066, masked.decode.loss_seg: 0.1636, masked.decode.acc_seg: 91.9129
2023-01-10 19:26:19,190 - mmseg - INFO - Iter [15900/40000]	lr: 3.615e-05, eta: 8:21:37, time: 1.225, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1459, decode.acc_seg: 87.6936, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1438, mix.decode.acc_seg: 89.8202, masked.decode.loss_seg: 0.1677, masked.decode.acc_seg: 91.7029
2023-01-10 19:27:20,317 - mmseg - INFO - Iter [15950/40000]	lr: 3.608e-05, eta: 8:20:32, time: 1.223, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1477, decode.acc_seg: 86.9937, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1573, mix.decode.acc_seg: 90.6072, masked.decode.loss_seg: 0.1661, masked.decode.acc_seg: 91.3679
2023-01-10 19:29:38,563 - mmseg - INFO - per class results:
2023-01-10 19:29:38,597 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      road     | 96.47 | 98.92 |
|    sidewalk   | 73.62 | 82.77 |
|    building   |  89.2 | 95.22 |
|      wall     | 55.17 | 67.83 |
|     fence     | 39.87 | 43.77 |
|      pole     | 44.12 | 49.33 |
| traffic light | 53.22 | 69.04 |
|  traffic sign | 56.31 | 60.91 |
|   vegetation  | 89.81 | 95.79 |
|    terrain    | 51.54 | 60.63 |
|      sky      | 90.98 | 99.09 |
|     person    | 71.03 | 81.14 |
|     rider     | 44.16 | 59.75 |
|      car      | 91.53 | 95.37 |
|     truck     | 68.47 | 87.75 |
|      bus      | 75.05 |  76.7 |
|     train     | 66.91 | 82.77 |
|   motorcycle  | 53.16 |  75.2 |
|    bicycle    |  61.9 | 82.45 |
+---------------+-------+-------+
2023-01-10 19:29:38,597 - mmseg - INFO - Summary:
2023-01-10 19:29:38,598 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 93.83 | 66.97 | 77.07 |
+-------+-------+-------+
2023-01-10 19:29:38,614 - mmseg - INFO - Exp name: 230110_1355_230110_1343_gta2cs_dacs_a999_fdthings_rcs001_cpl_m32-07-spta_daformer_sepaspp_mitb5_poly10warm_s0_2feea_f2bea
2023-01-10 19:29:38,615 - mmseg - INFO - Iter [500/40000]	lr: 3.600e-05, eta: 8:19:28, time: 1.228, data_time: 0.011, memory: 9807, aAcc: 0.9383, mIoU: 0.6697, mAcc: 0.7707, IoU.road: 0.9647, IoU.sidewalk: 0.7362, IoU.building: 0.8920, IoU.wall: 0.5517, IoU.fence: 0.3987, IoU.pole: 0.4412, IoU.traffic light: 0.5322, IoU.traffic sign: 0.5631, IoU.vegetation: 0.8981, IoU.terrain: 0.5154, IoU.sky: 0.9098, IoU.person: 0.7103, IoU.rider: 0.4416, IoU.car: 0.9153, IoU.truck: 0.6847, IoU.bus: 0.7505, IoU.train: 0.6691, IoU.motorcycle: 0.5316, IoU.bicycle: 0.6190, Acc.road: 0.9892, Acc.sidewalk: 0.8277, Acc.building: 0.9522, Acc.wall: 0.6783, Acc.fence: 0.4377, Acc.pole: 0.4933, Acc.traffic light: 0.6904, Acc.traffic sign: 0.6091, Acc.vegetation: 0.9579, Acc.terrain: 0.6063, Acc.sky: 0.9909, Acc.person: 0.8114, Acc.rider: 0.5975, Acc.car: 0.9537, Acc.truck: 0.8775, Acc.bus: 0.7670, Acc.train: 0.8277, Acc.motorcycle: 0.7520, Acc.bicycle: 0.8245, decode.loss_seg: 0.1473, decode.acc_seg: 88.7581, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1650, mix.decode.acc_seg: 90.5234, masked.decode.loss_seg: 0.1797, masked.decode.acc_seg: 90.9662
2023-01-10 19:30:46,411 - mmseg - INFO - Iter [16050/40000]	lr: 3.593e-05, eta: 8:20:28, time: 2.894, data_time: 1.549, memory: 9807, decode.loss_seg: 0.1211, decode.acc_seg: 88.4692, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1430, mix.decode.acc_seg: 89.4794, masked.decode.loss_seg: 0.1759, masked.decode.acc_seg: 91.4270
2023-01-10 19:31:47,700 - mmseg - INFO - Iter [16100/40000]	lr: 3.585e-05, eta: 8:19:24, time: 1.226, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1446, decode.acc_seg: 87.9603, src.loss_imnet_feat_dist: 0.1118, mix.decode.loss_seg: 0.1443, mix.decode.acc_seg: 90.0978, masked.decode.loss_seg: 0.1553, masked.decode.acc_seg: 91.9005
2023-01-10 19:32:48,678 - mmseg - INFO - Iter [16150/40000]	lr: 3.578e-05, eta: 8:18:18, time: 1.220, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1222, decode.acc_seg: 86.9928, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1376, mix.decode.acc_seg: 90.4348, masked.decode.loss_seg: 0.1664, masked.decode.acc_seg: 91.9149
2023-01-10 19:33:49,597 - mmseg - INFO - Iter [16200/40000]	lr: 3.570e-05, eta: 8:17:13, time: 1.218, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1135, decode.acc_seg: 87.2158, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1296, mix.decode.acc_seg: 90.1118, masked.decode.loss_seg: 0.1669, masked.decode.acc_seg: 91.6833
2023-01-10 19:34:50,494 - mmseg - INFO - Iter [16250/40000]	lr: 3.563e-05, eta: 8:16:08, time: 1.218, data_time: 0.010, memory: 9807, decode.loss_seg: 0.1250, decode.acc_seg: 87.5276, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1459, mix.decode.acc_seg: 89.5155, masked.decode.loss_seg: 0.1814, masked.decode.acc_seg: 90.1231
2023-01-10 19:35:52,076 - mmseg - INFO - Iter [16300/40000]	lr: 3.555e-05, eta: 8:15:04, time: 1.232, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1229, decode.acc_seg: 88.6991, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1387, mix.decode.acc_seg: 90.3495, masked.decode.loss_seg: 0.1702, masked.decode.acc_seg: 90.8831
2023-01-10 19:36:53,228 - mmseg - INFO - Iter [16350/40000]	lr: 3.548e-05, eta: 8:13:59, time: 1.223, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1453, decode.acc_seg: 88.5700, src.loss_imnet_feat_dist: 0.1104, mix.decode.loss_seg: 0.1583, mix.decode.acc_seg: 90.0719, masked.decode.loss_seg: 0.1822, masked.decode.acc_seg: 91.0411
2023-01-10 19:37:54,325 - mmseg - INFO - Iter [16400/40000]	lr: 3.540e-05, eta: 8:12:54, time: 1.222, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1245, decode.acc_seg: 86.8351, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1628, mix.decode.acc_seg: 88.5139, masked.decode.loss_seg: 0.1790, masked.decode.acc_seg: 90.4226
2023-01-10 19:38:55,868 - mmseg - INFO - Iter [16450/40000]	lr: 3.533e-05, eta: 8:11:50, time: 1.231, data_time: 0.013, memory: 9807, decode.loss_seg: 0.1316, decode.acc_seg: 87.5963, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1399, mix.decode.acc_seg: 90.6681, masked.decode.loss_seg: 0.1715, masked.decode.acc_seg: 91.7744
2023-01-10 19:39:57,490 - mmseg - INFO - Iter [16500/40000]	lr: 3.525e-05, eta: 8:10:46, time: 1.232, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1209, decode.acc_seg: 88.1223, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1284, mix.decode.acc_seg: 89.8856, masked.decode.loss_seg: 0.1711, masked.decode.acc_seg: 91.2447
2023-01-10 19:40:58,475 - mmseg - INFO - Iter [16550/40000]	lr: 3.518e-05, eta: 8:09:41, time: 1.220, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1163, decode.acc_seg: 88.3377, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1335, mix.decode.acc_seg: 89.7014, masked.decode.loss_seg: 0.1699, masked.decode.acc_seg: 91.6359
2023-01-10 19:41:59,875 - mmseg - INFO - Iter [16600/40000]	lr: 3.510e-05, eta: 8:08:36, time: 1.228, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1275, decode.acc_seg: 86.4873, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1412, mix.decode.acc_seg: 89.0930, masked.decode.loss_seg: 0.1882, masked.decode.acc_seg: 90.2282
2023-01-10 19:43:00,941 - mmseg - INFO - Iter [16650/40000]	lr: 3.503e-05, eta: 8:07:31, time: 1.221, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1199, decode.acc_seg: 88.4980, src.loss_imnet_feat_dist: 0.1200, mix.decode.loss_seg: 0.1331, mix.decode.acc_seg: 90.9869, masked.decode.loss_seg: 0.1727, masked.decode.acc_seg: 91.2123
2023-01-10 19:44:02,291 - mmseg - INFO - Iter [16700/40000]	lr: 3.495e-05, eta: 8:06:27, time: 1.227, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1269, decode.acc_seg: 88.8315, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1478, mix.decode.acc_seg: 90.2413, masked.decode.loss_seg: 0.1702, masked.decode.acc_seg: 91.2521
2023-01-10 19:45:03,353 - mmseg - INFO - Iter [16750/40000]	lr: 3.488e-05, eta: 8:05:22, time: 1.221, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1312, decode.acc_seg: 87.7941, src.loss_imnet_feat_dist: 0.1075, mix.decode.loss_seg: 0.1370, mix.decode.acc_seg: 89.5585, masked.decode.loss_seg: 0.1671, masked.decode.acc_seg: 91.5040
2023-01-10 19:46:04,658 - mmseg - INFO - Iter [16800/40000]	lr: 3.480e-05, eta: 8:04:18, time: 1.226, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1466, decode.acc_seg: 87.1659, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1408, mix.decode.acc_seg: 89.6956, masked.decode.loss_seg: 0.1682, masked.decode.acc_seg: 91.0495
2023-01-10 19:47:05,896 - mmseg - INFO - Iter [16850/40000]	lr: 3.473e-05, eta: 8:03:13, time: 1.225, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1249, decode.acc_seg: 88.3442, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1422, mix.decode.acc_seg: 89.6366, masked.decode.loss_seg: 0.1750, masked.decode.acc_seg: 91.4266
2023-01-10 19:48:07,127 - mmseg - INFO - Iter [16900/40000]	lr: 3.465e-05, eta: 8:02:08, time: 1.225, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1474, decode.acc_seg: 87.6160, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1531, mix.decode.acc_seg: 89.4733, masked.decode.loss_seg: 0.1847, masked.decode.acc_seg: 91.1069
2023-01-10 19:49:08,506 - mmseg - INFO - Iter [16950/40000]	lr: 3.458e-05, eta: 8:01:04, time: 1.228, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1329, decode.acc_seg: 88.2274, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1397, mix.decode.acc_seg: 90.2439, masked.decode.loss_seg: 0.1742, masked.decode.acc_seg: 90.8462
2023-01-10 19:50:10,121 - mmseg - INFO - Exp name: 230110_1355_230110_1343_gta2cs_dacs_a999_fdthings_rcs001_cpl_m32-07-spta_daformer_sepaspp_mitb5_poly10warm_s0_2feea_f2bea
2023-01-10 19:50:10,121 - mmseg - INFO - Iter [17000/40000]	lr: 3.450e-05, eta: 8:00:00, time: 1.232, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1214, decode.acc_seg: 87.9570, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1327, mix.decode.acc_seg: 90.2430, masked.decode.loss_seg: 0.1704, masked.decode.acc_seg: 91.2798
2023-01-10 19:51:16,481 - mmseg - INFO - Iter [17050/40000]	lr: 3.443e-05, eta: 7:59:03, time: 1.327, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1217, decode.acc_seg: 87.8082, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1484, mix.decode.acc_seg: 90.1543, masked.decode.loss_seg: 0.1701, masked.decode.acc_seg: 91.6822
2023-01-10 19:52:17,512 - mmseg - INFO - Iter [17100/40000]	lr: 3.435e-05, eta: 7:57:58, time: 1.221, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1271, decode.acc_seg: 88.4108, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1399, mix.decode.acc_seg: 90.6418, masked.decode.loss_seg: 0.1725, masked.decode.acc_seg: 91.1346
2023-01-10 19:53:18,662 - mmseg - INFO - Iter [17150/40000]	lr: 3.428e-05, eta: 7:56:53, time: 1.223, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1487, decode.acc_seg: 87.0234, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1385, mix.decode.acc_seg: 90.7551, masked.decode.loss_seg: 0.1650, masked.decode.acc_seg: 91.7315
2023-01-10 19:54:20,235 - mmseg - INFO - Iter [17200/40000]	lr: 3.420e-05, eta: 7:55:49, time: 1.231, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1265, decode.acc_seg: 88.2151, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1293, mix.decode.acc_seg: 90.1660, masked.decode.loss_seg: 0.1682, masked.decode.acc_seg: 91.6362
2023-01-10 19:55:21,465 - mmseg - INFO - Iter [17250/40000]	lr: 3.413e-05, eta: 7:54:45, time: 1.225, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1120, decode.acc_seg: 88.4150, src.loss_imnet_feat_dist: 0.1114, mix.decode.loss_seg: 0.1262, mix.decode.acc_seg: 90.7334, masked.decode.loss_seg: 0.1614, masked.decode.acc_seg: 91.6327
2023-01-10 19:56:22,666 - mmseg - INFO - Iter [17300/40000]	lr: 3.405e-05, eta: 7:53:40, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1189, decode.acc_seg: 87.6150, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1466, mix.decode.acc_seg: 90.0989, masked.decode.loss_seg: 0.1806, masked.decode.acc_seg: 90.8879
2023-01-10 19:57:24,150 - mmseg - INFO - Iter [17350/40000]	lr: 3.398e-05, eta: 7:52:36, time: 1.230, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1095, decode.acc_seg: 88.4600, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1286, mix.decode.acc_seg: 89.5130, masked.decode.loss_seg: 0.1643, masked.decode.acc_seg: 91.3639
2023-01-10 19:58:25,653 - mmseg - INFO - Iter [17400/40000]	lr: 3.390e-05, eta: 7:51:32, time: 1.230, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1101, decode.acc_seg: 87.3704, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1307, mix.decode.acc_seg: 88.7960, masked.decode.loss_seg: 0.1848, masked.decode.acc_seg: 90.7063
2023-01-10 19:59:26,966 - mmseg - INFO - Iter [17450/40000]	lr: 3.383e-05, eta: 7:50:28, time: 1.226, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1239, decode.acc_seg: 87.7387, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1884, mix.decode.acc_seg: 87.2647, masked.decode.loss_seg: 0.1752, masked.decode.acc_seg: 90.0188
2023-01-10 20:00:28,238 - mmseg - INFO - Iter [17500/40000]	lr: 3.375e-05, eta: 7:49:24, time: 1.225, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1395, decode.acc_seg: 86.7258, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1439, mix.decode.acc_seg: 88.9129, masked.decode.loss_seg: 0.1722, masked.decode.acc_seg: 90.7731
2023-01-10 20:01:29,948 - mmseg - INFO - Iter [17550/40000]	lr: 3.368e-05, eta: 7:48:20, time: 1.234, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1378, decode.acc_seg: 87.5835, src.loss_imnet_feat_dist: 0.1085, mix.decode.loss_seg: 0.1416, mix.decode.acc_seg: 90.9239, masked.decode.loss_seg: 0.1684, masked.decode.acc_seg: 91.4221
2023-01-10 20:02:31,112 - mmseg - INFO - Iter [17600/40000]	lr: 3.360e-05, eta: 7:47:16, time: 1.223, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1202, decode.acc_seg: 88.5355, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1315, mix.decode.acc_seg: 90.5543, masked.decode.loss_seg: 0.1754, masked.decode.acc_seg: 91.1157
2023-01-10 20:03:32,074 - mmseg - INFO - Iter [17650/40000]	lr: 3.353e-05, eta: 7:46:11, time: 1.219, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1258, decode.acc_seg: 88.2022, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1420, mix.decode.acc_seg: 90.3367, masked.decode.loss_seg: 0.1676, masked.decode.acc_seg: 91.5443
2023-01-10 20:04:33,155 - mmseg - INFO - Iter [17700/40000]	lr: 3.345e-05, eta: 7:45:07, time: 1.222, data_time: 0.010, memory: 9807, decode.loss_seg: 0.1266, decode.acc_seg: 88.3001, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1470, mix.decode.acc_seg: 89.5528, masked.decode.loss_seg: 0.1882, masked.decode.acc_seg: 89.5555
2023-01-10 20:05:34,353 - mmseg - INFO - Iter [17750/40000]	lr: 3.338e-05, eta: 7:44:02, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1192, decode.acc_seg: 88.0189, src.loss_imnet_feat_dist: 0.1122, mix.decode.loss_seg: 0.1163, mix.decode.acc_seg: 90.3370, masked.decode.loss_seg: 0.1599, masked.decode.acc_seg: 91.8274
2023-01-10 20:06:35,278 - mmseg - INFO - Iter [17800/40000]	lr: 3.330e-05, eta: 7:42:58, time: 1.218, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1208, decode.acc_seg: 87.3041, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1381, mix.decode.acc_seg: 89.7245, masked.decode.loss_seg: 0.1715, masked.decode.acc_seg: 91.2939
2023-01-10 20:07:36,451 - mmseg - INFO - Iter [17850/40000]	lr: 3.323e-05, eta: 7:41:53, time: 1.223, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1425, decode.acc_seg: 88.2783, src.loss_imnet_feat_dist: 0.1106, mix.decode.loss_seg: 0.1256, mix.decode.acc_seg: 90.6914, masked.decode.loss_seg: 0.1838, masked.decode.acc_seg: 90.1632
2023-01-10 20:08:37,879 - mmseg - INFO - Iter [17900/40000]	lr: 3.315e-05, eta: 7:40:49, time: 1.229, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1271, decode.acc_seg: 86.5322, src.loss_imnet_feat_dist: 0.1152, mix.decode.loss_seg: 0.1378, mix.decode.acc_seg: 88.7424, masked.decode.loss_seg: 0.1704, masked.decode.acc_seg: 91.6439
2023-01-10 20:09:39,306 - mmseg - INFO - Iter [17950/40000]	lr: 3.308e-05, eta: 7:39:46, time: 1.229, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1324, decode.acc_seg: 87.4969, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1432, mix.decode.acc_seg: 89.7118, masked.decode.loss_seg: 0.1728, masked.decode.acc_seg: 91.0938
2023-01-10 20:10:40,686 - mmseg - INFO - Exp name: 230110_1355_230110_1343_gta2cs_dacs_a999_fdthings_rcs001_cpl_m32-07-spta_daformer_sepaspp_mitb5_poly10warm_s0_2feea_f2bea
2023-01-10 20:10:40,686 - mmseg - INFO - Iter [18000/40000]	lr: 3.300e-05, eta: 7:38:42, time: 1.228, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1739, decode.acc_seg: 87.8361, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1478, mix.decode.acc_seg: 90.6388, masked.decode.loss_seg: 0.1678, masked.decode.acc_seg: 92.1053
2023-01-10 20:11:46,140 - mmseg - INFO - Iter [18050/40000]	lr: 3.293e-05, eta: 7:37:43, time: 1.309, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1594, decode.acc_seg: 86.5599, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.2051, mix.decode.acc_seg: 87.1329, masked.decode.loss_seg: 0.1884, masked.decode.acc_seg: 90.2228
2023-01-10 20:12:47,150 - mmseg - INFO - Iter [18100/40000]	lr: 3.285e-05, eta: 7:36:38, time: 1.220, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1575, decode.acc_seg: 87.3508, src.loss_imnet_feat_dist: 0.1201, mix.decode.loss_seg: 0.1450, mix.decode.acc_seg: 89.4072, masked.decode.loss_seg: 0.1774, masked.decode.acc_seg: 90.8317
2023-01-10 20:13:48,440 - mmseg - INFO - Iter [18150/40000]	lr: 3.278e-05, eta: 7:35:34, time: 1.226, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1280, decode.acc_seg: 88.6299, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1317, mix.decode.acc_seg: 90.4936, masked.decode.loss_seg: 0.1651, masked.decode.acc_seg: 92.0265
2023-01-10 20:14:49,971 - mmseg - INFO - Iter [18200/40000]	lr: 3.270e-05, eta: 7:34:30, time: 1.231, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1047, decode.acc_seg: 88.1660, src.loss_imnet_feat_dist: 0.1122, mix.decode.loss_seg: 0.1211, mix.decode.acc_seg: 89.7867, masked.decode.loss_seg: 0.1642, masked.decode.acc_seg: 91.3245
2023-01-10 20:15:51,243 - mmseg - INFO - Iter [18250/40000]	lr: 3.263e-05, eta: 7:33:26, time: 1.225, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1675, decode.acc_seg: 88.4893, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1467, mix.decode.acc_seg: 90.6306, masked.decode.loss_seg: 0.1701, masked.decode.acc_seg: 91.4837
2023-01-10 20:16:52,694 - mmseg - INFO - Iter [18300/40000]	lr: 3.255e-05, eta: 7:32:22, time: 1.229, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1260, decode.acc_seg: 87.5492, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1411, mix.decode.acc_seg: 88.6243, masked.decode.loss_seg: 0.1679, masked.decode.acc_seg: 91.0818
2023-01-10 20:17:53,690 - mmseg - INFO - Iter [18350/40000]	lr: 3.248e-05, eta: 7:31:18, time: 1.220, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1222, decode.acc_seg: 88.3111, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1384, mix.decode.acc_seg: 90.1040, masked.decode.loss_seg: 0.1752, masked.decode.acc_seg: 91.4892
2023-01-10 20:18:54,929 - mmseg - INFO - Iter [18400/40000]	lr: 3.240e-05, eta: 7:30:14, time: 1.225, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1149, decode.acc_seg: 87.6048, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1421, mix.decode.acc_seg: 89.1458, masked.decode.loss_seg: 0.1773, masked.decode.acc_seg: 90.8405
2023-01-10 20:19:56,280 - mmseg - INFO - Iter [18450/40000]	lr: 3.233e-05, eta: 7:29:10, time: 1.227, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1198, decode.acc_seg: 86.4620, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1399, mix.decode.acc_seg: 89.5163, masked.decode.loss_seg: 0.1670, masked.decode.acc_seg: 91.4316
2023-01-10 20:20:57,739 - mmseg - INFO - Iter [18500/40000]	lr: 3.225e-05, eta: 7:28:06, time: 1.229, data_time: 0.014, memory: 9807, decode.loss_seg: 0.1056, decode.acc_seg: 89.2111, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1272, mix.decode.acc_seg: 90.4130, masked.decode.loss_seg: 0.1620, masked.decode.acc_seg: 91.3328
2023-01-10 20:21:59,067 - mmseg - INFO - Iter [18550/40000]	lr: 3.218e-05, eta: 7:27:02, time: 1.227, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1249, decode.acc_seg: 86.7088, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1360, mix.decode.acc_seg: 90.1510, masked.decode.loss_seg: 0.1630, masked.decode.acc_seg: 91.4997
2023-01-10 20:23:00,073 - mmseg - INFO - Iter [18600/40000]	lr: 3.210e-05, eta: 7:25:58, time: 1.220, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1192, decode.acc_seg: 88.0149, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1286, mix.decode.acc_seg: 90.6644, masked.decode.loss_seg: 0.1699, masked.decode.acc_seg: 91.3879
2023-01-10 20:24:01,212 - mmseg - INFO - Iter [18650/40000]	lr: 3.203e-05, eta: 7:24:54, time: 1.223, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1175, decode.acc_seg: 88.4322, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1339, mix.decode.acc_seg: 90.2663, masked.decode.loss_seg: 0.1803, masked.decode.acc_seg: 90.3575
2023-01-10 20:25:02,288 - mmseg - INFO - Iter [18700/40000]	lr: 3.195e-05, eta: 7:23:50, time: 1.222, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1197, decode.acc_seg: 89.9046, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1232, mix.decode.acc_seg: 91.5258, masked.decode.loss_seg: 0.1681, masked.decode.acc_seg: 91.5258
2023-01-10 20:26:03,574 - mmseg - INFO - Iter [18750/40000]	lr: 3.188e-05, eta: 7:22:46, time: 1.226, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1164, decode.acc_seg: 88.3610, src.loss_imnet_feat_dist: 0.1123, mix.decode.loss_seg: 0.1321, mix.decode.acc_seg: 89.8933, masked.decode.loss_seg: 0.1631, masked.decode.acc_seg: 91.4723
2023-01-10 20:27:04,961 - mmseg - INFO - Iter [18800/40000]	lr: 3.180e-05, eta: 7:21:42, time: 1.228, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1172, decode.acc_seg: 87.4053, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1360, mix.decode.acc_seg: 88.9876, masked.decode.loss_seg: 0.1699, masked.decode.acc_seg: 91.5800
2023-01-10 20:28:06,277 - mmseg - INFO - Iter [18850/40000]	lr: 3.173e-05, eta: 7:20:38, time: 1.226, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1097, decode.acc_seg: 87.0148, src.loss_imnet_feat_dist: 0.1133, mix.decode.loss_seg: 0.1266, mix.decode.acc_seg: 89.5075, masked.decode.loss_seg: 0.1840, masked.decode.acc_seg: 90.6457
2023-01-10 20:29:07,723 - mmseg - INFO - Iter [18900/40000]	lr: 3.165e-05, eta: 7:19:35, time: 1.229, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1110, decode.acc_seg: 87.4771, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1268, mix.decode.acc_seg: 88.6178, masked.decode.loss_seg: 0.1706, masked.decode.acc_seg: 90.9944
2023-01-10 20:30:08,920 - mmseg - INFO - Iter [18950/40000]	lr: 3.158e-05, eta: 7:18:31, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1409, decode.acc_seg: 88.3651, src.loss_imnet_feat_dist: 0.1041, mix.decode.loss_seg: 0.1398, mix.decode.acc_seg: 91.2347, masked.decode.loss_seg: 0.1568, masked.decode.acc_seg: 91.4166
2023-01-10 20:31:09,917 - mmseg - INFO - Exp name: 230110_1355_230110_1343_gta2cs_dacs_a999_fdthings_rcs001_cpl_m32-07-spta_daformer_sepaspp_mitb5_poly10warm_s0_2feea_f2bea
2023-01-10 20:31:09,917 - mmseg - INFO - Iter [19000/40000]	lr: 3.150e-05, eta: 7:17:26, time: 1.220, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1091, decode.acc_seg: 88.0739, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1296, mix.decode.acc_seg: 89.3994, masked.decode.loss_seg: 0.1774, masked.decode.acc_seg: 90.4748
2023-01-10 20:32:15,134 - mmseg - INFO - Iter [19050/40000]	lr: 3.143e-05, eta: 7:16:27, time: 1.304, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1190, decode.acc_seg: 87.2508, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1359, mix.decode.acc_seg: 88.7327, masked.decode.loss_seg: 0.1672, masked.decode.acc_seg: 91.3180
2023-01-10 20:33:16,196 - mmseg - INFO - Iter [19100/40000]	lr: 3.135e-05, eta: 7:15:23, time: 1.221, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1110, decode.acc_seg: 87.6672, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1259, mix.decode.acc_seg: 89.4898, masked.decode.loss_seg: 0.1657, masked.decode.acc_seg: 91.7060
2023-01-10 20:34:17,504 - mmseg - INFO - Iter [19150/40000]	lr: 3.128e-05, eta: 7:14:19, time: 1.226, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1205, decode.acc_seg: 86.2895, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1576, mix.decode.acc_seg: 88.9792, masked.decode.loss_seg: 0.1688, masked.decode.acc_seg: 91.6359
2023-01-10 20:35:18,800 - mmseg - INFO - Iter [19200/40000]	lr: 3.120e-05, eta: 7:13:15, time: 1.226, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1295, decode.acc_seg: 87.2485, src.loss_imnet_feat_dist: 0.1148, mix.decode.loss_seg: 0.1508, mix.decode.acc_seg: 90.4252, masked.decode.loss_seg: 0.1684, masked.decode.acc_seg: 90.9332
2023-01-10 20:36:20,165 - mmseg - INFO - Iter [19250/40000]	lr: 3.113e-05, eta: 7:12:12, time: 1.227, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1325, decode.acc_seg: 87.9211, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1593, mix.decode.acc_seg: 90.1999, masked.decode.loss_seg: 0.1846, masked.decode.acc_seg: 90.3012
2023-01-10 20:37:21,445 - mmseg - INFO - Iter [19300/40000]	lr: 3.105e-05, eta: 7:11:08, time: 1.226, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1201, decode.acc_seg: 88.5896, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1345, mix.decode.acc_seg: 90.1394, masked.decode.loss_seg: 0.1744, masked.decode.acc_seg: 90.7136
2023-01-10 20:38:22,654 - mmseg - INFO - Iter [19350/40000]	lr: 3.098e-05, eta: 7:10:04, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1140, decode.acc_seg: 89.1105, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1223, mix.decode.acc_seg: 90.7163, masked.decode.loss_seg: 0.1739, masked.decode.acc_seg: 90.9170
2023-01-10 20:39:23,689 - mmseg - INFO - Iter [19400/40000]	lr: 3.090e-05, eta: 7:09:00, time: 1.221, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1127, decode.acc_seg: 87.9699, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1234, mix.decode.acc_seg: 90.2321, masked.decode.loss_seg: 0.1746, masked.decode.acc_seg: 90.8011
2023-01-10 20:40:24,877 - mmseg - INFO - Iter [19450/40000]	lr: 3.083e-05, eta: 7:07:56, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1102, decode.acc_seg: 87.2899, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1245, mix.decode.acc_seg: 90.8177, masked.decode.loss_seg: 0.1733, masked.decode.acc_seg: 90.8068
2023-01-10 20:41:25,915 - mmseg - INFO - Iter [19500/40000]	lr: 3.075e-05, eta: 7:06:52, time: 1.221, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1406, decode.acc_seg: 88.3175, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1321, mix.decode.acc_seg: 90.6007, masked.decode.loss_seg: 0.1722, masked.decode.acc_seg: 90.8915
2023-01-10 20:42:27,192 - mmseg - INFO - Iter [19550/40000]	lr: 3.068e-05, eta: 7:05:48, time: 1.226, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1177, decode.acc_seg: 86.3565, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1426, mix.decode.acc_seg: 89.8309, masked.decode.loss_seg: 0.1700, masked.decode.acc_seg: 91.5966
2023-01-10 20:43:28,857 - mmseg - INFO - Iter [19600/40000]	lr: 3.060e-05, eta: 7:04:45, time: 1.233, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1618, decode.acc_seg: 87.3682, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1585, mix.decode.acc_seg: 89.7008, masked.decode.loss_seg: 0.1641, masked.decode.acc_seg: 91.0400
2023-01-10 20:44:30,093 - mmseg - INFO - Iter [19650/40000]	lr: 3.053e-05, eta: 7:03:41, time: 1.225, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1202, decode.acc_seg: 88.2547, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1354, mix.decode.acc_seg: 90.4449, masked.decode.loss_seg: 0.1783, masked.decode.acc_seg: 90.8738
2023-01-10 20:45:30,963 - mmseg - INFO - Iter [19700/40000]	lr: 3.045e-05, eta: 7:02:37, time: 1.217, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1469, decode.acc_seg: 87.6510, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1607, mix.decode.acc_seg: 88.4008, masked.decode.loss_seg: 0.1739, masked.decode.acc_seg: 90.8582
2023-01-10 20:46:32,080 - mmseg - INFO - Iter [19750/40000]	lr: 3.038e-05, eta: 7:01:33, time: 1.222, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1196, decode.acc_seg: 89.1393, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1289, mix.decode.acc_seg: 91.3994, masked.decode.loss_seg: 0.1576, masked.decode.acc_seg: 91.6720
2023-01-10 20:47:33,253 - mmseg - INFO - Iter [19800/40000]	lr: 3.030e-05, eta: 7:00:30, time: 1.223, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1141, decode.acc_seg: 87.6946, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1358, mix.decode.acc_seg: 89.2915, masked.decode.loss_seg: 0.1639, masked.decode.acc_seg: 91.3753
2023-01-10 20:48:34,255 - mmseg - INFO - Iter [19850/40000]	lr: 3.023e-05, eta: 6:59:26, time: 1.220, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1175, decode.acc_seg: 87.7577, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1262, mix.decode.acc_seg: 89.0367, masked.decode.loss_seg: 0.1613, masked.decode.acc_seg: 91.5467
2023-01-10 20:49:35,599 - mmseg - INFO - Iter [19900/40000]	lr: 3.015e-05, eta: 6:58:22, time: 1.227, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1120, decode.acc_seg: 88.7254, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1320, mix.decode.acc_seg: 89.4894, masked.decode.loss_seg: 0.1656, masked.decode.acc_seg: 91.0889
2023-01-10 20:50:36,583 - mmseg - INFO - Iter [19950/40000]	lr: 3.008e-05, eta: 6:57:18, time: 1.220, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1455, decode.acc_seg: 87.4383, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1258, mix.decode.acc_seg: 89.7323, masked.decode.loss_seg: 0.1669, masked.decode.acc_seg: 90.7476
2023-01-10 20:52:54,183 - mmseg - INFO - per class results:
2023-01-10 20:52:54,225 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      road     |  96.7 | 98.71 |
|    sidewalk   | 75.47 | 84.89 |
|    building   | 88.97 | 94.33 |
|      wall     | 50.43 | 70.03 |
|     fence     | 42.47 | 46.86 |
|      pole     |  48.1 | 56.14 |
| traffic light | 53.79 | 73.27 |
|  traffic sign |  59.4 | 65.53 |
|   vegetation  | 89.94 | 95.77 |
|    terrain    | 51.13 | 59.84 |
|      sky      | 91.27 | 99.05 |
|     person    | 70.63 |  85.5 |
|     rider     | 44.86 | 63.24 |
|      car      | 91.61 | 95.64 |
|     truck     |  71.1 | 88.63 |
|      bus      | 81.09 |  86.6 |
|     train     | 67.75 | 78.85 |
|   motorcycle  | 53.44 | 76.23 |
|    bicycle    |  62.8 | 78.56 |
+---------------+-------+-------+
2023-01-10 20:52:54,225 - mmseg - INFO - Summary:
2023-01-10 20:52:54,226 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 93.94 | 67.94 | 78.82 |
+-------+-------+-------+
2023-01-10 20:52:54,262 - mmseg - INFO - Exp name: 230110_1355_230110_1343_gta2cs_dacs_a999_fdthings_rcs001_cpl_m32-07-spta_daformer_sepaspp_mitb5_poly10warm_s0_2feea_f2bea
2023-01-10 20:52:54,263 - mmseg - INFO - Iter [500/40000]	lr: 3.000e-05, eta: 6:56:15, time: 1.227, data_time: 0.011, memory: 9807, aAcc: 0.9394, mIoU: 0.6794, mAcc: 0.7882, IoU.road: 0.9670, IoU.sidewalk: 0.7547, IoU.building: 0.8897, IoU.wall: 0.5043, IoU.fence: 0.4247, IoU.pole: 0.4810, IoU.traffic light: 0.5379, IoU.traffic sign: 0.5940, IoU.vegetation: 0.8994, IoU.terrain: 0.5113, IoU.sky: 0.9127, IoU.person: 0.7063, IoU.rider: 0.4486, IoU.car: 0.9161, IoU.truck: 0.7110, IoU.bus: 0.8109, IoU.train: 0.6775, IoU.motorcycle: 0.5344, IoU.bicycle: 0.6280, Acc.road: 0.9871, Acc.sidewalk: 0.8489, Acc.building: 0.9433, Acc.wall: 0.7003, Acc.fence: 0.4686, Acc.pole: 0.5614, Acc.traffic light: 0.7327, Acc.traffic sign: 0.6553, Acc.vegetation: 0.9577, Acc.terrain: 0.5984, Acc.sky: 0.9905, Acc.person: 0.8550, Acc.rider: 0.6324, Acc.car: 0.9564, Acc.truck: 0.8863, Acc.bus: 0.8660, Acc.train: 0.7885, Acc.motorcycle: 0.7623, Acc.bicycle: 0.7856, decode.loss_seg: 0.1162, decode.acc_seg: 88.3546, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1333, mix.decode.acc_seg: 91.2657, masked.decode.loss_seg: 0.1549, masked.decode.acc_seg: 91.4671
2023-01-10 20:54:00,669 - mmseg - INFO - Iter [20050/40000]	lr: 2.993e-05, eta: 6:56:32, time: 2.855, data_time: 1.538, memory: 9807, decode.loss_seg: 0.1147, decode.acc_seg: 88.3828, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1219, mix.decode.acc_seg: 90.9970, masked.decode.loss_seg: 0.1642, masked.decode.acc_seg: 91.4483
2023-01-10 20:55:01,795 - mmseg - INFO - Iter [20100/40000]	lr: 2.985e-05, eta: 6:55:28, time: 1.223, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1233, decode.acc_seg: 88.2066, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1442, mix.decode.acc_seg: 89.8370, masked.decode.loss_seg: 0.1712, masked.decode.acc_seg: 91.3103
2023-01-10 20:56:03,473 - mmseg - INFO - Iter [20150/40000]	lr: 2.978e-05, eta: 6:54:25, time: 1.234, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1168, decode.acc_seg: 87.6747, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1323, mix.decode.acc_seg: 91.2344, masked.decode.loss_seg: 0.1646, masked.decode.acc_seg: 91.0758
2023-01-10 20:57:04,802 - mmseg - INFO - Iter [20200/40000]	lr: 2.970e-05, eta: 6:53:21, time: 1.227, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1207, decode.acc_seg: 87.7540, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1480, mix.decode.acc_seg: 90.1587, masked.decode.loss_seg: 0.1694, masked.decode.acc_seg: 90.6816
2023-01-10 20:58:06,056 - mmseg - INFO - Iter [20250/40000]	lr: 2.963e-05, eta: 6:52:17, time: 1.225, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1173, decode.acc_seg: 88.5091, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1248, mix.decode.acc_seg: 90.6994, masked.decode.loss_seg: 0.1724, masked.decode.acc_seg: 91.0007
2023-01-10 20:59:07,052 - mmseg - INFO - Iter [20300/40000]	lr: 2.955e-05, eta: 6:51:12, time: 1.220, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1064, decode.acc_seg: 88.1898, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1192, mix.decode.acc_seg: 90.2523, masked.decode.loss_seg: 0.1706, masked.decode.acc_seg: 91.0088
2023-01-10 21:00:08,280 - mmseg - INFO - Iter [20350/40000]	lr: 2.948e-05, eta: 6:50:08, time: 1.225, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1430, decode.acc_seg: 88.0474, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1575, mix.decode.acc_seg: 89.3728, masked.decode.loss_seg: 0.1660, masked.decode.acc_seg: 91.0293
2023-01-10 21:01:09,098 - mmseg - INFO - Iter [20400/40000]	lr: 2.940e-05, eta: 6:49:04, time: 1.216, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1259, decode.acc_seg: 88.3017, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1330, mix.decode.acc_seg: 90.9838, masked.decode.loss_seg: 0.1642, masked.decode.acc_seg: 91.4161
2023-01-10 21:02:10,982 - mmseg - INFO - Iter [20450/40000]	lr: 2.933e-05, eta: 6:48:01, time: 1.238, data_time: 0.024, memory: 9807, decode.loss_seg: 0.1180, decode.acc_seg: 87.3991, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1240, mix.decode.acc_seg: 88.7627, masked.decode.loss_seg: 0.1679, masked.decode.acc_seg: 90.5981
2023-01-10 21:03:12,095 - mmseg - INFO - Iter [20500/40000]	lr: 2.925e-05, eta: 6:46:57, time: 1.222, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1246, decode.acc_seg: 87.4038, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1363, mix.decode.acc_seg: 89.9375, masked.decode.loss_seg: 0.1729, masked.decode.acc_seg: 90.3183
2023-01-10 21:04:13,424 - mmseg - INFO - Iter [20550/40000]	lr: 2.918e-05, eta: 6:45:53, time: 1.227, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1186, decode.acc_seg: 88.5547, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1243, mix.decode.acc_seg: 91.0304, masked.decode.loss_seg: 0.1594, masked.decode.acc_seg: 91.3018
2023-01-10 21:05:14,505 - mmseg - INFO - Iter [20600/40000]	lr: 2.910e-05, eta: 6:44:49, time: 1.222, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1155, decode.acc_seg: 87.8553, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1428, mix.decode.acc_seg: 89.6905, masked.decode.loss_seg: 0.1661, masked.decode.acc_seg: 91.1536
2023-01-10 21:06:15,573 - mmseg - INFO - Iter [20650/40000]	lr: 2.903e-05, eta: 6:43:45, time: 1.221, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1390, decode.acc_seg: 87.3553, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1404, mix.decode.acc_seg: 91.4260, masked.decode.loss_seg: 0.1676, masked.decode.acc_seg: 91.5742
2023-01-10 21:07:16,721 - mmseg - INFO - Iter [20700/40000]	lr: 2.895e-05, eta: 6:42:41, time: 1.223, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1354, decode.acc_seg: 87.2497, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1502, mix.decode.acc_seg: 89.3527, masked.decode.loss_seg: 0.1631, masked.decode.acc_seg: 91.4179
2023-01-10 21:08:17,751 - mmseg - INFO - Iter [20750/40000]	lr: 2.888e-05, eta: 6:41:37, time: 1.221, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1171, decode.acc_seg: 87.8646, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1539, mix.decode.acc_seg: 87.8581, masked.decode.loss_seg: 0.1665, masked.decode.acc_seg: 90.5690
2023-01-10 21:09:18,862 - mmseg - INFO - Iter [20800/40000]	lr: 2.880e-05, eta: 6:40:33, time: 1.222, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1205, decode.acc_seg: 89.1534, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1368, mix.decode.acc_seg: 89.9793, masked.decode.loss_seg: 0.1743, masked.decode.acc_seg: 91.1472
2023-01-10 21:10:20,352 - mmseg - INFO - Iter [20850/40000]	lr: 2.873e-05, eta: 6:39:29, time: 1.230, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1055, decode.acc_seg: 90.0486, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1273, mix.decode.acc_seg: 90.6770, masked.decode.loss_seg: 0.1701, masked.decode.acc_seg: 90.7946
2023-01-10 21:11:21,949 - mmseg - INFO - Iter [20900/40000]	lr: 2.865e-05, eta: 6:38:26, time: 1.232, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1271, decode.acc_seg: 88.0733, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1340, mix.decode.acc_seg: 90.2595, masked.decode.loss_seg: 0.1648, masked.decode.acc_seg: 91.0558
2023-01-10 21:12:23,648 - mmseg - INFO - Iter [20950/40000]	lr: 2.858e-05, eta: 6:37:22, time: 1.234, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1557, decode.acc_seg: 89.0488, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1563, mix.decode.acc_seg: 90.2647, masked.decode.loss_seg: 0.1664, masked.decode.acc_seg: 91.4595
2023-01-10 21:13:25,054 - mmseg - INFO - Exp name: 230110_1355_230110_1343_gta2cs_dacs_a999_fdthings_rcs001_cpl_m32-07-spta_daformer_sepaspp_mitb5_poly10warm_s0_2feea_f2bea
2023-01-10 21:13:25,055 - mmseg - INFO - Iter [21000/40000]	lr: 2.850e-05, eta: 6:36:19, time: 1.228, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1333, decode.acc_seg: 88.1062, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1269, mix.decode.acc_seg: 90.0700, masked.decode.loss_seg: 0.1564, masked.decode.acc_seg: 92.0048
2023-01-10 21:14:33,645 - mmseg - INFO - Iter [21050/40000]	lr: 2.843e-05, eta: 6:35:22, time: 1.372, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1237, decode.acc_seg: 87.9470, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1276, mix.decode.acc_seg: 91.0038, masked.decode.loss_seg: 0.1708, masked.decode.acc_seg: 91.1217
2023-01-10 21:15:34,571 - mmseg - INFO - Iter [21100/40000]	lr: 2.835e-05, eta: 6:34:18, time: 1.219, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1121, decode.acc_seg: 89.0361, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1276, mix.decode.acc_seg: 91.4171, masked.decode.loss_seg: 0.1658, masked.decode.acc_seg: 91.1039
2023-01-10 21:16:35,791 - mmseg - INFO - Iter [21150/40000]	lr: 2.828e-05, eta: 6:33:14, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1078, decode.acc_seg: 84.9304, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1236, mix.decode.acc_seg: 87.2603, masked.decode.loss_seg: 0.1717, masked.decode.acc_seg: 90.7270
2023-01-10 21:17:37,611 - mmseg - INFO - Iter [21200/40000]	lr: 2.820e-05, eta: 6:32:11, time: 1.236, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1132, decode.acc_seg: 89.0636, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1349, mix.decode.acc_seg: 89.7509, masked.decode.loss_seg: 0.1729, masked.decode.acc_seg: 91.0903
2023-01-10 21:18:39,220 - mmseg - INFO - Iter [21250/40000]	lr: 2.813e-05, eta: 6:31:07, time: 1.232, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1263, decode.acc_seg: 88.5927, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1397, mix.decode.acc_seg: 90.8239, masked.decode.loss_seg: 0.1785, masked.decode.acc_seg: 90.5900
2023-01-10 21:19:40,743 - mmseg - INFO - Iter [21300/40000]	lr: 2.805e-05, eta: 6:30:04, time: 1.230, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1147, decode.acc_seg: 88.2311, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1227, mix.decode.acc_seg: 89.2783, masked.decode.loss_seg: 0.1734, masked.decode.acc_seg: 90.6128
2023-01-10 21:20:41,718 - mmseg - INFO - Iter [21350/40000]	lr: 2.798e-05, eta: 6:29:00, time: 1.219, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1364, decode.acc_seg: 86.7055, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1311, mix.decode.acc_seg: 89.6781, masked.decode.loss_seg: 0.1757, masked.decode.acc_seg: 91.1378
2023-01-10 21:21:43,028 - mmseg - INFO - Iter [21400/40000]	lr: 2.790e-05, eta: 6:27:56, time: 1.226, data_time: 0.016, memory: 9807, decode.loss_seg: 0.1196, decode.acc_seg: 87.8233, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1339, mix.decode.acc_seg: 89.6615, masked.decode.loss_seg: 0.1807, masked.decode.acc_seg: 90.4294
2023-01-10 21:22:44,000 - mmseg - INFO - Iter [21450/40000]	lr: 2.783e-05, eta: 6:26:52, time: 1.219, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1211, decode.acc_seg: 87.5817, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1280, mix.decode.acc_seg: 89.0624, masked.decode.loss_seg: 0.1721, masked.decode.acc_seg: 90.8385
2023-01-10 21:23:44,989 - mmseg - INFO - Iter [21500/40000]	lr: 2.775e-05, eta: 6:25:48, time: 1.220, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1324, decode.acc_seg: 88.2848, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1286, mix.decode.acc_seg: 90.1627, masked.decode.loss_seg: 0.1659, masked.decode.acc_seg: 91.2281
2023-01-10 21:24:46,420 - mmseg - INFO - Iter [21550/40000]	lr: 2.768e-05, eta: 6:24:44, time: 1.229, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1283, decode.acc_seg: 88.1415, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1589, mix.decode.acc_seg: 88.9790, masked.decode.loss_seg: 0.1715, masked.decode.acc_seg: 90.8512
2023-01-10 21:25:47,589 - mmseg - INFO - Iter [21600/40000]	lr: 2.760e-05, eta: 6:23:41, time: 1.223, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1147, decode.acc_seg: 87.4375, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1282, mix.decode.acc_seg: 90.1225, masked.decode.loss_seg: 0.1693, masked.decode.acc_seg: 91.0551
2023-01-10 21:26:49,005 - mmseg - INFO - Iter [21650/40000]	lr: 2.753e-05, eta: 6:22:37, time: 1.228, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1175, decode.acc_seg: 89.1817, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1341, mix.decode.acc_seg: 90.3893, masked.decode.loss_seg: 0.1754, masked.decode.acc_seg: 90.6563
2023-01-10 21:27:50,219 - mmseg - INFO - Iter [21700/40000]	lr: 2.745e-05, eta: 6:21:34, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1163, decode.acc_seg: 88.2413, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1220, mix.decode.acc_seg: 90.6762, masked.decode.loss_seg: 0.1734, masked.decode.acc_seg: 90.7367
2023-01-10 21:28:51,481 - mmseg - INFO - Iter [21750/40000]	lr: 2.738e-05, eta: 6:20:30, time: 1.225, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1331, decode.acc_seg: 87.1291, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1596, mix.decode.acc_seg: 89.8038, masked.decode.loss_seg: 0.1643, masked.decode.acc_seg: 90.9894
2023-01-10 21:29:52,514 - mmseg - INFO - Iter [21800/40000]	lr: 2.730e-05, eta: 6:19:26, time: 1.221, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1232, decode.acc_seg: 90.0638, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1341, mix.decode.acc_seg: 91.0430, masked.decode.loss_seg: 0.1756, masked.decode.acc_seg: 90.8931
2023-01-10 21:30:54,119 - mmseg - INFO - Iter [21850/40000]	lr: 2.723e-05, eta: 6:18:23, time: 1.232, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1250, decode.acc_seg: 87.0164, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1348, mix.decode.acc_seg: 89.9450, masked.decode.loss_seg: 0.1726, masked.decode.acc_seg: 90.8488
2023-01-10 21:31:55,419 - mmseg - INFO - Iter [21900/40000]	lr: 2.715e-05, eta: 6:17:19, time: 1.226, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1332, decode.acc_seg: 87.4558, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1288, mix.decode.acc_seg: 90.3240, masked.decode.loss_seg: 0.1709, masked.decode.acc_seg: 90.7956
2023-01-10 21:32:56,560 - mmseg - INFO - Iter [21950/40000]	lr: 2.708e-05, eta: 6:16:16, time: 1.223, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1273, decode.acc_seg: 87.5495, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1732, mix.decode.acc_seg: 89.2907, masked.decode.loss_seg: 0.1725, masked.decode.acc_seg: 90.1103
2023-01-10 21:33:57,465 - mmseg - INFO - Exp name: 230110_1355_230110_1343_gta2cs_dacs_a999_fdthings_rcs001_cpl_m32-07-spta_daformer_sepaspp_mitb5_poly10warm_s0_2feea_f2bea
2023-01-10 21:33:57,466 - mmseg - INFO - Iter [22000/40000]	lr: 2.700e-05, eta: 6:15:12, time: 1.218, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1112, decode.acc_seg: 88.6928, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1210, mix.decode.acc_seg: 91.0652, masked.decode.loss_seg: 0.1666, masked.decode.acc_seg: 90.4127
2023-01-10 21:35:03,010 - mmseg - INFO - Iter [22050/40000]	lr: 2.693e-05, eta: 6:14:12, time: 1.311, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1170, decode.acc_seg: 87.4230, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1263, mix.decode.acc_seg: 90.3106, masked.decode.loss_seg: 0.1646, masked.decode.acc_seg: 90.7954
2023-01-10 21:36:04,128 - mmseg - INFO - Iter [22100/40000]	lr: 2.685e-05, eta: 6:13:08, time: 1.222, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1301, decode.acc_seg: 88.1164, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1315, mix.decode.acc_seg: 90.4266, masked.decode.loss_seg: 0.1552, masked.decode.acc_seg: 91.5043
2023-01-10 21:37:05,356 - mmseg - INFO - Iter [22150/40000]	lr: 2.678e-05, eta: 6:12:04, time: 1.225, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1117, decode.acc_seg: 88.2688, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1252, mix.decode.acc_seg: 90.0545, masked.decode.loss_seg: 0.1622, masked.decode.acc_seg: 91.0710
2023-01-10 21:38:06,483 - mmseg - INFO - Iter [22200/40000]	lr: 2.670e-05, eta: 6:11:01, time: 1.223, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1716, decode.acc_seg: 88.7472, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1337, mix.decode.acc_seg: 90.6695, masked.decode.loss_seg: 0.1712, masked.decode.acc_seg: 90.9520
2023-01-10 21:39:07,743 - mmseg - INFO - Iter [22250/40000]	lr: 2.663e-05, eta: 6:09:57, time: 1.225, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1816, decode.acc_seg: 87.0129, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1928, mix.decode.acc_seg: 88.6417, masked.decode.loss_seg: 0.1666, masked.decode.acc_seg: 90.2523
2023-01-10 21:40:09,142 - mmseg - INFO - Iter [22300/40000]	lr: 2.655e-05, eta: 6:08:54, time: 1.228, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1156, decode.acc_seg: 88.7432, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1353, mix.decode.acc_seg: 89.5470, masked.decode.loss_seg: 0.1817, masked.decode.acc_seg: 89.2086
2023-01-10 21:41:10,750 - mmseg - INFO - Iter [22350/40000]	lr: 2.648e-05, eta: 6:07:50, time: 1.232, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1123, decode.acc_seg: 88.6909, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1265, mix.decode.acc_seg: 90.5861, masked.decode.loss_seg: 0.1751, masked.decode.acc_seg: 90.0544
2023-01-10 21:42:12,054 - mmseg - INFO - Iter [22400/40000]	lr: 2.640e-05, eta: 6:06:47, time: 1.226, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1170, decode.acc_seg: 87.9818, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1378, mix.decode.acc_seg: 89.2081, masked.decode.loss_seg: 0.1599, masked.decode.acc_seg: 90.4545
2023-01-10 21:43:13,665 - mmseg - INFO - Iter [22450/40000]	lr: 2.633e-05, eta: 6:05:44, time: 1.232, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1221, decode.acc_seg: 89.2464, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1379, mix.decode.acc_seg: 89.7872, masked.decode.loss_seg: 0.1646, masked.decode.acc_seg: 90.7343
2023-01-10 21:44:14,671 - mmseg - INFO - Iter [22500/40000]	lr: 2.625e-05, eta: 6:04:40, time: 1.220, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1199, decode.acc_seg: 87.4757, src.loss_imnet_feat_dist: 0.1067, mix.decode.loss_seg: 0.1338, mix.decode.acc_seg: 89.9156, masked.decode.loss_seg: 0.1683, masked.decode.acc_seg: 90.9943
2023-01-10 21:45:15,859 - mmseg - INFO - Iter [22550/40000]	lr: 2.618e-05, eta: 6:03:36, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1048, decode.acc_seg: 89.5439, src.loss_imnet_feat_dist: 0.1083, mix.decode.loss_seg: 0.1235, mix.decode.acc_seg: 90.7299, masked.decode.loss_seg: 0.1731, masked.decode.acc_seg: 90.5733
2023-01-10 21:46:17,309 - mmseg - INFO - Iter [22600/40000]	lr: 2.610e-05, eta: 6:02:33, time: 1.229, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1123, decode.acc_seg: 89.9713, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1342, mix.decode.acc_seg: 90.7037, masked.decode.loss_seg: 0.1571, masked.decode.acc_seg: 91.3163
2023-01-10 21:47:18,347 - mmseg - INFO - Iter [22650/40000]	lr: 2.603e-05, eta: 6:01:29, time: 1.221, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1121, decode.acc_seg: 89.1684, src.loss_imnet_feat_dist: 0.1031, mix.decode.loss_seg: 0.1198, mix.decode.acc_seg: 90.6436, masked.decode.loss_seg: 0.1673, masked.decode.acc_seg: 90.4314
2023-01-10 21:48:19,750 - mmseg - INFO - Iter [22700/40000]	lr: 2.595e-05, eta: 6:00:26, time: 1.228, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1102, decode.acc_seg: 89.1729, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1257, mix.decode.acc_seg: 90.0640, masked.decode.loss_seg: 0.1680, masked.decode.acc_seg: 90.5092
2023-01-10 21:49:21,113 - mmseg - INFO - Iter [22750/40000]	lr: 2.588e-05, eta: 5:59:23, time: 1.227, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1126, decode.acc_seg: 88.4894, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1212, mix.decode.acc_seg: 89.6880, masked.decode.loss_seg: 0.1673, masked.decode.acc_seg: 90.4423
2023-01-10 21:50:22,275 - mmseg - INFO - Iter [22800/40000]	lr: 2.580e-05, eta: 5:58:19, time: 1.223, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1243, decode.acc_seg: 86.7417, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1390, mix.decode.acc_seg: 88.2154, masked.decode.loss_seg: 0.1750, masked.decode.acc_seg: 89.5160
2023-01-10 21:51:23,609 - mmseg - INFO - Iter [22850/40000]	lr: 2.573e-05, eta: 5:57:16, time: 1.227, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1387, decode.acc_seg: 86.3580, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1536, mix.decode.acc_seg: 88.1381, masked.decode.loss_seg: 0.1668, masked.decode.acc_seg: 90.1776
2023-01-10 21:52:25,324 - mmseg - INFO - Iter [22900/40000]	lr: 2.565e-05, eta: 5:56:13, time: 1.234, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1094, decode.acc_seg: 88.7133, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1201, mix.decode.acc_seg: 90.0911, masked.decode.loss_seg: 0.1766, masked.decode.acc_seg: 90.2869
2023-01-10 21:53:26,873 - mmseg - INFO - Iter [22950/40000]	lr: 2.558e-05, eta: 5:55:10, time: 1.231, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1031, decode.acc_seg: 88.5104, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1182, mix.decode.acc_seg: 89.5158, masked.decode.loss_seg: 0.1678, masked.decode.acc_seg: 89.6291
2023-01-10 21:54:27,927 - mmseg - INFO - Exp name: 230110_1355_230110_1343_gta2cs_dacs_a999_fdthings_rcs001_cpl_m32-07-spta_daformer_sepaspp_mitb5_poly10warm_s0_2feea_f2bea
2023-01-10 21:54:27,927 - mmseg - INFO - Iter [23000/40000]	lr: 2.550e-05, eta: 5:54:06, time: 1.221, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1089, decode.acc_seg: 87.2934, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1244, mix.decode.acc_seg: 90.0259, masked.decode.loss_seg: 0.1650, masked.decode.acc_seg: 90.4038
2023-01-10 21:55:33,242 - mmseg - INFO - Iter [23050/40000]	lr: 2.543e-05, eta: 5:53:06, time: 1.306, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1331, decode.acc_seg: 89.3853, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1311, mix.decode.acc_seg: 90.2470, masked.decode.loss_seg: 0.1636, masked.decode.acc_seg: 90.4722
2023-01-10 21:56:34,438 - mmseg - INFO - Iter [23100/40000]	lr: 2.535e-05, eta: 5:52:02, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1144, decode.acc_seg: 88.7537, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1182, mix.decode.acc_seg: 90.3381, masked.decode.loss_seg: 0.1674, masked.decode.acc_seg: 90.1492
2023-01-10 21:57:35,954 - mmseg - INFO - Iter [23150/40000]	lr: 2.528e-05, eta: 5:50:59, time: 1.230, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1116, decode.acc_seg: 88.0929, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1272, mix.decode.acc_seg: 89.5811, masked.decode.loss_seg: 0.1777, masked.decode.acc_seg: 90.1605
2023-01-10 21:58:37,357 - mmseg - INFO - Iter [23200/40000]	lr: 2.520e-05, eta: 5:49:56, time: 1.228, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1031, decode.acc_seg: 90.4249, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1239, mix.decode.acc_seg: 91.7292, masked.decode.loss_seg: 0.1569, masked.decode.acc_seg: 91.1640
2023-01-10 21:59:38,508 - mmseg - INFO - Iter [23250/40000]	lr: 2.513e-05, eta: 5:48:52, time: 1.223, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1182, decode.acc_seg: 88.0502, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1227, mix.decode.acc_seg: 90.1281, masked.decode.loss_seg: 0.1605, masked.decode.acc_seg: 90.5479
2023-01-10 22:00:39,607 - mmseg - INFO - Iter [23300/40000]	lr: 2.505e-05, eta: 5:47:49, time: 1.222, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1164, decode.acc_seg: 87.4176, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1277, mix.decode.acc_seg: 89.4528, masked.decode.loss_seg: 0.1634, masked.decode.acc_seg: 90.4357
2023-01-10 22:01:40,956 - mmseg - INFO - Iter [23350/40000]	lr: 2.498e-05, eta: 5:46:45, time: 1.227, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1061, decode.acc_seg: 88.9601, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1300, mix.decode.acc_seg: 88.3116, masked.decode.loss_seg: 0.1824, masked.decode.acc_seg: 88.9374
2023-01-10 22:02:42,485 - mmseg - INFO - Iter [23400/40000]	lr: 2.490e-05, eta: 5:45:42, time: 1.231, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1324, decode.acc_seg: 87.2259, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1225, mix.decode.acc_seg: 88.5231, masked.decode.loss_seg: 0.1705, masked.decode.acc_seg: 90.0593
2023-01-10 22:03:43,584 - mmseg - INFO - Iter [23450/40000]	lr: 2.483e-05, eta: 5:44:39, time: 1.222, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1454, decode.acc_seg: 87.1936, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1269, mix.decode.acc_seg: 90.0511, masked.decode.loss_seg: 0.1593, masked.decode.acc_seg: 90.7663
2023-01-10 22:04:44,866 - mmseg - INFO - Iter [23500/40000]	lr: 2.475e-05, eta: 5:43:36, time: 1.226, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0945, decode.acc_seg: 89.3746, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1145, mix.decode.acc_seg: 90.0269, masked.decode.loss_seg: 0.1789, masked.decode.acc_seg: 88.8309
2023-01-10 22:05:45,779 - mmseg - INFO - Iter [23550/40000]	lr: 2.468e-05, eta: 5:42:32, time: 1.218, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1357, decode.acc_seg: 87.8635, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1482, mix.decode.acc_seg: 89.8031, masked.decode.loss_seg: 0.1625, masked.decode.acc_seg: 90.1045
2023-01-10 22:06:46,692 - mmseg - INFO - Iter [23600/40000]	lr: 2.460e-05, eta: 5:41:28, time: 1.218, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1220, decode.acc_seg: 87.1833, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1320, mix.decode.acc_seg: 88.4857, masked.decode.loss_seg: 0.1672, masked.decode.acc_seg: 89.9649
2023-01-10 22:07:47,685 - mmseg - INFO - Iter [23650/40000]	lr: 2.453e-05, eta: 5:40:25, time: 1.220, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1098, decode.acc_seg: 88.0343, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1275, mix.decode.acc_seg: 90.1924, masked.decode.loss_seg: 0.1754, masked.decode.acc_seg: 89.2358
2023-01-10 22:08:48,803 - mmseg - INFO - Iter [23700/40000]	lr: 2.445e-05, eta: 5:39:22, time: 1.222, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1107, decode.acc_seg: 89.1852, src.loss_imnet_feat_dist: 0.1081, mix.decode.loss_seg: 0.1265, mix.decode.acc_seg: 90.2423, masked.decode.loss_seg: 0.1543, masked.decode.acc_seg: 91.1109
2023-01-10 22:09:49,707 - mmseg - INFO - Iter [23750/40000]	lr: 2.438e-05, eta: 5:38:18, time: 1.218, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1114, decode.acc_seg: 88.1564, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1278, mix.decode.acc_seg: 90.7049, masked.decode.loss_seg: 0.1648, masked.decode.acc_seg: 90.2495
2023-01-10 22:10:51,227 - mmseg - INFO - Iter [23800/40000]	lr: 2.430e-05, eta: 5:37:15, time: 1.230, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1138, decode.acc_seg: 87.8554, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1260, mix.decode.acc_seg: 90.3983, masked.decode.loss_seg: 0.1558, masked.decode.acc_seg: 90.9324
2023-01-10 22:11:52,314 - mmseg - INFO - Iter [23850/40000]	lr: 2.423e-05, eta: 5:36:12, time: 1.222, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1097, decode.acc_seg: 88.7354, src.loss_imnet_feat_dist: 0.1039, mix.decode.loss_seg: 0.1286, mix.decode.acc_seg: 90.2665, masked.decode.loss_seg: 0.1672, masked.decode.acc_seg: 90.1023
2023-01-10 22:12:53,717 - mmseg - INFO - Iter [23900/40000]	lr: 2.415e-05, eta: 5:35:08, time: 1.228, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1199, decode.acc_seg: 88.0023, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1217, mix.decode.acc_seg: 89.2293, masked.decode.loss_seg: 0.1538, masked.decode.acc_seg: 90.4592
2023-01-10 22:13:54,872 - mmseg - INFO - Iter [23950/40000]	lr: 2.408e-05, eta: 5:34:05, time: 1.223, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1070, decode.acc_seg: 87.7604, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1174, mix.decode.acc_seg: 89.9061, masked.decode.loss_seg: 0.1664, masked.decode.acc_seg: 90.1198
2023-01-10 22:16:12,115 - mmseg - INFO - per class results:
2023-01-10 22:16:12,173 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      road     |  96.9 | 99.22 |
|    sidewalk   | 76.32 | 82.76 |
|    building   | 89.28 | 94.21 |
|      wall     | 52.56 |  71.6 |
|     fence     | 43.25 | 46.41 |
|      pole     | 49.67 | 58.06 |
| traffic light | 54.71 | 73.25 |
|  traffic sign | 59.24 | 63.29 |
|   vegetation  | 89.72 |  96.3 |
|    terrain    | 51.69 | 59.44 |
|      sky      | 91.55 | 99.16 |
|     person    | 70.62 | 84.94 |
|     rider     | 46.26 |  70.1 |
|      car      | 92.35 | 96.82 |
|     truck     | 79.85 | 88.72 |
|      bus      | 75.22 | 79.91 |
|     train     |  70.1 |  75.0 |
|   motorcycle  | 56.16 | 74.88 |
|    bicycle    | 62.72 | 76.25 |
+---------------+-------+-------+
2023-01-10 22:16:12,173 - mmseg - INFO - Summary:
2023-01-10 22:16:12,174 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 94.14 | 68.85 | 78.44 |
+-------+-------+-------+
2023-01-10 22:16:12,190 - mmseg - INFO - Exp name: 230110_1355_230110_1343_gta2cs_dacs_a999_fdthings_rcs001_cpl_m32-07-spta_daformer_sepaspp_mitb5_poly10warm_s0_2feea_f2bea
2023-01-10 22:16:12,190 - mmseg - INFO - Iter [500/40000]	lr: 2.400e-05, eta: 5:33:02, time: 1.226, data_time: 0.011, memory: 9807, aAcc: 0.9414, mIoU: 0.6885, mAcc: 0.7844, IoU.road: 0.9690, IoU.sidewalk: 0.7632, IoU.building: 0.8928, IoU.wall: 0.5256, IoU.fence: 0.4325, IoU.pole: 0.4967, IoU.traffic light: 0.5471, IoU.traffic sign: 0.5924, IoU.vegetation: 0.8972, IoU.terrain: 0.5169, IoU.sky: 0.9155, IoU.person: 0.7062, IoU.rider: 0.4626, IoU.car: 0.9235, IoU.truck: 0.7985, IoU.bus: 0.7522, IoU.train: 0.7010, IoU.motorcycle: 0.5616, IoU.bicycle: 0.6272, Acc.road: 0.9922, Acc.sidewalk: 0.8276, Acc.building: 0.9421, Acc.wall: 0.7160, Acc.fence: 0.4641, Acc.pole: 0.5806, Acc.traffic light: 0.7325, Acc.traffic sign: 0.6329, Acc.vegetation: 0.9630, Acc.terrain: 0.5944, Acc.sky: 0.9916, Acc.person: 0.8494, Acc.rider: 0.7010, Acc.car: 0.9682, Acc.truck: 0.8872, Acc.bus: 0.7991, Acc.train: 0.7500, Acc.motorcycle: 0.7488, Acc.bicycle: 0.7625, decode.loss_seg: 0.1245, decode.acc_seg: 88.0835, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1237, mix.decode.acc_seg: 89.9288, masked.decode.loss_seg: 0.1583, masked.decode.acc_seg: 90.4598
2023-01-10 22:17:18,727 - mmseg - INFO - Iter [24050/40000]	lr: 2.393e-05, eta: 5:32:53, time: 2.852, data_time: 1.533, memory: 9807, decode.loss_seg: 0.1035, decode.acc_seg: 86.4384, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1207, mix.decode.acc_seg: 89.8619, masked.decode.loss_seg: 0.1706, masked.decode.acc_seg: 89.8947
2023-01-10 22:18:20,021 - mmseg - INFO - Iter [24100/40000]	lr: 2.385e-05, eta: 5:31:49, time: 1.226, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1273, decode.acc_seg: 87.8764, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1275, mix.decode.acc_seg: 90.9449, masked.decode.loss_seg: 0.1617, masked.decode.acc_seg: 90.8158
2023-01-10 22:19:21,166 - mmseg - INFO - Iter [24150/40000]	lr: 2.378e-05, eta: 5:30:45, time: 1.223, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1309, decode.acc_seg: 88.4984, src.loss_imnet_feat_dist: 0.0990, mix.decode.loss_seg: 0.1314, mix.decode.acc_seg: 90.7699, masked.decode.loss_seg: 0.1527, masked.decode.acc_seg: 90.9681
2023-01-10 22:20:22,234 - mmseg - INFO - Iter [24200/40000]	lr: 2.370e-05, eta: 5:29:42, time: 1.221, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1385, decode.acc_seg: 86.8653, src.loss_imnet_feat_dist: 0.1032, mix.decode.loss_seg: 0.1179, mix.decode.acc_seg: 90.8265, masked.decode.loss_seg: 0.1554, masked.decode.acc_seg: 90.7912
2023-01-10 22:21:23,131 - mmseg - INFO - Iter [24250/40000]	lr: 2.363e-05, eta: 5:28:38, time: 1.218, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1346, decode.acc_seg: 86.5004, src.loss_imnet_feat_dist: 0.1111, mix.decode.loss_seg: 0.1419, mix.decode.acc_seg: 88.8835, masked.decode.loss_seg: 0.1656, masked.decode.acc_seg: 90.0959
2023-01-10 22:22:24,404 - mmseg - INFO - Iter [24300/40000]	lr: 2.355e-05, eta: 5:27:35, time: 1.225, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1226, decode.acc_seg: 88.3980, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1377, mix.decode.acc_seg: 90.8915, masked.decode.loss_seg: 0.1728, masked.decode.acc_seg: 89.7206
2023-01-10 22:23:25,415 - mmseg - INFO - Iter [24350/40000]	lr: 2.348e-05, eta: 5:26:31, time: 1.220, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1115, decode.acc_seg: 86.4942, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1378, mix.decode.acc_seg: 88.8591, masked.decode.loss_seg: 0.1760, masked.decode.acc_seg: 89.6727
2023-01-10 22:24:26,714 - mmseg - INFO - Iter [24400/40000]	lr: 2.340e-05, eta: 5:25:28, time: 1.226, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1268, decode.acc_seg: 88.3691, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1256, mix.decode.acc_seg: 90.0080, masked.decode.loss_seg: 0.1636, masked.decode.acc_seg: 90.6564
2023-01-10 22:25:27,870 - mmseg - INFO - Iter [24450/40000]	lr: 2.333e-05, eta: 5:24:24, time: 1.223, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1292, decode.acc_seg: 86.4111, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1269, mix.decode.acc_seg: 88.7732, masked.decode.loss_seg: 0.1598, masked.decode.acc_seg: 90.4623
2023-01-10 22:26:29,474 - mmseg - INFO - Iter [24500/40000]	lr: 2.325e-05, eta: 5:23:21, time: 1.232, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1096, decode.acc_seg: 88.3608, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1362, mix.decode.acc_seg: 89.8876, masked.decode.loss_seg: 0.1698, masked.decode.acc_seg: 90.5013
2023-01-10 22:27:30,896 - mmseg - INFO - Iter [24550/40000]	lr: 2.318e-05, eta: 5:22:18, time: 1.228, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1188, decode.acc_seg: 87.2562, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1403, mix.decode.acc_seg: 88.9841, masked.decode.loss_seg: 0.1762, masked.decode.acc_seg: 89.8600
2023-01-10 22:28:32,109 - mmseg - INFO - Iter [24600/40000]	lr: 2.310e-05, eta: 5:21:14, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1247, decode.acc_seg: 88.5188, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1282, mix.decode.acc_seg: 89.4615, masked.decode.loss_seg: 0.1656, masked.decode.acc_seg: 90.6757
2023-01-10 22:29:33,214 - mmseg - INFO - Iter [24650/40000]	lr: 2.303e-05, eta: 5:20:11, time: 1.222, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1228, decode.acc_seg: 87.6697, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1237, mix.decode.acc_seg: 90.4094, masked.decode.loss_seg: 0.1641, masked.decode.acc_seg: 90.7592
2023-01-10 22:30:34,416 - mmseg - INFO - Iter [24700/40000]	lr: 2.295e-05, eta: 5:19:07, time: 1.224, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1279, decode.acc_seg: 87.1705, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1389, mix.decode.acc_seg: 89.5306, masked.decode.loss_seg: 0.1634, masked.decode.acc_seg: 90.1648
2023-01-10 22:31:35,332 - mmseg - INFO - Iter [24750/40000]	lr: 2.288e-05, eta: 5:18:04, time: 1.218, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1190, decode.acc_seg: 88.7796, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1274, mix.decode.acc_seg: 89.8250, masked.decode.loss_seg: 0.1579, masked.decode.acc_seg: 90.8775
2023-01-10 22:32:36,342 - mmseg - INFO - Iter [24800/40000]	lr: 2.280e-05, eta: 5:17:00, time: 1.220, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1017, decode.acc_seg: 88.4539, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1105, mix.decode.acc_seg: 90.8260, masked.decode.loss_seg: 0.1627, masked.decode.acc_seg: 90.4668
2023-01-10 22:33:37,526 - mmseg - INFO - Iter [24850/40000]	lr: 2.273e-05, eta: 5:15:57, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1187, decode.acc_seg: 88.8425, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1447, mix.decode.acc_seg: 89.7521, masked.decode.loss_seg: 0.1643, masked.decode.acc_seg: 90.3662
2023-01-10 22:34:39,006 - mmseg - INFO - Iter [24900/40000]	lr: 2.265e-05, eta: 5:14:54, time: 1.230, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1142, decode.acc_seg: 88.3905, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1197, mix.decode.acc_seg: 91.1521, masked.decode.loss_seg: 0.1621, masked.decode.acc_seg: 90.2945
2023-01-10 22:35:40,582 - mmseg - INFO - Iter [24950/40000]	lr: 2.258e-05, eta: 5:13:50, time: 1.232, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1243, decode.acc_seg: 86.2908, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1435, mix.decode.acc_seg: 88.7074, masked.decode.loss_seg: 0.1683, masked.decode.acc_seg: 90.8188
2023-01-10 22:36:41,793 - mmseg - INFO - Exp name: 230110_1355_230110_1343_gta2cs_dacs_a999_fdthings_rcs001_cpl_m32-07-spta_daformer_sepaspp_mitb5_poly10warm_s0_2feea_f2bea
2023-01-10 22:36:41,794 - mmseg - INFO - Iter [25000/40000]	lr: 2.250e-05, eta: 5:12:47, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1320, decode.acc_seg: 87.8002, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1238, mix.decode.acc_seg: 89.1033, masked.decode.loss_seg: 0.1667, masked.decode.acc_seg: 90.8039
2023-01-10 22:37:48,489 - mmseg - INFO - Iter [25050/40000]	lr: 2.243e-05, eta: 5:11:47, time: 1.334, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0999, decode.acc_seg: 87.4212, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1203, mix.decode.acc_seg: 89.2631, masked.decode.loss_seg: 0.1571, masked.decode.acc_seg: 90.5776
2023-01-10 22:38:50,004 - mmseg - INFO - Iter [25100/40000]	lr: 2.235e-05, eta: 5:10:44, time: 1.230, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1043, decode.acc_seg: 90.6547, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1184, mix.decode.acc_seg: 91.8718, masked.decode.loss_seg: 0.1655, masked.decode.acc_seg: 90.2083
2023-01-10 22:39:50,894 - mmseg - INFO - Iter [25150/40000]	lr: 2.228e-05, eta: 5:09:40, time: 1.218, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1209, decode.acc_seg: 88.6921, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1281, mix.decode.acc_seg: 90.1986, masked.decode.loss_seg: 0.1694, masked.decode.acc_seg: 90.0320
2023-01-10 22:40:52,065 - mmseg - INFO - Iter [25200/40000]	lr: 2.220e-05, eta: 5:08:37, time: 1.223, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1228, decode.acc_seg: 86.4726, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1348, mix.decode.acc_seg: 88.9897, masked.decode.loss_seg: 0.1675, masked.decode.acc_seg: 90.5860
2023-01-10 22:41:53,393 - mmseg - INFO - Iter [25250/40000]	lr: 2.213e-05, eta: 5:07:33, time: 1.227, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1068, decode.acc_seg: 87.6603, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1204, mix.decode.acc_seg: 89.8878, masked.decode.loss_seg: 0.1652, masked.decode.acc_seg: 90.2673
2023-01-10 22:42:54,530 - mmseg - INFO - Iter [25300/40000]	lr: 2.205e-05, eta: 5:06:30, time: 1.223, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1103, decode.acc_seg: 88.9160, src.loss_imnet_feat_dist: 0.0985, mix.decode.loss_seg: 0.1216, mix.decode.acc_seg: 91.1873, masked.decode.loss_seg: 0.1561, masked.decode.acc_seg: 90.7144
2023-01-10 22:43:55,903 - mmseg - INFO - Iter [25350/40000]	lr: 2.198e-05, eta: 5:05:27, time: 1.227, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1182, decode.acc_seg: 88.0314, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1258, mix.decode.acc_seg: 90.0407, masked.decode.loss_seg: 0.1724, masked.decode.acc_seg: 90.3690
2023-01-10 22:44:57,144 - mmseg - INFO - Iter [25400/40000]	lr: 2.190e-05, eta: 5:04:24, time: 1.225, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1171, decode.acc_seg: 88.7453, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1270, mix.decode.acc_seg: 90.2222, masked.decode.loss_seg: 0.1702, masked.decode.acc_seg: 90.0948
2023-01-10 22:45:58,225 - mmseg - INFO - Iter [25450/40000]	lr: 2.183e-05, eta: 5:03:20, time: 1.222, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1407, decode.acc_seg: 87.3947, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1439, mix.decode.acc_seg: 88.3963, masked.decode.loss_seg: 0.1753, masked.decode.acc_seg: 89.2232
2023-01-10 22:46:59,524 - mmseg - INFO - Iter [25500/40000]	lr: 2.175e-05, eta: 5:02:17, time: 1.226, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1048, decode.acc_seg: 88.7822, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1243, mix.decode.acc_seg: 90.3444, masked.decode.loss_seg: 0.1620, masked.decode.acc_seg: 90.3610
2023-01-10 22:48:00,846 - mmseg - INFO - Iter [25550/40000]	lr: 2.168e-05, eta: 5:01:14, time: 1.226, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1141, decode.acc_seg: 89.1263, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1346, mix.decode.acc_seg: 89.6767, masked.decode.loss_seg: 0.1681, masked.decode.acc_seg: 90.2258
2023-01-10 22:49:01,888 - mmseg - INFO - Iter [25600/40000]	lr: 2.160e-05, eta: 5:00:10, time: 1.221, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1110, decode.acc_seg: 90.0259, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1236, mix.decode.acc_seg: 91.1743, masked.decode.loss_seg: 0.1629, masked.decode.acc_seg: 90.4319
2023-01-10 22:50:02,857 - mmseg - INFO - Iter [25650/40000]	lr: 2.153e-05, eta: 4:59:07, time: 1.219, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1068, decode.acc_seg: 88.1201, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1201, mix.decode.acc_seg: 90.2844, masked.decode.loss_seg: 0.1595, masked.decode.acc_seg: 91.1738
2023-01-10 22:51:03,843 - mmseg - INFO - Iter [25700/40000]	lr: 2.145e-05, eta: 4:58:04, time: 1.220, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1121, decode.acc_seg: 88.4577, src.loss_imnet_feat_dist: 0.1069, mix.decode.loss_seg: 0.1310, mix.decode.acc_seg: 90.4369, masked.decode.loss_seg: 0.1588, masked.decode.acc_seg: 90.3277
2023-01-10 22:52:05,139 - mmseg - INFO - Iter [25750/40000]	lr: 2.138e-05, eta: 4:57:00, time: 1.226, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1193, decode.acc_seg: 88.5577, src.loss_imnet_feat_dist: 0.1057, mix.decode.loss_seg: 0.1264, mix.decode.acc_seg: 90.3480, masked.decode.loss_seg: 0.1595, masked.decode.acc_seg: 90.2045
2023-01-10 22:53:06,786 - mmseg - INFO - Iter [25800/40000]	lr: 2.130e-05, eta: 4:55:57, time: 1.233, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1229, decode.acc_seg: 86.5971, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1467, mix.decode.acc_seg: 88.2497, masked.decode.loss_seg: 0.1735, masked.decode.acc_seg: 90.5287
2023-01-10 22:54:08,518 - mmseg - INFO - Iter [25850/40000]	lr: 2.123e-05, eta: 4:54:54, time: 1.235, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1128, decode.acc_seg: 90.4271, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1197, mix.decode.acc_seg: 91.4857, masked.decode.loss_seg: 0.1719, masked.decode.acc_seg: 89.9555
2023-01-10 22:55:09,603 - mmseg - INFO - Iter [25900/40000]	lr: 2.115e-05, eta: 4:53:51, time: 1.222, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1226, decode.acc_seg: 88.0870, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1481, mix.decode.acc_seg: 89.6618, masked.decode.loss_seg: 0.1671, masked.decode.acc_seg: 89.8401
2023-01-10 22:56:10,780 - mmseg - INFO - Iter [25950/40000]	lr: 2.108e-05, eta: 4:52:48, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1156, decode.acc_seg: 88.9321, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1330, mix.decode.acc_seg: 89.7395, masked.decode.loss_seg: 0.1626, masked.decode.acc_seg: 90.4731
2023-01-10 22:57:12,125 - mmseg - INFO - Exp name: 230110_1355_230110_1343_gta2cs_dacs_a999_fdthings_rcs001_cpl_m32-07-spta_daformer_sepaspp_mitb5_poly10warm_s0_2feea_f2bea
2023-01-10 22:57:12,125 - mmseg - INFO - Iter [26000/40000]	lr: 2.100e-05, eta: 4:51:45, time: 1.227, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1243, decode.acc_seg: 88.3771, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1273, mix.decode.acc_seg: 89.6909, masked.decode.loss_seg: 0.1620, masked.decode.acc_seg: 90.3590
2023-01-10 22:58:17,175 - mmseg - INFO - Iter [26050/40000]	lr: 2.093e-05, eta: 4:50:43, time: 1.301, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1076, decode.acc_seg: 88.3917, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1260, mix.decode.acc_seg: 90.7780, masked.decode.loss_seg: 0.1710, masked.decode.acc_seg: 89.9231
2023-01-10 22:59:18,533 - mmseg - INFO - Iter [26100/40000]	lr: 2.085e-05, eta: 4:49:40, time: 1.227, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1102, decode.acc_seg: 88.6761, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1161, mix.decode.acc_seg: 90.6787, masked.decode.loss_seg: 0.1617, masked.decode.acc_seg: 90.7754
2023-01-10 23:00:19,701 - mmseg - INFO - Iter [26150/40000]	lr: 2.078e-05, eta: 4:48:37, time: 1.223, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1178, decode.acc_seg: 88.6666, src.loss_imnet_feat_dist: 0.0970, mix.decode.loss_seg: 0.1184, mix.decode.acc_seg: 90.6168, masked.decode.loss_seg: 0.1632, masked.decode.acc_seg: 90.9012
2023-01-10 23:01:20,960 - mmseg - INFO - Iter [26200/40000]	lr: 2.070e-05, eta: 4:47:34, time: 1.225, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1098, decode.acc_seg: 89.9921, src.loss_imnet_feat_dist: 0.1036, mix.decode.loss_seg: 0.1313, mix.decode.acc_seg: 90.8835, masked.decode.loss_seg: 0.1692, masked.decode.acc_seg: 89.6548
2023-01-10 23:02:22,089 - mmseg - INFO - Iter [26250/40000]	lr: 2.063e-05, eta: 4:46:31, time: 1.223, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1115, decode.acc_seg: 88.8414, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1247, mix.decode.acc_seg: 90.3727, masked.decode.loss_seg: 0.1673, masked.decode.acc_seg: 90.5599
2023-01-10 23:03:23,539 - mmseg - INFO - Iter [26300/40000]	lr: 2.055e-05, eta: 4:45:28, time: 1.229, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1069, decode.acc_seg: 89.8770, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1280, mix.decode.acc_seg: 90.6170, masked.decode.loss_seg: 0.1651, masked.decode.acc_seg: 90.9026
2023-01-10 23:04:24,750 - mmseg - INFO - Iter [26350/40000]	lr: 2.048e-05, eta: 4:44:24, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1066, decode.acc_seg: 87.7079, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1298, mix.decode.acc_seg: 90.2069, masked.decode.loss_seg: 0.1751, masked.decode.acc_seg: 90.5574
2023-01-10 23:05:25,942 - mmseg - INFO - Iter [26400/40000]	lr: 2.040e-05, eta: 4:43:21, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1074, decode.acc_seg: 88.7800, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1149, mix.decode.acc_seg: 90.3208, masked.decode.loss_seg: 0.1586, masked.decode.acc_seg: 91.0113
2023-01-10 23:06:26,891 - mmseg - INFO - Iter [26450/40000]	lr: 2.033e-05, eta: 4:42:18, time: 1.219, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1013, decode.acc_seg: 88.0476, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1184, mix.decode.acc_seg: 89.7127, masked.decode.loss_seg: 0.1473, masked.decode.acc_seg: 91.0420
2023-01-10 23:07:28,257 - mmseg - INFO - Iter [26500/40000]	lr: 2.025e-05, eta: 4:41:15, time: 1.227, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1103, decode.acc_seg: 89.0144, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1209, mix.decode.acc_seg: 91.0101, masked.decode.loss_seg: 0.1680, masked.decode.acc_seg: 90.6650
2023-01-10 23:08:29,801 - mmseg - INFO - Iter [26550/40000]	lr: 2.018e-05, eta: 4:40:12, time: 1.231, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0966, decode.acc_seg: 88.3137, src.loss_imnet_feat_dist: 0.1008, mix.decode.loss_seg: 0.1102, mix.decode.acc_seg: 89.7683, masked.decode.loss_seg: 0.1586, masked.decode.acc_seg: 91.1712
2023-01-10 23:09:31,154 - mmseg - INFO - Iter [26600/40000]	lr: 2.010e-05, eta: 4:39:09, time: 1.227, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1378, decode.acc_seg: 88.5709, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1306, mix.decode.acc_seg: 90.2260, masked.decode.loss_seg: 0.1589, masked.decode.acc_seg: 91.0810
2023-01-10 23:10:32,319 - mmseg - INFO - Iter [26650/40000]	lr: 2.003e-05, eta: 4:38:06, time: 1.223, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1133, decode.acc_seg: 89.8250, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1245, mix.decode.acc_seg: 91.2921, masked.decode.loss_seg: 0.1564, masked.decode.acc_seg: 91.2864
2023-01-10 23:11:34,029 - mmseg - INFO - Iter [26700/40000]	lr: 1.995e-05, eta: 4:37:03, time: 1.234, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1255, decode.acc_seg: 88.8107, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1355, mix.decode.acc_seg: 91.7480, masked.decode.loss_seg: 0.1648, masked.decode.acc_seg: 90.4484
2023-01-10 23:12:35,302 - mmseg - INFO - Iter [26750/40000]	lr: 1.988e-05, eta: 4:36:00, time: 1.225, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1072, decode.acc_seg: 90.1518, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1230, mix.decode.acc_seg: 90.3825, masked.decode.loss_seg: 0.1722, masked.decode.acc_seg: 90.2494
2023-01-10 23:13:36,689 - mmseg - INFO - Iter [26800/40000]	lr: 1.980e-05, eta: 4:34:57, time: 1.228, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1001, decode.acc_seg: 88.1459, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1174, mix.decode.acc_seg: 90.8900, masked.decode.loss_seg: 0.1735, masked.decode.acc_seg: 90.5047
2023-01-10 23:14:37,692 - mmseg - INFO - Iter [26850/40000]	lr: 1.973e-05, eta: 4:33:53, time: 1.220, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1283, decode.acc_seg: 86.9583, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1290, mix.decode.acc_seg: 88.4235, masked.decode.loss_seg: 0.1654, masked.decode.acc_seg: 90.2193
2023-01-10 23:15:38,982 - mmseg - INFO - Iter [26900/40000]	lr: 1.965e-05, eta: 4:32:50, time: 1.226, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1428, decode.acc_seg: 88.3848, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1386, mix.decode.acc_seg: 90.4425, masked.decode.loss_seg: 0.1727, masked.decode.acc_seg: 90.0769
2023-01-10 23:16:40,293 - mmseg - INFO - Iter [26950/40000]	lr: 1.958e-05, eta: 4:31:47, time: 1.226, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1021, decode.acc_seg: 88.4776, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1154, mix.decode.acc_seg: 90.9584, masked.decode.loss_seg: 0.1571, masked.decode.acc_seg: 91.6030
2023-01-10 23:17:41,397 - mmseg - INFO - Exp name: 230110_1355_230110_1343_gta2cs_dacs_a999_fdthings_rcs001_cpl_m32-07-spta_daformer_sepaspp_mitb5_poly10warm_s0_2feea_f2bea
2023-01-10 23:17:41,397 - mmseg - INFO - Iter [27000/40000]	lr: 1.950e-05, eta: 4:30:44, time: 1.222, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0958, decode.acc_seg: 89.0644, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1150, mix.decode.acc_seg: 91.0051, masked.decode.loss_seg: 0.1606, masked.decode.acc_seg: 91.5389
2023-01-10 23:18:46,482 - mmseg - INFO - Iter [27050/40000]	lr: 1.943e-05, eta: 4:29:43, time: 1.302, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1032, decode.acc_seg: 87.6266, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1307, mix.decode.acc_seg: 90.3446, masked.decode.loss_seg: 0.1681, masked.decode.acc_seg: 90.9271
2023-01-10 23:19:47,589 - mmseg - INFO - Iter [27100/40000]	lr: 1.935e-05, eta: 4:28:40, time: 1.222, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1118, decode.acc_seg: 88.0942, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1278, mix.decode.acc_seg: 90.3939, masked.decode.loss_seg: 0.1720, masked.decode.acc_seg: 90.7243
2023-01-10 23:20:48,753 - mmseg - INFO - Iter [27150/40000]	lr: 1.928e-05, eta: 4:27:37, time: 1.223, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1123, decode.acc_seg: 88.7498, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1192, mix.decode.acc_seg: 91.7483, masked.decode.loss_seg: 0.1581, masked.decode.acc_seg: 91.5543
2023-01-10 23:21:50,138 - mmseg - INFO - Iter [27200/40000]	lr: 1.920e-05, eta: 4:26:34, time: 1.228, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1082, decode.acc_seg: 88.3773, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1137, mix.decode.acc_seg: 89.9109, masked.decode.loss_seg: 0.1589, masked.decode.acc_seg: 91.5032
2023-01-10 23:22:51,897 - mmseg - INFO - Iter [27250/40000]	lr: 1.913e-05, eta: 4:25:31, time: 1.235, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1058, decode.acc_seg: 88.9143, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1178, mix.decode.acc_seg: 90.8186, masked.decode.loss_seg: 0.1542, masked.decode.acc_seg: 91.2036
2023-01-10 23:23:53,126 - mmseg - INFO - Iter [27300/40000]	lr: 1.905e-05, eta: 4:24:28, time: 1.225, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1350, decode.acc_seg: 89.0187, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1152, mix.decode.acc_seg: 90.1295, masked.decode.loss_seg: 0.1553, masked.decode.acc_seg: 91.3530
2023-01-10 23:24:54,628 - mmseg - INFO - Iter [27350/40000]	lr: 1.898e-05, eta: 4:23:25, time: 1.230, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1025, decode.acc_seg: 89.2107, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1200, mix.decode.acc_seg: 91.4851, masked.decode.loss_seg: 0.1661, masked.decode.acc_seg: 90.8463
2023-01-10 23:25:55,682 - mmseg - INFO - Iter [27400/40000]	lr: 1.890e-05, eta: 4:22:22, time: 1.221, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1379, decode.acc_seg: 89.9872, src.loss_imnet_feat_dist: 0.1084, mix.decode.loss_seg: 0.1255, mix.decode.acc_seg: 91.4115, masked.decode.loss_seg: 0.1604, masked.decode.acc_seg: 91.3873
2023-01-10 23:26:56,989 - mmseg - INFO - Iter [27450/40000]	lr: 1.883e-05, eta: 4:21:19, time: 1.226, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1176, decode.acc_seg: 86.8724, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1228, mix.decode.acc_seg: 90.2914, masked.decode.loss_seg: 0.1661, masked.decode.acc_seg: 90.5958
2023-01-10 23:27:58,054 - mmseg - INFO - Iter [27500/40000]	lr: 1.875e-05, eta: 4:20:16, time: 1.221, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0993, decode.acc_seg: 87.0572, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1179, mix.decode.acc_seg: 88.9523, masked.decode.loss_seg: 0.1775, masked.decode.acc_seg: 90.8481
2023-01-10 23:28:59,282 - mmseg - INFO - Iter [27550/40000]	lr: 1.868e-05, eta: 4:19:13, time: 1.225, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1094, decode.acc_seg: 89.2356, src.loss_imnet_feat_dist: 0.0998, mix.decode.loss_seg: 0.1237, mix.decode.acc_seg: 90.6187, masked.decode.loss_seg: 0.1747, masked.decode.acc_seg: 90.7323
2023-01-10 23:30:00,663 - mmseg - INFO - Iter [27600/40000]	lr: 1.860e-05, eta: 4:18:10, time: 1.228, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1007, decode.acc_seg: 88.0206, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1221, mix.decode.acc_seg: 89.6937, masked.decode.loss_seg: 0.1708, masked.decode.acc_seg: 90.3064
2023-01-10 23:31:02,004 - mmseg - INFO - Iter [27650/40000]	lr: 1.853e-05, eta: 4:17:07, time: 1.227, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1204, decode.acc_seg: 88.6504, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1274, mix.decode.acc_seg: 91.1400, masked.decode.loss_seg: 0.1763, masked.decode.acc_seg: 90.7842
2023-01-10 23:32:03,301 - mmseg - INFO - Iter [27700/40000]	lr: 1.845e-05, eta: 4:16:04, time: 1.226, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1129, decode.acc_seg: 89.0141, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1219, mix.decode.acc_seg: 90.2012, masked.decode.loss_seg: 0.1654, masked.decode.acc_seg: 90.7564
2023-01-10 23:33:04,479 - mmseg - INFO - Iter [27750/40000]	lr: 1.838e-05, eta: 4:15:01, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1189, decode.acc_seg: 87.7027, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1302, mix.decode.acc_seg: 88.8985, masked.decode.loss_seg: 0.1639, masked.decode.acc_seg: 90.6545
2023-01-10 23:34:05,960 - mmseg - INFO - Iter [27800/40000]	lr: 1.830e-05, eta: 4:13:58, time: 1.230, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1041, decode.acc_seg: 88.1327, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1171, mix.decode.acc_seg: 90.7109, masked.decode.loss_seg: 0.1575, masked.decode.acc_seg: 91.4281
2023-01-10 23:35:07,516 - mmseg - INFO - Iter [27850/40000]	lr: 1.823e-05, eta: 4:12:55, time: 1.231, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1105, decode.acc_seg: 89.3678, src.loss_imnet_feat_dist: 0.1016, mix.decode.loss_seg: 0.1214, mix.decode.acc_seg: 91.4502, masked.decode.loss_seg: 0.1576, masked.decode.acc_seg: 91.3398
2023-01-10 23:36:08,870 - mmseg - INFO - Iter [27900/40000]	lr: 1.815e-05, eta: 4:11:52, time: 1.227, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1020, decode.acc_seg: 87.7186, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1183, mix.decode.acc_seg: 91.0116, masked.decode.loss_seg: 0.1720, masked.decode.acc_seg: 91.0104
2023-01-10 23:37:10,620 - mmseg - INFO - Iter [27950/40000]	lr: 1.808e-05, eta: 4:10:49, time: 1.235, data_time: 0.018, memory: 9807, decode.loss_seg: 0.1197, decode.acc_seg: 88.1401, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1270, mix.decode.acc_seg: 89.5890, masked.decode.loss_seg: 0.1734, masked.decode.acc_seg: 90.5865
2023-01-10 23:39:25,048 - mmseg - INFO - per class results:
2023-01-10 23:39:25,091 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      road     | 96.69 | 99.22 |
|    sidewalk   |  75.3 | 82.16 |
|    building   | 89.54 | 95.23 |
|      wall     | 54.23 | 69.99 |
|     fence     | 39.55 | 41.81 |
|      pole     | 50.12 |  58.2 |
| traffic light | 56.02 | 71.51 |
|  traffic sign | 62.23 | 66.95 |
|   vegetation  | 90.21 | 95.95 |
|    terrain    | 50.83 | 59.98 |
|      sky      | 92.31 | 98.93 |
|     person    | 71.94 | 83.89 |
|     rider     | 47.03 | 67.27 |
|      car      | 92.04 | 96.23 |
|     truck     | 78.13 | 88.96 |
|      bus      | 80.77 |  84.4 |
|     train     | 73.77 | 81.37 |
|   motorcycle  | 57.35 | 72.01 |
|    bicycle    | 62.47 | 75.17 |
+---------------+-------+-------+
2023-01-10 23:39:25,091 - mmseg - INFO - Summary:
2023-01-10 23:39:25,091 - mmseg - INFO - 
+-------+------+-------+
|  aAcc | mIoU |  mAcc |
+-------+------+-------+
| 94.19 | 69.5 | 78.38 |
+-------+------+-------+
2023-01-10 23:39:25,099 - mmseg - INFO - Exp name: 230110_1355_230110_1343_gta2cs_dacs_a999_fdthings_rcs001_cpl_m32-07-spta_daformer_sepaspp_mitb5_poly10warm_s0_2feea_f2bea
2023-01-10 23:39:25,100 - mmseg - INFO - Iter [500/40000]	lr: 1.800e-05, eta: 4:09:46, time: 1.226, data_time: 0.011, memory: 9807, aAcc: 0.9419, mIoU: 0.6950, mAcc: 0.7838, IoU.road: 0.9669, IoU.sidewalk: 0.7530, IoU.building: 0.8954, IoU.wall: 0.5423, IoU.fence: 0.3955, IoU.pole: 0.5012, IoU.traffic light: 0.5602, IoU.traffic sign: 0.6223, IoU.vegetation: 0.9021, IoU.terrain: 0.5083, IoU.sky: 0.9231, IoU.person: 0.7194, IoU.rider: 0.4703, IoU.car: 0.9204, IoU.truck: 0.7813, IoU.bus: 0.8077, IoU.train: 0.7377, IoU.motorcycle: 0.5735, IoU.bicycle: 0.6247, Acc.road: 0.9922, Acc.sidewalk: 0.8216, Acc.building: 0.9523, Acc.wall: 0.6999, Acc.fence: 0.4181, Acc.pole: 0.5820, Acc.traffic light: 0.7151, Acc.traffic sign: 0.6695, Acc.vegetation: 0.9595, Acc.terrain: 0.5998, Acc.sky: 0.9893, Acc.person: 0.8389, Acc.rider: 0.6727, Acc.car: 0.9623, Acc.truck: 0.8896, Acc.bus: 0.8440, Acc.train: 0.8137, Acc.motorcycle: 0.7201, Acc.bicycle: 0.7517, decode.loss_seg: 0.1093, decode.acc_seg: 90.2867, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1298, mix.decode.acc_seg: 91.0207, masked.decode.loss_seg: 0.1651, masked.decode.acc_seg: 90.3080
2023-01-10 23:40:33,151 - mmseg - INFO - Iter [28050/40000]	lr: 1.793e-05, eta: 4:09:17, time: 2.824, data_time: 1.475, memory: 9807, decode.loss_seg: 0.1081, decode.acc_seg: 87.5977, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1318, mix.decode.acc_seg: 89.0015, masked.decode.loss_seg: 0.1572, masked.decode.acc_seg: 90.9277
2023-01-10 23:41:34,238 - mmseg - INFO - Iter [28100/40000]	lr: 1.785e-05, eta: 4:08:14, time: 1.222, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1006, decode.acc_seg: 89.7500, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1207, mix.decode.acc_seg: 91.5511, masked.decode.loss_seg: 0.1705, masked.decode.acc_seg: 90.6035
2023-01-10 23:42:35,518 - mmseg - INFO - Iter [28150/40000]	lr: 1.778e-05, eta: 4:07:11, time: 1.226, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1014, decode.acc_seg: 89.1482, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1210, mix.decode.acc_seg: 90.4377, masked.decode.loss_seg: 0.1621, masked.decode.acc_seg: 90.6030
2023-01-10 23:43:36,462 - mmseg - INFO - Iter [28200/40000]	lr: 1.770e-05, eta: 4:06:08, time: 1.219, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1250, decode.acc_seg: 86.3577, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1227, mix.decode.acc_seg: 89.3595, masked.decode.loss_seg: 0.1621, masked.decode.acc_seg: 90.7980
2023-01-10 23:44:37,479 - mmseg - INFO - Iter [28250/40000]	lr: 1.763e-05, eta: 4:05:05, time: 1.220, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1134, decode.acc_seg: 89.0164, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1237, mix.decode.acc_seg: 90.0181, masked.decode.loss_seg: 0.1607, masked.decode.acc_seg: 90.5309
2023-01-10 23:45:38,608 - mmseg - INFO - Iter [28300/40000]	lr: 1.755e-05, eta: 4:04:01, time: 1.223, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1009, decode.acc_seg: 86.7754, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1108, mix.decode.acc_seg: 89.4037, masked.decode.loss_seg: 0.1511, masked.decode.acc_seg: 91.5534
2023-01-10 23:46:39,768 - mmseg - INFO - Iter [28350/40000]	lr: 1.748e-05, eta: 4:02:58, time: 1.223, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1085, decode.acc_seg: 85.0006, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1160, mix.decode.acc_seg: 88.8177, masked.decode.loss_seg: 0.1621, masked.decode.acc_seg: 91.1386
2023-01-10 23:47:40,852 - mmseg - INFO - Iter [28400/40000]	lr: 1.740e-05, eta: 4:01:55, time: 1.222, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1400, decode.acc_seg: 87.5803, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1395, mix.decode.acc_seg: 89.0421, masked.decode.loss_seg: 0.1562, masked.decode.acc_seg: 91.1661
2023-01-10 23:48:41,856 - mmseg - INFO - Iter [28450/40000]	lr: 1.733e-05, eta: 4:00:52, time: 1.220, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1111, decode.acc_seg: 88.8812, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1277, mix.decode.acc_seg: 90.0166, masked.decode.loss_seg: 0.1540, masked.decode.acc_seg: 91.1018
2023-01-10 23:49:42,963 - mmseg - INFO - Iter [28500/40000]	lr: 1.725e-05, eta: 3:59:49, time: 1.222, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1155, decode.acc_seg: 88.3129, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1135, mix.decode.acc_seg: 91.1485, masked.decode.loss_seg: 0.1484, masked.decode.acc_seg: 91.9809
2023-01-10 23:50:43,918 - mmseg - INFO - Iter [28550/40000]	lr: 1.718e-05, eta: 3:58:46, time: 1.219, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1009, decode.acc_seg: 89.9140, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1225, mix.decode.acc_seg: 91.6157, masked.decode.loss_seg: 0.1634, masked.decode.acc_seg: 91.0037
2023-01-10 23:51:45,112 - mmseg - INFO - Iter [28600/40000]	lr: 1.710e-05, eta: 3:57:42, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1052, decode.acc_seg: 87.5271, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1155, mix.decode.acc_seg: 89.9827, masked.decode.loss_seg: 0.1546, masked.decode.acc_seg: 91.4231
2023-01-10 23:52:46,653 - mmseg - INFO - Iter [28650/40000]	lr: 1.703e-05, eta: 3:56:39, time: 1.231, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1302, decode.acc_seg: 88.7565, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1304, mix.decode.acc_seg: 91.5317, masked.decode.loss_seg: 0.1497, masked.decode.acc_seg: 91.5979
2023-01-10 23:53:47,586 - mmseg - INFO - Iter [28700/40000]	lr: 1.695e-05, eta: 3:55:36, time: 1.219, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1104, decode.acc_seg: 89.3874, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1202, mix.decode.acc_seg: 91.3741, masked.decode.loss_seg: 0.1620, masked.decode.acc_seg: 90.7253
2023-01-10 23:54:48,879 - mmseg - INFO - Iter [28750/40000]	lr: 1.688e-05, eta: 3:54:33, time: 1.226, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1649, decode.acc_seg: 88.9195, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1782, mix.decode.acc_seg: 90.6999, masked.decode.loss_seg: 0.1643, masked.decode.acc_seg: 91.0332
2023-01-10 23:55:50,020 - mmseg - INFO - Iter [28800/40000]	lr: 1.680e-05, eta: 3:53:30, time: 1.223, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1087, decode.acc_seg: 88.2179, src.loss_imnet_feat_dist: 0.1019, mix.decode.loss_seg: 0.1225, mix.decode.acc_seg: 89.7594, masked.decode.loss_seg: 0.1615, masked.decode.acc_seg: 91.2085
2023-01-10 23:56:50,984 - mmseg - INFO - Iter [28850/40000]	lr: 1.673e-05, eta: 3:52:27, time: 1.219, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1090, decode.acc_seg: 88.6452, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1348, mix.decode.acc_seg: 90.9759, masked.decode.loss_seg: 0.1653, masked.decode.acc_seg: 90.7456
2023-01-10 23:57:52,277 - mmseg - INFO - Iter [28900/40000]	lr: 1.665e-05, eta: 3:51:24, time: 1.226, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1267, decode.acc_seg: 87.8081, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1309, mix.decode.acc_seg: 89.9580, masked.decode.loss_seg: 0.1618, masked.decode.acc_seg: 91.1097
2023-01-10 23:58:53,805 - mmseg - INFO - Iter [28950/40000]	lr: 1.658e-05, eta: 3:50:21, time: 1.231, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1006, decode.acc_seg: 89.2763, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1124, mix.decode.acc_seg: 90.7546, masked.decode.loss_seg: 0.1649, masked.decode.acc_seg: 90.7269
2023-01-10 23:59:55,262 - mmseg - INFO - Exp name: 230110_1355_230110_1343_gta2cs_dacs_a999_fdthings_rcs001_cpl_m32-07-spta_daformer_sepaspp_mitb5_poly10warm_s0_2feea_f2bea
2023-01-10 23:59:55,262 - mmseg - INFO - Iter [29000/40000]	lr: 1.650e-05, eta: 3:49:18, time: 1.229, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1170, decode.acc_seg: 88.4035, src.loss_imnet_feat_dist: 0.0988, mix.decode.loss_seg: 0.1317, mix.decode.acc_seg: 89.6500, masked.decode.loss_seg: 0.1595, masked.decode.acc_seg: 91.0274
2023-01-11 00:01:01,174 - mmseg - INFO - Iter [29050/40000]	lr: 1.643e-05, eta: 3:48:17, time: 1.318, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1038, decode.acc_seg: 88.7605, src.loss_imnet_feat_dist: 0.1010, mix.decode.loss_seg: 0.1155, mix.decode.acc_seg: 90.3214, masked.decode.loss_seg: 0.1656, masked.decode.acc_seg: 90.8662
2023-01-11 00:02:02,912 - mmseg - INFO - Iter [29100/40000]	lr: 1.635e-05, eta: 3:47:14, time: 1.235, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1017, decode.acc_seg: 88.8032, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1212, mix.decode.acc_seg: 91.6079, masked.decode.loss_seg: 0.1684, masked.decode.acc_seg: 90.7853
2023-01-11 00:03:04,644 - mmseg - INFO - Iter [29150/40000]	lr: 1.628e-05, eta: 3:46:11, time: 1.235, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0971, decode.acc_seg: 88.5873, src.loss_imnet_feat_dist: 0.1049, mix.decode.loss_seg: 0.1074, mix.decode.acc_seg: 91.7983, masked.decode.loss_seg: 0.1613, masked.decode.acc_seg: 91.2938
2023-01-11 00:04:06,194 - mmseg - INFO - Iter [29200/40000]	lr: 1.620e-05, eta: 3:45:08, time: 1.231, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1067, decode.acc_seg: 88.8020, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1256, mix.decode.acc_seg: 89.7542, masked.decode.loss_seg: 0.1667, masked.decode.acc_seg: 90.6712
2023-01-11 00:05:07,093 - mmseg - INFO - Iter [29250/40000]	lr: 1.613e-05, eta: 3:44:05, time: 1.218, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1085, decode.acc_seg: 87.5025, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1151, mix.decode.acc_seg: 89.7911, masked.decode.loss_seg: 0.1648, masked.decode.acc_seg: 90.9368
2023-01-11 00:06:08,038 - mmseg - INFO - Iter [29300/40000]	lr: 1.605e-05, eta: 3:43:02, time: 1.219, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1021, decode.acc_seg: 89.6443, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1208, mix.decode.acc_seg: 91.0453, masked.decode.loss_seg: 0.1729, masked.decode.acc_seg: 90.6413
2023-01-11 00:07:09,222 - mmseg - INFO - Iter [29350/40000]	lr: 1.598e-05, eta: 3:41:59, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1064, decode.acc_seg: 89.1090, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1187, mix.decode.acc_seg: 90.5499, masked.decode.loss_seg: 0.1554, masked.decode.acc_seg: 90.7540
2023-01-11 00:08:10,432 - mmseg - INFO - Iter [29400/40000]	lr: 1.590e-05, eta: 3:40:56, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1363, decode.acc_seg: 87.9115, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1737, mix.decode.acc_seg: 90.2323, masked.decode.loss_seg: 0.1617, masked.decode.acc_seg: 90.8130
2023-01-11 00:09:11,930 - mmseg - INFO - Iter [29450/40000]	lr: 1.583e-05, eta: 3:39:53, time: 1.230, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1058, decode.acc_seg: 88.2091, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1322, mix.decode.acc_seg: 90.4790, masked.decode.loss_seg: 0.1583, masked.decode.acc_seg: 91.1970
2023-01-11 00:10:13,680 - mmseg - INFO - Iter [29500/40000]	lr: 1.575e-05, eta: 3:38:50, time: 1.235, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0995, decode.acc_seg: 86.5906, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1213, mix.decode.acc_seg: 89.6630, masked.decode.loss_seg: 0.1635, masked.decode.acc_seg: 91.3839
2023-01-11 00:11:14,934 - mmseg - INFO - Iter [29550/40000]	lr: 1.568e-05, eta: 3:37:47, time: 1.225, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1062, decode.acc_seg: 89.0234, src.loss_imnet_feat_dist: 0.0973, mix.decode.loss_seg: 0.1139, mix.decode.acc_seg: 90.8780, masked.decode.loss_seg: 0.1727, masked.decode.acc_seg: 90.6039
2023-01-11 00:12:16,291 - mmseg - INFO - Iter [29600/40000]	lr: 1.560e-05, eta: 3:36:44, time: 1.227, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1199, decode.acc_seg: 87.5972, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1220, mix.decode.acc_seg: 91.3677, masked.decode.loss_seg: 0.1650, masked.decode.acc_seg: 91.6110
2023-01-11 00:13:17,513 - mmseg - INFO - Iter [29650/40000]	lr: 1.553e-05, eta: 3:35:41, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0984, decode.acc_seg: 89.9165, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1127, mix.decode.acc_seg: 91.3564, masked.decode.loss_seg: 0.1690, masked.decode.acc_seg: 91.2162
2023-01-11 00:14:18,676 - mmseg - INFO - Iter [29700/40000]	lr: 1.545e-05, eta: 3:34:38, time: 1.223, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1028, decode.acc_seg: 88.7167, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1159, mix.decode.acc_seg: 90.6286, masked.decode.loss_seg: 0.1579, masked.decode.acc_seg: 91.1238
2023-01-11 00:15:19,625 - mmseg - INFO - Iter [29750/40000]	lr: 1.538e-05, eta: 3:33:35, time: 1.219, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1393, decode.acc_seg: 88.5593, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1505, mix.decode.acc_seg: 91.4086, masked.decode.loss_seg: 0.1621, masked.decode.acc_seg: 91.1520
2023-01-11 00:16:21,046 - mmseg - INFO - Iter [29800/40000]	lr: 1.530e-05, eta: 3:32:32, time: 1.228, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1113, decode.acc_seg: 88.8222, src.loss_imnet_feat_dist: 0.0988, mix.decode.loss_seg: 0.1272, mix.decode.acc_seg: 90.6884, masked.decode.loss_seg: 0.1618, masked.decode.acc_seg: 91.6924
2023-01-11 00:17:22,090 - mmseg - INFO - Iter [29850/40000]	lr: 1.523e-05, eta: 3:31:29, time: 1.221, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1059, decode.acc_seg: 88.3033, src.loss_imnet_feat_dist: 0.0987, mix.decode.loss_seg: 0.1157, mix.decode.acc_seg: 91.8768, masked.decode.loss_seg: 0.1628, masked.decode.acc_seg: 91.3390
2023-01-11 00:18:23,280 - mmseg - INFO - Iter [29900/40000]	lr: 1.515e-05, eta: 3:30:26, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1042, decode.acc_seg: 87.0596, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1181, mix.decode.acc_seg: 89.4441, masked.decode.loss_seg: 0.1709, masked.decode.acc_seg: 90.7767
2023-01-11 00:19:24,430 - mmseg - INFO - Iter [29950/40000]	lr: 1.508e-05, eta: 3:29:23, time: 1.223, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0993, decode.acc_seg: 88.7146, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1175, mix.decode.acc_seg: 90.8861, masked.decode.loss_seg: 0.1615, masked.decode.acc_seg: 90.9076
2023-01-11 00:20:25,618 - mmseg - INFO - Exp name: 230110_1355_230110_1343_gta2cs_dacs_a999_fdthings_rcs001_cpl_m32-07-spta_daformer_sepaspp_mitb5_poly10warm_s0_2feea_f2bea
2023-01-11 00:20:25,618 - mmseg - INFO - Iter [30000/40000]	lr: 1.500e-05, eta: 3:28:20, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1147, decode.acc_seg: 88.7395, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1153, mix.decode.acc_seg: 91.5256, masked.decode.loss_seg: 0.1605, masked.decode.acc_seg: 91.3002
2023-01-11 00:21:31,009 - mmseg - INFO - Iter [30050/40000]	lr: 1.493e-05, eta: 3:27:19, time: 1.308, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1241, decode.acc_seg: 88.3669, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1360, mix.decode.acc_seg: 90.7999, masked.decode.loss_seg: 0.1566, masked.decode.acc_seg: 91.3566
2023-01-11 00:22:32,071 - mmseg - INFO - Iter [30100/40000]	lr: 1.485e-05, eta: 3:26:16, time: 1.221, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1031, decode.acc_seg: 89.1498, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1148, mix.decode.acc_seg: 91.1158, masked.decode.loss_seg: 0.1753, masked.decode.acc_seg: 90.7670
2023-01-11 00:23:33,239 - mmseg - INFO - Iter [30150/40000]	lr: 1.478e-05, eta: 3:25:13, time: 1.223, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1194, decode.acc_seg: 89.6615, src.loss_imnet_feat_dist: 0.1042, mix.decode.loss_seg: 0.1199, mix.decode.acc_seg: 90.4916, masked.decode.loss_seg: 0.1800, masked.decode.acc_seg: 89.7128
2023-01-11 00:24:34,470 - mmseg - INFO - Iter [30200/40000]	lr: 1.470e-05, eta: 3:24:10, time: 1.225, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0974, decode.acc_seg: 88.7643, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1112, mix.decode.acc_seg: 90.6641, masked.decode.loss_seg: 0.1663, masked.decode.acc_seg: 90.7385
2023-01-11 00:25:35,671 - mmseg - INFO - Iter [30250/40000]	lr: 1.463e-05, eta: 3:23:07, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1003, decode.acc_seg: 90.3403, src.loss_imnet_feat_dist: 0.0933, mix.decode.loss_seg: 0.1250, mix.decode.acc_seg: 91.4614, masked.decode.loss_seg: 0.1643, masked.decode.acc_seg: 91.0800
2023-01-11 00:26:36,657 - mmseg - INFO - Iter [30300/40000]	lr: 1.455e-05, eta: 3:22:04, time: 1.220, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0993, decode.acc_seg: 88.4052, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1120, mix.decode.acc_seg: 90.9255, masked.decode.loss_seg: 0.1688, masked.decode.acc_seg: 91.2898
2023-01-11 00:27:37,834 - mmseg - INFO - Iter [30350/40000]	lr: 1.448e-05, eta: 3:21:01, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1112, decode.acc_seg: 87.8184, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1645, mix.decode.acc_seg: 87.6049, masked.decode.loss_seg: 0.1733, masked.decode.acc_seg: 90.8309
2023-01-11 00:28:39,193 - mmseg - INFO - Iter [30400/40000]	lr: 1.440e-05, eta: 3:19:58, time: 1.227, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1172, decode.acc_seg: 89.3233, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1479, mix.decode.acc_seg: 91.0006, masked.decode.loss_seg: 0.1718, masked.decode.acc_seg: 91.0900
2023-01-11 00:29:40,493 - mmseg - INFO - Iter [30450/40000]	lr: 1.433e-05, eta: 3:18:56, time: 1.226, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0963, decode.acc_seg: 88.2216, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1139, mix.decode.acc_seg: 90.1117, masked.decode.loss_seg: 0.1606, masked.decode.acc_seg: 91.3195
2023-01-11 00:30:41,958 - mmseg - INFO - Iter [30500/40000]	lr: 1.425e-05, eta: 3:17:53, time: 1.229, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1161, decode.acc_seg: 88.3777, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1201, mix.decode.acc_seg: 91.2993, masked.decode.loss_seg: 0.1570, masked.decode.acc_seg: 91.3244
2023-01-11 00:31:43,425 - mmseg - INFO - Iter [30550/40000]	lr: 1.418e-05, eta: 3:16:50, time: 1.229, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1054, decode.acc_seg: 89.9364, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1154, mix.decode.acc_seg: 91.6162, masked.decode.loss_seg: 0.1574, masked.decode.acc_seg: 91.7833
2023-01-11 00:32:44,763 - mmseg - INFO - Iter [30600/40000]	lr: 1.410e-05, eta: 3:15:47, time: 1.227, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1006, decode.acc_seg: 88.7631, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1130, mix.decode.acc_seg: 91.3317, masked.decode.loss_seg: 0.1720, masked.decode.acc_seg: 91.1859
2023-01-11 00:33:45,924 - mmseg - INFO - Iter [30650/40000]	lr: 1.403e-05, eta: 3:14:44, time: 1.223, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1412, decode.acc_seg: 88.2853, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1407, mix.decode.acc_seg: 89.8369, masked.decode.loss_seg: 0.1569, masked.decode.acc_seg: 91.8686
2023-01-11 00:34:47,568 - mmseg - INFO - Iter [30700/40000]	lr: 1.395e-05, eta: 3:13:41, time: 1.233, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0976, decode.acc_seg: 87.7391, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1077, mix.decode.acc_seg: 89.6304, masked.decode.loss_seg: 0.1663, masked.decode.acc_seg: 90.9376
2023-01-11 00:35:48,811 - mmseg - INFO - Iter [30750/40000]	lr: 1.388e-05, eta: 3:12:39, time: 1.225, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1264, decode.acc_seg: 87.8074, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1347, mix.decode.acc_seg: 89.8529, masked.decode.loss_seg: 0.1708, masked.decode.acc_seg: 90.9828
2023-01-11 00:36:50,081 - mmseg - INFO - Iter [30800/40000]	lr: 1.380e-05, eta: 3:11:36, time: 1.225, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1244, decode.acc_seg: 89.6536, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1112, mix.decode.acc_seg: 91.7015, masked.decode.loss_seg: 0.1553, masked.decode.acc_seg: 91.5426
2023-01-11 00:37:51,263 - mmseg - INFO - Iter [30850/40000]	lr: 1.373e-05, eta: 3:10:33, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1170, decode.acc_seg: 89.7385, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1232, mix.decode.acc_seg: 90.9057, masked.decode.loss_seg: 0.1636, masked.decode.acc_seg: 91.1918
2023-01-11 00:38:52,763 - mmseg - INFO - Iter [30900/40000]	lr: 1.365e-05, eta: 3:09:30, time: 1.230, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1133, decode.acc_seg: 87.8630, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1376, mix.decode.acc_seg: 89.2145, masked.decode.loss_seg: 0.1680, masked.decode.acc_seg: 90.7974
2023-01-11 00:39:54,054 - mmseg - INFO - Iter [30950/40000]	lr: 1.358e-05, eta: 3:08:27, time: 1.226, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0956, decode.acc_seg: 88.7452, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1126, mix.decode.acc_seg: 90.4418, masked.decode.loss_seg: 0.1720, masked.decode.acc_seg: 90.1355
2023-01-11 00:40:55,109 - mmseg - INFO - Exp name: 230110_1355_230110_1343_gta2cs_dacs_a999_fdthings_rcs001_cpl_m32-07-spta_daformer_sepaspp_mitb5_poly10warm_s0_2feea_f2bea
2023-01-11 00:40:55,110 - mmseg - INFO - Iter [31000/40000]	lr: 1.350e-05, eta: 3:07:24, time: 1.221, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1027, decode.acc_seg: 88.4374, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1236, mix.decode.acc_seg: 90.3458, masked.decode.loss_seg: 0.1709, masked.decode.acc_seg: 90.6047
2023-01-11 00:41:59,967 - mmseg - INFO - Iter [31050/40000]	lr: 1.343e-05, eta: 3:06:23, time: 1.297, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1072, decode.acc_seg: 88.8249, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1205, mix.decode.acc_seg: 90.4052, masked.decode.loss_seg: 0.1702, masked.decode.acc_seg: 90.6478
2023-01-11 00:43:00,824 - mmseg - INFO - Iter [31100/40000]	lr: 1.335e-05, eta: 3:05:20, time: 1.217, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1033, decode.acc_seg: 88.6164, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1148, mix.decode.acc_seg: 91.8044, masked.decode.loss_seg: 0.1481, masked.decode.acc_seg: 91.8928
2023-01-11 00:44:01,702 - mmseg - INFO - Iter [31150/40000]	lr: 1.328e-05, eta: 3:04:17, time: 1.218, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1368, decode.acc_seg: 88.5964, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1245, mix.decode.acc_seg: 90.7437, masked.decode.loss_seg: 0.1713, masked.decode.acc_seg: 90.4814
2023-01-11 00:45:02,722 - mmseg - INFO - Iter [31200/40000]	lr: 1.320e-05, eta: 3:03:14, time: 1.220, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1048, decode.acc_seg: 88.7791, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1107, mix.decode.acc_seg: 89.8743, masked.decode.loss_seg: 0.1678, masked.decode.acc_seg: 90.9458
2023-01-11 00:46:03,776 - mmseg - INFO - Iter [31250/40000]	lr: 1.313e-05, eta: 3:02:11, time: 1.221, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1029, decode.acc_seg: 88.7831, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1221, mix.decode.acc_seg: 90.1771, masked.decode.loss_seg: 0.1711, masked.decode.acc_seg: 90.7545
2023-01-11 00:47:05,286 - mmseg - INFO - Iter [31300/40000]	lr: 1.305e-05, eta: 3:01:08, time: 1.230, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1127, decode.acc_seg: 87.5877, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1285, mix.decode.acc_seg: 88.7831, masked.decode.loss_seg: 0.1577, masked.decode.acc_seg: 91.1156
2023-01-11 00:48:06,411 - mmseg - INFO - Iter [31350/40000]	lr: 1.298e-05, eta: 3:00:05, time: 1.222, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1094, decode.acc_seg: 89.3782, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1137, mix.decode.acc_seg: 90.4553, masked.decode.loss_seg: 0.1724, masked.decode.acc_seg: 90.2957
2023-01-11 00:49:07,283 - mmseg - INFO - Iter [31400/40000]	lr: 1.290e-05, eta: 2:59:03, time: 1.217, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1129, decode.acc_seg: 88.0280, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1265, mix.decode.acc_seg: 89.7363, masked.decode.loss_seg: 0.1577, masked.decode.acc_seg: 91.4858
2023-01-11 00:50:08,463 - mmseg - INFO - Iter [31450/40000]	lr: 1.283e-05, eta: 2:58:00, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0945, decode.acc_seg: 88.4911, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1081, mix.decode.acc_seg: 90.7286, masked.decode.loss_seg: 0.1601, masked.decode.acc_seg: 90.9161
2023-01-11 00:51:09,697 - mmseg - INFO - Iter [31500/40000]	lr: 1.275e-05, eta: 2:56:57, time: 1.225, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1498, decode.acc_seg: 88.3399, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1298, mix.decode.acc_seg: 90.4045, masked.decode.loss_seg: 0.1513, masked.decode.acc_seg: 91.6626
2023-01-11 00:52:10,628 - mmseg - INFO - Iter [31550/40000]	lr: 1.268e-05, eta: 2:55:54, time: 1.219, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1154, decode.acc_seg: 88.0781, src.loss_imnet_feat_dist: 0.1012, mix.decode.loss_seg: 0.1399, mix.decode.acc_seg: 90.0717, masked.decode.loss_seg: 0.1622, masked.decode.acc_seg: 90.8910
2023-01-11 00:53:11,692 - mmseg - INFO - Iter [31600/40000]	lr: 1.260e-05, eta: 2:54:51, time: 1.221, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1030, decode.acc_seg: 88.3788, src.loss_imnet_feat_dist: 0.0960, mix.decode.loss_seg: 0.1125, mix.decode.acc_seg: 89.9980, masked.decode.loss_seg: 0.1567, masked.decode.acc_seg: 91.1983
2023-01-11 00:54:12,739 - mmseg - INFO - Iter [31650/40000]	lr: 1.253e-05, eta: 2:53:48, time: 1.221, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1152, decode.acc_seg: 87.6556, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1115, mix.decode.acc_seg: 91.1630, masked.decode.loss_seg: 0.1610, masked.decode.acc_seg: 90.6135
2023-01-11 00:55:13,916 - mmseg - INFO - Iter [31700/40000]	lr: 1.245e-05, eta: 2:52:46, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1042, decode.acc_seg: 88.7974, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1125, mix.decode.acc_seg: 90.6726, masked.decode.loss_seg: 0.1651, masked.decode.acc_seg: 91.1565
2023-01-11 00:56:15,139 - mmseg - INFO - Iter [31750/40000]	lr: 1.238e-05, eta: 2:51:43, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1179, decode.acc_seg: 87.9823, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1334, mix.decode.acc_seg: 89.9033, masked.decode.loss_seg: 0.1633, masked.decode.acc_seg: 91.0893
2023-01-11 00:57:16,665 - mmseg - INFO - Iter [31800/40000]	lr: 1.230e-05, eta: 2:50:40, time: 1.231, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0959, decode.acc_seg: 88.9272, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1080, mix.decode.acc_seg: 91.3498, masked.decode.loss_seg: 0.1609, masked.decode.acc_seg: 91.0638
2023-01-11 00:58:17,992 - mmseg - INFO - Iter [31850/40000]	lr: 1.223e-05, eta: 2:49:37, time: 1.227, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1034, decode.acc_seg: 89.8725, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1220, mix.decode.acc_seg: 91.2194, masked.decode.loss_seg: 0.1732, masked.decode.acc_seg: 90.8354
2023-01-11 00:59:19,267 - mmseg - INFO - Iter [31900/40000]	lr: 1.215e-05, eta: 2:48:35, time: 1.225, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1013, decode.acc_seg: 88.6650, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1146, mix.decode.acc_seg: 90.9191, masked.decode.loss_seg: 0.1629, masked.decode.acc_seg: 91.1092
2023-01-11 01:00:20,394 - mmseg - INFO - Iter [31950/40000]	lr: 1.208e-05, eta: 2:47:32, time: 1.223, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0928, decode.acc_seg: 88.3825, src.loss_imnet_feat_dist: 0.0982, mix.decode.loss_seg: 0.1113, mix.decode.acc_seg: 90.1614, masked.decode.loss_seg: 0.1657, masked.decode.acc_seg: 90.9394
2023-01-11 01:02:37,351 - mmseg - INFO - per class results:
2023-01-11 01:02:37,404 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      road     | 97.03 | 99.23 |
|    sidewalk   | 77.25 | 84.44 |
|    building   | 89.91 |  94.6 |
|      wall     | 55.81 | 69.85 |
|     fence     | 46.98 | 51.59 |
|      pole     | 51.01 | 59.21 |
| traffic light | 56.12 | 72.86 |
|  traffic sign | 62.66 | 67.85 |
|   vegetation  | 89.95 | 96.13 |
|    terrain    | 50.76 | 60.72 |
|      sky      | 91.85 | 99.15 |
|     person    | 71.69 | 83.91 |
|     rider     | 46.41 | 74.89 |
|      car      |  92.2 | 96.63 |
|     truck     | 80.56 | 89.15 |
|      bus      | 75.98 | 81.65 |
|     train     | 72.57 | 76.36 |
|   motorcycle  | 57.35 | 73.19 |
|    bicycle    | 62.48 | 75.38 |
+---------------+-------+-------+
2023-01-11 01:02:37,404 - mmseg - INFO - Summary:
2023-01-11 01:02:37,405 - mmseg - INFO - 
+-------+-------+------+
|  aAcc |  mIoU | mAcc |
+-------+-------+------+
| 94.36 | 69.92 | 79.3 |
+-------+-------+------+
2023-01-11 01:02:37,431 - mmseg - INFO - Exp name: 230110_1355_230110_1343_gta2cs_dacs_a999_fdthings_rcs001_cpl_m32-07-spta_daformer_sepaspp_mitb5_poly10warm_s0_2feea_f2bea
2023-01-11 01:02:37,433 - mmseg - INFO - Iter [500/40000]	lr: 1.200e-05, eta: 2:46:29, time: 1.223, data_time: 0.011, memory: 9807, aAcc: 0.9436, mIoU: 0.6992, mAcc: 0.7930, IoU.road: 0.9703, IoU.sidewalk: 0.7725, IoU.building: 0.8991, IoU.wall: 0.5581, IoU.fence: 0.4698, IoU.pole: 0.5101, IoU.traffic light: 0.5612, IoU.traffic sign: 0.6266, IoU.vegetation: 0.8995, IoU.terrain: 0.5076, IoU.sky: 0.9185, IoU.person: 0.7169, IoU.rider: 0.4641, IoU.car: 0.9220, IoU.truck: 0.8056, IoU.bus: 0.7598, IoU.train: 0.7257, IoU.motorcycle: 0.5735, IoU.bicycle: 0.6248, Acc.road: 0.9923, Acc.sidewalk: 0.8444, Acc.building: 0.9460, Acc.wall: 0.6985, Acc.fence: 0.5159, Acc.pole: 0.5921, Acc.traffic light: 0.7286, Acc.traffic sign: 0.6785, Acc.vegetation: 0.9613, Acc.terrain: 0.6072, Acc.sky: 0.9915, Acc.person: 0.8391, Acc.rider: 0.7489, Acc.car: 0.9663, Acc.truck: 0.8915, Acc.bus: 0.8165, Acc.train: 0.7636, Acc.motorcycle: 0.7319, Acc.bicycle: 0.7538, decode.loss_seg: 0.1194, decode.acc_seg: 87.3684, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1247, mix.decode.acc_seg: 90.4093, masked.decode.loss_seg: 0.1721, masked.decode.acc_seg: 91.2466
2023-01-11 01:03:44,207 - mmseg - INFO - Iter [32050/40000]	lr: 1.193e-05, eta: 2:45:47, time: 2.853, data_time: 1.530, memory: 9807, decode.loss_seg: 0.1013, decode.acc_seg: 89.4762, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1163, mix.decode.acc_seg: 89.2057, masked.decode.loss_seg: 0.1567, masked.decode.acc_seg: 91.0133
2023-01-11 01:04:45,406 - mmseg - INFO - Iter [32100/40000]	lr: 1.185e-05, eta: 2:44:44, time: 1.224, data_time: 0.012, memory: 9807, decode.loss_seg: 0.0991, decode.acc_seg: 89.5596, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1160, mix.decode.acc_seg: 91.3591, masked.decode.loss_seg: 0.1727, masked.decode.acc_seg: 90.9237
2023-01-11 01:05:46,700 - mmseg - INFO - Iter [32150/40000]	lr: 1.178e-05, eta: 2:43:41, time: 1.226, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1233, decode.acc_seg: 89.1381, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1130, mix.decode.acc_seg: 91.8149, masked.decode.loss_seg: 0.1531, masked.decode.acc_seg: 91.3409
2023-01-11 01:06:48,136 - mmseg - INFO - Iter [32200/40000]	lr: 1.170e-05, eta: 2:42:38, time: 1.229, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1524, decode.acc_seg: 88.7586, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1528, mix.decode.acc_seg: 89.5415, masked.decode.loss_seg: 0.1607, masked.decode.acc_seg: 91.1720
2023-01-11 01:07:49,718 - mmseg - INFO - Iter [32250/40000]	lr: 1.163e-05, eta: 2:41:35, time: 1.232, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0916, decode.acc_seg: 88.3540, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1126, mix.decode.acc_seg: 89.7720, masked.decode.loss_seg: 0.1753, masked.decode.acc_seg: 90.2196
2023-01-11 01:08:51,236 - mmseg - INFO - Iter [32300/40000]	lr: 1.155e-05, eta: 2:40:33, time: 1.230, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1118, decode.acc_seg: 88.8653, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1189, mix.decode.acc_seg: 91.4582, masked.decode.loss_seg: 0.1590, masked.decode.acc_seg: 91.2387
2023-01-11 01:09:52,361 - mmseg - INFO - Iter [32350/40000]	lr: 1.148e-05, eta: 2:39:30, time: 1.223, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1219, decode.acc_seg: 87.7746, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1235, mix.decode.acc_seg: 90.4425, masked.decode.loss_seg: 0.1618, masked.decode.acc_seg: 91.2200
2023-01-11 01:10:53,604 - mmseg - INFO - Iter [32400/40000]	lr: 1.140e-05, eta: 2:38:27, time: 1.225, data_time: 0.013, memory: 9807, decode.loss_seg: 0.1118, decode.acc_seg: 88.6435, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1238, mix.decode.acc_seg: 90.1716, masked.decode.loss_seg: 0.1602, masked.decode.acc_seg: 91.0722
2023-01-11 01:11:54,917 - mmseg - INFO - Iter [32450/40000]	lr: 1.133e-05, eta: 2:37:24, time: 1.226, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1046, decode.acc_seg: 89.0306, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1191, mix.decode.acc_seg: 91.3228, masked.decode.loss_seg: 0.1569, masked.decode.acc_seg: 91.5199
2023-01-11 01:12:56,152 - mmseg - INFO - Iter [32500/40000]	lr: 1.125e-05, eta: 2:36:21, time: 1.225, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1009, decode.acc_seg: 89.6920, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1157, mix.decode.acc_seg: 91.4396, masked.decode.loss_seg: 0.1575, masked.decode.acc_seg: 91.5164
2023-01-11 01:13:57,063 - mmseg - INFO - Iter [32550/40000]	lr: 1.118e-05, eta: 2:35:18, time: 1.218, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1021, decode.acc_seg: 87.5593, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1203, mix.decode.acc_seg: 89.5329, masked.decode.loss_seg: 0.1560, masked.decode.acc_seg: 90.6897
2023-01-11 01:14:58,233 - mmseg - INFO - Iter [32600/40000]	lr: 1.110e-05, eta: 2:34:15, time: 1.223, data_time: 0.012, memory: 9807, decode.loss_seg: 0.0954, decode.acc_seg: 87.9162, src.loss_imnet_feat_dist: 0.0999, mix.decode.loss_seg: 0.1092, mix.decode.acc_seg: 90.0333, masked.decode.loss_seg: 0.1657, masked.decode.acc_seg: 91.3519
2023-01-11 01:15:59,514 - mmseg - INFO - Iter [32650/40000]	lr: 1.103e-05, eta: 2:33:12, time: 1.226, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1013, decode.acc_seg: 87.4708, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1177, mix.decode.acc_seg: 89.9669, masked.decode.loss_seg: 0.1650, masked.decode.acc_seg: 91.2677
2023-01-11 01:17:00,997 - mmseg - INFO - Iter [32700/40000]	lr: 1.095e-05, eta: 2:32:10, time: 1.230, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0984, decode.acc_seg: 88.9777, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1225, mix.decode.acc_seg: 91.0491, masked.decode.loss_seg: 0.1662, masked.decode.acc_seg: 91.1299
2023-01-11 01:18:02,414 - mmseg - INFO - Iter [32750/40000]	lr: 1.088e-05, eta: 2:31:07, time: 1.228, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1004, decode.acc_seg: 89.7140, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1076, mix.decode.acc_seg: 90.2213, masked.decode.loss_seg: 0.1555, masked.decode.acc_seg: 91.1062
2023-01-11 01:19:03,597 - mmseg - INFO - Iter [32800/40000]	lr: 1.080e-05, eta: 2:30:04, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0988, decode.acc_seg: 87.6860, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1033, mix.decode.acc_seg: 89.7092, masked.decode.loss_seg: 0.1643, masked.decode.acc_seg: 91.1017
2023-01-11 01:20:04,586 - mmseg - INFO - Iter [32850/40000]	lr: 1.073e-05, eta: 2:29:01, time: 1.220, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1029, decode.acc_seg: 87.8062, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1196, mix.decode.acc_seg: 90.7182, masked.decode.loss_seg: 0.1616, masked.decode.acc_seg: 91.1601
2023-01-11 01:21:05,710 - mmseg - INFO - Iter [32900/40000]	lr: 1.065e-05, eta: 2:27:58, time: 1.222, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0946, decode.acc_seg: 87.5785, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1213, mix.decode.acc_seg: 89.2323, masked.decode.loss_seg: 0.1688, masked.decode.acc_seg: 90.9425
2023-01-11 01:22:07,023 - mmseg - INFO - Iter [32950/40000]	lr: 1.058e-05, eta: 2:26:56, time: 1.226, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1068, decode.acc_seg: 88.9002, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1170, mix.decode.acc_seg: 90.4277, masked.decode.loss_seg: 0.1683, masked.decode.acc_seg: 90.8617
2023-01-11 01:23:08,531 - mmseg - INFO - Exp name: 230110_1355_230110_1343_gta2cs_dacs_a999_fdthings_rcs001_cpl_m32-07-spta_daformer_sepaspp_mitb5_poly10warm_s0_2feea_f2bea
2023-01-11 01:23:08,532 - mmseg - INFO - Iter [33000/40000]	lr: 1.050e-05, eta: 2:25:53, time: 1.230, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1312, decode.acc_seg: 89.0728, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1362, mix.decode.acc_seg: 91.7640, masked.decode.loss_seg: 0.1525, masked.decode.acc_seg: 91.8298
2023-01-11 01:24:18,829 - mmseg - INFO - Iter [33050/40000]	lr: 1.043e-05, eta: 2:24:52, time: 1.406, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1284, decode.acc_seg: 86.4857, src.loss_imnet_feat_dist: 0.0997, mix.decode.loss_seg: 0.1344, mix.decode.acc_seg: 90.1509, masked.decode.loss_seg: 0.1667, masked.decode.acc_seg: 90.8653
2023-01-11 01:25:20,517 - mmseg - INFO - Iter [33100/40000]	lr: 1.035e-05, eta: 2:23:49, time: 1.234, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1031, decode.acc_seg: 89.0224, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1220, mix.decode.acc_seg: 91.0936, masked.decode.loss_seg: 0.1660, masked.decode.acc_seg: 90.6608
2023-01-11 01:26:21,734 - mmseg - INFO - Iter [33150/40000]	lr: 1.028e-05, eta: 2:22:46, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1027, decode.acc_seg: 87.2136, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1110, mix.decode.acc_seg: 90.2422, masked.decode.loss_seg: 0.1589, masked.decode.acc_seg: 91.0186
2023-01-11 01:27:22,687 - mmseg - INFO - Iter [33200/40000]	lr: 1.020e-05, eta: 2:21:44, time: 1.219, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1146, decode.acc_seg: 87.8740, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1146, mix.decode.acc_seg: 90.9881, masked.decode.loss_seg: 0.1681, masked.decode.acc_seg: 91.2400
2023-01-11 01:28:23,874 - mmseg - INFO - Iter [33250/40000]	lr: 1.013e-05, eta: 2:20:41, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1020, decode.acc_seg: 87.8940, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1122, mix.decode.acc_seg: 90.3554, masked.decode.loss_seg: 0.1681, masked.decode.acc_seg: 90.7277
2023-01-11 01:29:25,010 - mmseg - INFO - Iter [33300/40000]	lr: 1.005e-05, eta: 2:19:38, time: 1.223, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1139, decode.acc_seg: 88.6456, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1260, mix.decode.acc_seg: 90.0963, masked.decode.loss_seg: 0.1654, masked.decode.acc_seg: 90.9769
2023-01-11 01:30:26,222 - mmseg - INFO - Iter [33350/40000]	lr: 9.976e-06, eta: 2:18:35, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1075, decode.acc_seg: 87.2830, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1265, mix.decode.acc_seg: 89.9008, masked.decode.loss_seg: 0.1632, masked.decode.acc_seg: 90.7407
2023-01-11 01:31:27,266 - mmseg - INFO - Iter [33400/40000]	lr: 9.901e-06, eta: 2:17:32, time: 1.221, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1035, decode.acc_seg: 89.2386, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1238, mix.decode.acc_seg: 91.0531, masked.decode.loss_seg: 0.1537, masked.decode.acc_seg: 90.9547
2023-01-11 01:32:28,461 - mmseg - INFO - Iter [33450/40000]	lr: 9.826e-06, eta: 2:16:30, time: 1.224, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0955, decode.acc_seg: 89.3118, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1160, mix.decode.acc_seg: 90.7709, masked.decode.loss_seg: 0.1695, masked.decode.acc_seg: 90.7702
2023-01-11 01:33:29,491 - mmseg - INFO - Iter [33500/40000]	lr: 9.752e-06, eta: 2:15:27, time: 1.221, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1001, decode.acc_seg: 90.2825, src.loss_imnet_feat_dist: 0.0960, mix.decode.loss_seg: 0.1145, mix.decode.acc_seg: 90.9069, masked.decode.loss_seg: 0.1676, masked.decode.acc_seg: 90.5369
2023-01-11 01:34:30,737 - mmseg - INFO - Iter [33550/40000]	lr: 9.676e-06, eta: 2:14:24, time: 1.225, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1120, decode.acc_seg: 88.2671, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1204, mix.decode.acc_seg: 90.2552, masked.decode.loss_seg: 0.1545, masked.decode.acc_seg: 91.3117
2023-01-11 01:35:33,487 - mmseg - INFO - Iter [33600/40000]	lr: 9.601e-06, eta: 2:13:22, time: 1.255, data_time: 0.012, memory: 9807, decode.loss_seg: 0.1032, decode.acc_seg: 89.2244, src.loss_imnet_feat_dist: 0.0922, mix.decode.loss_seg: 0.1114, mix.decode.acc_seg: 90.9666, masked.decode.loss_seg: 0.1611, masked.decode.acc_seg: 91.2733
2023-01-11 01:36:35,762 - mmseg - INFO - Iter [33650/40000]	lr: 9.527e-06, eta: 2:12:19, time: 1.245, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1008, decode.acc_seg: 87.9538, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1142, mix.decode.acc_seg: 90.6838, masked.decode.loss_seg: 0.1691, masked.decode.acc_seg: 90.8715
2023-01-11 01:37:37,644 - mmseg - INFO - Iter [33700/40000]	lr: 9.452e-06, eta: 2:11:16, time: 1.238, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0992, decode.acc_seg: 87.3894, src.loss_imnet_feat_dist: 0.0951, mix.decode.loss_seg: 0.1142, mix.decode.acc_seg: 90.1578, masked.decode.loss_seg: 0.1552, masked.decode.acc_seg: 91.0362
2023-01-11 01:38:39,670 - mmseg - INFO - Iter [33750/40000]	lr: 9.377e-06, eta: 2:10:14, time: 1.241, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1149, decode.acc_seg: 86.3011, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1160, mix.decode.acc_seg: 89.1900, masked.decode.loss_seg: 0.1676, masked.decode.acc_seg: 91.1305
2023-01-11 01:39:42,138 - mmseg - INFO - Iter [33800/40000]	lr: 9.301e-06, eta: 2:09:11, time: 1.249, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0955, decode.acc_seg: 89.1051, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1103, mix.decode.acc_seg: 90.3713, masked.decode.loss_seg: 0.1662, masked.decode.acc_seg: 90.6840
2023-01-11 01:40:44,434 - mmseg - INFO - Iter [33850/40000]	lr: 9.227e-06, eta: 2:08:09, time: 1.246, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1175, decode.acc_seg: 88.6392, src.loss_imnet_feat_dist: 0.0996, mix.decode.loss_seg: 0.1146, mix.decode.acc_seg: 90.4315, masked.decode.loss_seg: 0.1743, masked.decode.acc_seg: 90.7581
2023-01-11 01:41:46,647 - mmseg - INFO - Iter [33900/40000]	lr: 9.152e-06, eta: 2:07:06, time: 1.244, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1111, decode.acc_seg: 88.9127, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1210, mix.decode.acc_seg: 90.7516, masked.decode.loss_seg: 0.1667, masked.decode.acc_seg: 91.0496
2023-01-11 01:42:48,788 - mmseg - INFO - Iter [33950/40000]	lr: 9.077e-06, eta: 2:06:04, time: 1.243, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1033, decode.acc_seg: 89.0272, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1146, mix.decode.acc_seg: 90.2162, masked.decode.loss_seg: 0.1725, masked.decode.acc_seg: 90.7331
2023-01-11 01:43:51,116 - mmseg - INFO - Exp name: 230110_1355_230110_1343_gta2cs_dacs_a999_fdthings_rcs001_cpl_m32-07-spta_daformer_sepaspp_mitb5_poly10warm_s0_2feea_f2bea
2023-01-11 01:43:51,116 - mmseg - INFO - Iter [34000/40000]	lr: 9.001e-06, eta: 2:05:01, time: 1.247, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1053, decode.acc_seg: 88.3150, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1199, mix.decode.acc_seg: 91.1045, masked.decode.loss_seg: 0.1677, masked.decode.acc_seg: 90.8839
2023-01-11 01:44:57,186 - mmseg - INFO - Iter [34050/40000]	lr: 8.926e-06, eta: 2:03:59, time: 1.321, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0958, decode.acc_seg: 88.8535, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1141, mix.decode.acc_seg: 91.2772, masked.decode.loss_seg: 0.1687, masked.decode.acc_seg: 90.8668
2023-01-11 01:45:59,432 - mmseg - INFO - Iter [34100/40000]	lr: 8.852e-06, eta: 2:02:57, time: 1.245, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1175, decode.acc_seg: 89.6687, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1069, mix.decode.acc_seg: 91.4497, masked.decode.loss_seg: 0.1677, masked.decode.acc_seg: 91.0160
2023-01-11 01:47:01,698 - mmseg - INFO - Iter [34150/40000]	lr: 8.777e-06, eta: 2:01:54, time: 1.245, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1047, decode.acc_seg: 88.4042, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1158, mix.decode.acc_seg: 91.1746, masked.decode.loss_seg: 0.1499, masked.decode.acc_seg: 92.0433
2023-01-11 01:48:04,127 - mmseg - INFO - Iter [34200/40000]	lr: 8.701e-06, eta: 2:00:51, time: 1.249, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1149, decode.acc_seg: 88.3898, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1059, mix.decode.acc_seg: 91.2763, masked.decode.loss_seg: 0.1543, masked.decode.acc_seg: 91.6515
2023-01-11 01:49:06,253 - mmseg - INFO - Iter [34250/40000]	lr: 8.626e-06, eta: 1:59:49, time: 1.243, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1019, decode.acc_seg: 88.0101, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1170, mix.decode.acc_seg: 90.0535, masked.decode.loss_seg: 0.1706, masked.decode.acc_seg: 91.1125
2023-01-11 01:50:08,756 - mmseg - INFO - Iter [34300/40000]	lr: 8.552e-06, eta: 1:58:46, time: 1.250, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1010, decode.acc_seg: 89.0443, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1181, mix.decode.acc_seg: 91.1339, masked.decode.loss_seg: 0.1561, masked.decode.acc_seg: 91.8120
2023-01-11 01:51:11,035 - mmseg - INFO - Iter [34350/40000]	lr: 8.477e-06, eta: 1:57:44, time: 1.246, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1073, decode.acc_seg: 89.1061, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1210, mix.decode.acc_seg: 90.8728, masked.decode.loss_seg: 0.1564, masked.decode.acc_seg: 91.7878
2023-01-11 01:52:13,251 - mmseg - INFO - Iter [34400/40000]	lr: 8.401e-06, eta: 1:56:41, time: 1.244, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0957, decode.acc_seg: 88.6656, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1138, mix.decode.acc_seg: 90.3790, masked.decode.loss_seg: 0.1532, masked.decode.acc_seg: 92.0524
2023-01-11 01:53:15,122 - mmseg - INFO - Iter [34450/40000]	lr: 8.326e-06, eta: 1:55:39, time: 1.237, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1110, decode.acc_seg: 88.0382, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1236, mix.decode.acc_seg: 89.4218, masked.decode.loss_seg: 0.1535, masked.decode.acc_seg: 91.7357
2023-01-11 01:54:17,414 - mmseg - INFO - Iter [34500/40000]	lr: 8.252e-06, eta: 1:54:36, time: 1.246, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0997, decode.acc_seg: 89.0694, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1118, mix.decode.acc_seg: 90.5527, masked.decode.loss_seg: 0.1571, masked.decode.acc_seg: 91.8180
2023-01-11 01:55:19,383 - mmseg - INFO - Iter [34550/40000]	lr: 8.177e-06, eta: 1:53:33, time: 1.239, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1163, decode.acc_seg: 88.3574, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1256, mix.decode.acc_seg: 91.2647, masked.decode.loss_seg: 0.1615, masked.decode.acc_seg: 91.7401
2023-01-11 01:56:21,353 - mmseg - INFO - Iter [34600/40000]	lr: 8.101e-06, eta: 1:52:31, time: 1.239, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1092, decode.acc_seg: 89.8192, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1113, mix.decode.acc_seg: 92.2311, masked.decode.loss_seg: 0.1712, masked.decode.acc_seg: 91.7481
2023-01-11 01:57:23,923 - mmseg - INFO - Iter [34650/40000]	lr: 8.026e-06, eta: 1:51:28, time: 1.251, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1035, decode.acc_seg: 87.8155, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1204, mix.decode.acc_seg: 89.3409, masked.decode.loss_seg: 0.1743, masked.decode.acc_seg: 91.2634
2023-01-11 01:58:26,048 - mmseg - INFO - Iter [34700/40000]	lr: 7.952e-06, eta: 1:50:26, time: 1.242, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1062, decode.acc_seg: 88.4357, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1145, mix.decode.acc_seg: 91.4063, masked.decode.loss_seg: 0.1615, masked.decode.acc_seg: 91.8155
2023-01-11 01:59:28,155 - mmseg - INFO - Iter [34750/40000]	lr: 7.877e-06, eta: 1:49:23, time: 1.242, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1129, decode.acc_seg: 87.4904, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1132, mix.decode.acc_seg: 91.0411, masked.decode.loss_seg: 0.1597, masked.decode.acc_seg: 91.4346
2023-01-11 02:00:30,409 - mmseg - INFO - Iter [34800/40000]	lr: 7.801e-06, eta: 1:48:21, time: 1.245, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0997, decode.acc_seg: 87.9117, src.loss_imnet_feat_dist: 0.0983, mix.decode.loss_seg: 0.1128, mix.decode.acc_seg: 90.6013, masked.decode.loss_seg: 0.1619, masked.decode.acc_seg: 91.6521
2023-01-11 02:01:32,526 - mmseg - INFO - Iter [34850/40000]	lr: 7.726e-06, eta: 1:47:18, time: 1.242, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1263, decode.acc_seg: 88.0113, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1348, mix.decode.acc_seg: 91.0156, masked.decode.loss_seg: 0.1586, masked.decode.acc_seg: 91.8363
2023-01-11 02:02:34,787 - mmseg - INFO - Iter [34900/40000]	lr: 7.651e-06, eta: 1:46:16, time: 1.245, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1033, decode.acc_seg: 88.6801, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1175, mix.decode.acc_seg: 90.2684, masked.decode.loss_seg: 0.1539, masked.decode.acc_seg: 91.9778
2023-01-11 02:03:36,870 - mmseg - INFO - Iter [34950/40000]	lr: 7.577e-06, eta: 1:45:13, time: 1.242, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0967, decode.acc_seg: 89.6667, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1085, mix.decode.acc_seg: 91.8608, masked.decode.loss_seg: 0.1677, masked.decode.acc_seg: 91.6133
2023-01-11 02:04:38,895 - mmseg - INFO - Exp name: 230110_1355_230110_1343_gta2cs_dacs_a999_fdthings_rcs001_cpl_m32-07-spta_daformer_sepaspp_mitb5_poly10warm_s0_2feea_f2bea
2023-01-11 02:04:38,896 - mmseg - INFO - Iter [35000/40000]	lr: 7.502e-06, eta: 1:44:10, time: 1.241, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1075, decode.acc_seg: 88.0598, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1110, mix.decode.acc_seg: 90.3033, masked.decode.loss_seg: 0.1648, masked.decode.acc_seg: 91.7863
2023-01-11 02:05:45,651 - mmseg - INFO - Iter [35050/40000]	lr: 7.426e-06, eta: 1:43:08, time: 1.335, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0993, decode.acc_seg: 88.1526, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1222, mix.decode.acc_seg: 90.8280, masked.decode.loss_seg: 0.1626, masked.decode.acc_seg: 91.6741
2023-01-11 02:06:47,950 - mmseg - INFO - Iter [35100/40000]	lr: 7.351e-06, eta: 1:42:06, time: 1.246, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1047, decode.acc_seg: 87.8351, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1207, mix.decode.acc_seg: 90.4901, masked.decode.loss_seg: 0.1613, masked.decode.acc_seg: 91.8947
2023-01-11 02:07:50,062 - mmseg - INFO - Iter [35150/40000]	lr: 7.277e-06, eta: 1:41:03, time: 1.242, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1103, decode.acc_seg: 87.7209, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1241, mix.decode.acc_seg: 90.0410, masked.decode.loss_seg: 0.1706, masked.decode.acc_seg: 91.2954
2023-01-11 02:08:52,117 - mmseg - INFO - Iter [35200/40000]	lr: 7.202e-06, eta: 1:40:01, time: 1.241, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0940, decode.acc_seg: 87.5887, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1111, mix.decode.acc_seg: 89.5753, masked.decode.loss_seg: 0.1625, masked.decode.acc_seg: 91.6005
2023-01-11 02:09:54,652 - mmseg - INFO - Iter [35250/40000]	lr: 7.126e-06, eta: 1:38:58, time: 1.251, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1106, decode.acc_seg: 89.9130, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1305, mix.decode.acc_seg: 91.9297, masked.decode.loss_seg: 0.1632, masked.decode.acc_seg: 91.7014
2023-01-11 02:10:57,090 - mmseg - INFO - Iter [35300/40000]	lr: 7.051e-06, eta: 1:37:56, time: 1.249, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1023, decode.acc_seg: 88.2565, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1158, mix.decode.acc_seg: 91.4949, masked.decode.loss_seg: 0.1547, masked.decode.acc_seg: 92.4286
2023-01-11 02:11:59,146 - mmseg - INFO - Iter [35350/40000]	lr: 6.977e-06, eta: 1:36:53, time: 1.241, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0958, decode.acc_seg: 88.2241, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1180, mix.decode.acc_seg: 89.3721, masked.decode.loss_seg: 0.1636, masked.decode.acc_seg: 91.3460
2023-01-11 02:13:01,440 - mmseg - INFO - Iter [35400/40000]	lr: 6.902e-06, eta: 1:35:51, time: 1.246, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1098, decode.acc_seg: 88.4053, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1126, mix.decode.acc_seg: 91.1853, masked.decode.loss_seg: 0.1708, masked.decode.acc_seg: 91.6148
2023-01-11 02:14:03,804 - mmseg - INFO - Iter [35450/40000]	lr: 6.826e-06, eta: 1:34:48, time: 1.247, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1037, decode.acc_seg: 87.1224, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1126, mix.decode.acc_seg: 90.1937, masked.decode.loss_seg: 0.1560, masked.decode.acc_seg: 92.3670
2023-01-11 02:15:06,441 - mmseg - INFO - Iter [35500/40000]	lr: 6.751e-06, eta: 1:33:46, time: 1.253, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1128, decode.acc_seg: 88.3178, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1161, mix.decode.acc_seg: 90.6077, masked.decode.loss_seg: 0.1566, masked.decode.acc_seg: 91.4804
2023-01-11 02:16:08,723 - mmseg - INFO - Iter [35550/40000]	lr: 6.677e-06, eta: 1:32:43, time: 1.246, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0989, decode.acc_seg: 87.4830, src.loss_imnet_feat_dist: 0.0946, mix.decode.loss_seg: 0.1209, mix.decode.acc_seg: 90.5537, masked.decode.loss_seg: 0.1643, masked.decode.acc_seg: 91.8368
2023-01-11 02:17:10,965 - mmseg - INFO - Iter [35600/40000]	lr: 6.602e-06, eta: 1:31:41, time: 1.245, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0979, decode.acc_seg: 89.2501, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1201, mix.decode.acc_seg: 90.7512, masked.decode.loss_seg: 0.1561, masked.decode.acc_seg: 91.9874
2023-01-11 02:18:12,797 - mmseg - INFO - Iter [35650/40000]	lr: 6.526e-06, eta: 1:30:38, time: 1.237, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0969, decode.acc_seg: 89.4256, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1040, mix.decode.acc_seg: 92.2678, masked.decode.loss_seg: 0.1651, masked.decode.acc_seg: 91.5733
2023-01-11 02:19:15,077 - mmseg - INFO - Iter [35700/40000]	lr: 6.451e-06, eta: 1:29:35, time: 1.246, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1332, decode.acc_seg: 88.4929, src.loss_imnet_feat_dist: 0.0939, mix.decode.loss_seg: 0.1272, mix.decode.acc_seg: 90.6261, masked.decode.loss_seg: 0.1579, masked.decode.acc_seg: 91.8813
2023-01-11 02:20:17,516 - mmseg - INFO - Iter [35750/40000]	lr: 6.377e-06, eta: 1:28:33, time: 1.249, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1041, decode.acc_seg: 86.9333, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1208, mix.decode.acc_seg: 90.1083, masked.decode.loss_seg: 0.1549, masked.decode.acc_seg: 91.8444
2023-01-11 02:21:19,556 - mmseg - INFO - Iter [35800/40000]	lr: 6.302e-06, eta: 1:27:30, time: 1.241, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0907, decode.acc_seg: 88.6859, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1076, mix.decode.acc_seg: 91.0324, masked.decode.loss_seg: 0.1614, masked.decode.acc_seg: 91.3425
2023-01-11 02:22:21,768 - mmseg - INFO - Iter [35850/40000]	lr: 6.226e-06, eta: 1:26:28, time: 1.244, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1104, decode.acc_seg: 87.9028, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1193, mix.decode.acc_seg: 90.0233, masked.decode.loss_seg: 0.1625, masked.decode.acc_seg: 91.6566
2023-01-11 02:23:23,897 - mmseg - INFO - Iter [35900/40000]	lr: 6.151e-06, eta: 1:25:25, time: 1.243, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1023, decode.acc_seg: 89.5134, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1288, mix.decode.acc_seg: 91.3311, masked.decode.loss_seg: 0.1663, masked.decode.acc_seg: 91.4591
2023-01-11 02:24:25,768 - mmseg - INFO - Iter [35950/40000]	lr: 6.077e-06, eta: 1:24:23, time: 1.237, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0925, decode.acc_seg: 87.2311, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1043, mix.decode.acc_seg: 90.9264, masked.decode.loss_seg: 0.1695, masked.decode.acc_seg: 91.2632
2023-01-11 02:26:48,118 - mmseg - INFO - per class results:
2023-01-11 02:26:48,139 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      road     | 97.09 | 99.17 |
|    sidewalk   |  77.9 | 84.98 |
|    building   | 89.96 | 95.29 |
|      wall     |  56.5 | 68.17 |
|     fence     | 47.96 | 52.95 |
|      pole     | 50.61 | 58.48 |
| traffic light | 54.37 | 76.29 |
|  traffic sign | 62.34 | 67.42 |
|   vegetation  | 90.31 | 95.96 |
|    terrain    | 51.46 | 60.65 |
|      sky      | 92.26 | 98.98 |
|     person    |  72.4 | 86.24 |
|     rider     | 47.81 | 69.92 |
|      car      | 92.23 | 95.94 |
|     truck     | 75.52 | 90.41 |
|      bus      | 78.64 | 84.15 |
|     train     |  71.3 | 76.07 |
|   motorcycle  | 58.63 | 73.21 |
|    bicycle    | 63.18 | 75.48 |
+---------------+-------+-------+
2023-01-11 02:26:48,139 - mmseg - INFO - Summary:
2023-01-11 02:26:48,139 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 94.46 | 70.02 | 79.46 |
+-------+-------+-------+
2023-01-11 02:26:48,148 - mmseg - INFO - Exp name: 230110_1355_230110_1343_gta2cs_dacs_a999_fdthings_rcs001_cpl_m32-07-spta_daformer_sepaspp_mitb5_poly10warm_s0_2feea_f2bea
2023-01-11 02:26:48,148 - mmseg - INFO - Iter [500/40000]	lr: 6.002e-06, eta: 1:23:20, time: 1.239, data_time: 0.011, memory: 9807, aAcc: 0.9446, mIoU: 0.7002, mAcc: 0.7946, IoU.road: 0.9709, IoU.sidewalk: 0.7790, IoU.building: 0.8996, IoU.wall: 0.5650, IoU.fence: 0.4796, IoU.pole: 0.5061, IoU.traffic light: 0.5437, IoU.traffic sign: 0.6234, IoU.vegetation: 0.9031, IoU.terrain: 0.5146, IoU.sky: 0.9226, IoU.person: 0.7240, IoU.rider: 0.4781, IoU.car: 0.9223, IoU.truck: 0.7552, IoU.bus: 0.7864, IoU.train: 0.7130, IoU.motorcycle: 0.5863, IoU.bicycle: 0.6318, Acc.road: 0.9917, Acc.sidewalk: 0.8498, Acc.building: 0.9529, Acc.wall: 0.6817, Acc.fence: 0.5295, Acc.pole: 0.5848, Acc.traffic light: 0.7629, Acc.traffic sign: 0.6742, Acc.vegetation: 0.9596, Acc.terrain: 0.6065, Acc.sky: 0.9898, Acc.person: 0.8624, Acc.rider: 0.6992, Acc.car: 0.9594, Acc.truck: 0.9041, Acc.bus: 0.8415, Acc.train: 0.7607, Acc.motorcycle: 0.7321, Acc.bicycle: 0.7548, decode.loss_seg: 0.1108, decode.acc_seg: 87.3411, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1349, mix.decode.acc_seg: 90.4257, masked.decode.loss_seg: 0.1661, masked.decode.acc_seg: 91.2408
2023-01-11 02:27:55,215 - mmseg - INFO - Iter [36050/40000]	lr: 5.926e-06, eta: 1:22:27, time: 2.950, data_time: 1.622, memory: 9807, decode.loss_seg: 0.1004, decode.acc_seg: 89.2364, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1133, mix.decode.acc_seg: 90.2913, masked.decode.loss_seg: 0.1569, masked.decode.acc_seg: 91.6863
2023-01-11 02:28:57,114 - mmseg - INFO - Iter [36100/40000]	lr: 5.851e-06, eta: 1:21:24, time: 1.238, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0931, decode.acc_seg: 89.0600, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1055, mix.decode.acc_seg: 90.8186, masked.decode.loss_seg: 0.1612, masked.decode.acc_seg: 91.7279
2023-01-11 02:29:58,712 - mmseg - INFO - Iter [36150/40000]	lr: 5.777e-06, eta: 1:20:21, time: 1.232, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0985, decode.acc_seg: 87.9139, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1209, mix.decode.acc_seg: 90.4511, masked.decode.loss_seg: 0.1619, masked.decode.acc_seg: 92.0601
2023-01-11 02:31:00,841 - mmseg - INFO - Iter [36200/40000]	lr: 5.702e-06, eta: 1:19:19, time: 1.243, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0975, decode.acc_seg: 88.3699, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1114, mix.decode.acc_seg: 89.8571, masked.decode.loss_seg: 0.1693, masked.decode.acc_seg: 91.5249
2023-01-11 02:32:02,676 - mmseg - INFO - Iter [36250/40000]	lr: 5.627e-06, eta: 1:18:16, time: 1.237, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0987, decode.acc_seg: 88.1614, src.loss_imnet_feat_dist: 0.0939, mix.decode.loss_seg: 0.1117, mix.decode.acc_seg: 89.8231, masked.decode.loss_seg: 0.1563, masked.decode.acc_seg: 91.8180
2023-01-11 02:33:04,723 - mmseg - INFO - Iter [36300/40000]	lr: 5.551e-06, eta: 1:17:13, time: 1.241, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0923, decode.acc_seg: 88.6083, src.loss_imnet_feat_dist: 0.0986, mix.decode.loss_seg: 0.1042, mix.decode.acc_seg: 91.2861, masked.decode.loss_seg: 0.1612, masked.decode.acc_seg: 91.8702
2023-01-11 02:34:06,551 - mmseg - INFO - Iter [36350/40000]	lr: 5.476e-06, eta: 1:16:11, time: 1.237, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1245, decode.acc_seg: 89.8217, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1159, mix.decode.acc_seg: 91.5831, masked.decode.loss_seg: 0.1531, masked.decode.acc_seg: 92.0426
2023-01-11 02:35:08,578 - mmseg - INFO - Iter [36400/40000]	lr: 5.402e-06, eta: 1:15:08, time: 1.241, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1002, decode.acc_seg: 88.0144, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1052, mix.decode.acc_seg: 90.5331, masked.decode.loss_seg: 0.1666, masked.decode.acc_seg: 91.4540
2023-01-11 02:36:10,682 - mmseg - INFO - Iter [36450/40000]	lr: 5.327e-06, eta: 1:14:05, time: 1.242, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1062, decode.acc_seg: 87.8490, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1203, mix.decode.acc_seg: 90.3574, masked.decode.loss_seg: 0.1664, masked.decode.acc_seg: 91.0382
2023-01-11 02:37:12,534 - mmseg - INFO - Iter [36500/40000]	lr: 5.251e-06, eta: 1:13:03, time: 1.237, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1041, decode.acc_seg: 90.0555, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1067, mix.decode.acc_seg: 91.6093, masked.decode.loss_seg: 0.1467, masked.decode.acc_seg: 92.2306
2023-01-11 02:38:14,791 - mmseg - INFO - Iter [36550/40000]	lr: 5.176e-06, eta: 1:12:00, time: 1.245, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0900, decode.acc_seg: 87.8176, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1108, mix.decode.acc_seg: 90.8134, masked.decode.loss_seg: 0.1571, masked.decode.acc_seg: 91.8408
2023-01-11 02:39:16,839 - mmseg - INFO - Iter [36600/40000]	lr: 5.102e-06, eta: 1:10:57, time: 1.241, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1026, decode.acc_seg: 87.8190, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1169, mix.decode.acc_seg: 89.3136, masked.decode.loss_seg: 0.1592, masked.decode.acc_seg: 91.9691
2023-01-11 02:40:19,274 - mmseg - INFO - Iter [36650/40000]	lr: 5.027e-06, eta: 1:09:55, time: 1.249, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1040, decode.acc_seg: 88.1510, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1178, mix.decode.acc_seg: 91.0541, masked.decode.loss_seg: 0.1665, masked.decode.acc_seg: 91.3820
2023-01-11 02:41:21,451 - mmseg - INFO - Iter [36700/40000]	lr: 4.951e-06, eta: 1:08:52, time: 1.244, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1126, decode.acc_seg: 88.2714, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1165, mix.decode.acc_seg: 89.7196, masked.decode.loss_seg: 0.1597, masked.decode.acc_seg: 91.4140
2023-01-11 02:42:23,529 - mmseg - INFO - Iter [36750/40000]	lr: 4.876e-06, eta: 1:07:49, time: 1.242, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1101, decode.acc_seg: 86.8358, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1187, mix.decode.acc_seg: 88.1819, masked.decode.loss_seg: 0.1590, masked.decode.acc_seg: 91.8647
2023-01-11 02:43:25,663 - mmseg - INFO - Iter [36800/40000]	lr: 4.802e-06, eta: 1:06:47, time: 1.243, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1142, decode.acc_seg: 89.0175, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1177, mix.decode.acc_seg: 90.8211, masked.decode.loss_seg: 0.1523, masked.decode.acc_seg: 91.9340
2023-01-11 02:44:27,880 - mmseg - INFO - Iter [36850/40000]	lr: 4.727e-06, eta: 1:05:44, time: 1.244, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1041, decode.acc_seg: 89.0374, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1184, mix.decode.acc_seg: 91.5549, masked.decode.loss_seg: 0.1622, masked.decode.acc_seg: 91.6606
2023-01-11 02:45:29,920 - mmseg - INFO - Iter [36900/40000]	lr: 4.651e-06, eta: 1:04:41, time: 1.241, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0988, decode.acc_seg: 87.4153, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1122, mix.decode.acc_seg: 88.5103, masked.decode.loss_seg: 0.1669, masked.decode.acc_seg: 91.3203
2023-01-11 02:46:32,666 - mmseg - INFO - Iter [36950/40000]	lr: 4.576e-06, eta: 1:03:39, time: 1.255, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1066, decode.acc_seg: 88.3042, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1184, mix.decode.acc_seg: 90.8957, masked.decode.loss_seg: 0.1549, masked.decode.acc_seg: 91.9956
2023-01-11 02:47:34,621 - mmseg - INFO - Exp name: 230110_1355_230110_1343_gta2cs_dacs_a999_fdthings_rcs001_cpl_m32-07-spta_daformer_sepaspp_mitb5_poly10warm_s0_2feea_f2bea
2023-01-11 02:47:34,621 - mmseg - INFO - Iter [37000/40000]	lr: 4.502e-06, eta: 1:02:36, time: 1.239, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0910, decode.acc_seg: 88.5700, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1127, mix.decode.acc_seg: 89.6563, masked.decode.loss_seg: 0.1639, masked.decode.acc_seg: 91.4639
2023-01-11 02:48:40,778 - mmseg - INFO - Iter [37050/40000]	lr: 4.427e-06, eta: 1:01:34, time: 1.323, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1072, decode.acc_seg: 88.1695, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1108, mix.decode.acc_seg: 90.4926, masked.decode.loss_seg: 0.1656, masked.decode.acc_seg: 91.6641
2023-01-11 02:49:43,003 - mmseg - INFO - Iter [37100/40000]	lr: 4.351e-06, eta: 1:00:31, time: 1.245, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1074, decode.acc_seg: 87.2287, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1149, mix.decode.acc_seg: 90.4027, masked.decode.loss_seg: 0.1577, masked.decode.acc_seg: 91.9141
2023-01-11 02:50:45,065 - mmseg - INFO - Iter [37150/40000]	lr: 4.276e-06, eta: 0:59:29, time: 1.241, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0939, decode.acc_seg: 88.7008, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1070, mix.decode.acc_seg: 92.0433, masked.decode.loss_seg: 0.1718, masked.decode.acc_seg: 90.9529
2023-01-11 02:51:47,254 - mmseg - INFO - Iter [37200/40000]	lr: 4.202e-06, eta: 0:58:26, time: 1.244, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1018, decode.acc_seg: 87.2276, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1132, mix.decode.acc_seg: 89.7704, masked.decode.loss_seg: 0.1600, masked.decode.acc_seg: 91.8015
2023-01-11 02:52:49,509 - mmseg - INFO - Iter [37250/40000]	lr: 4.127e-06, eta: 0:57:23, time: 1.245, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0931, decode.acc_seg: 88.9538, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1095, mix.decode.acc_seg: 90.2862, masked.decode.loss_seg: 0.1670, masked.decode.acc_seg: 91.4745
2023-01-11 02:53:51,836 - mmseg - INFO - Iter [37300/40000]	lr: 4.051e-06, eta: 0:56:21, time: 1.247, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1097, decode.acc_seg: 90.7915, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1284, mix.decode.acc_seg: 91.6357, masked.decode.loss_seg: 0.1555, masked.decode.acc_seg: 91.7920
2023-01-11 02:54:54,113 - mmseg - INFO - Iter [37350/40000]	lr: 3.976e-06, eta: 0:55:18, time: 1.246, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1021, decode.acc_seg: 89.4911, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1061, mix.decode.acc_seg: 91.9810, masked.decode.loss_seg: 0.1534, masked.decode.acc_seg: 91.8555
2023-01-11 02:55:56,620 - mmseg - INFO - Iter [37400/40000]	lr: 3.901e-06, eta: 0:54:15, time: 1.250, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1061, decode.acc_seg: 89.6586, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1177, mix.decode.acc_seg: 90.4381, masked.decode.loss_seg: 0.1544, masked.decode.acc_seg: 91.9071
2023-01-11 02:56:59,129 - mmseg - INFO - Iter [37450/40000]	lr: 3.827e-06, eta: 0:53:13, time: 1.250, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1022, decode.acc_seg: 89.2708, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1146, mix.decode.acc_seg: 91.2656, masked.decode.loss_seg: 0.1644, masked.decode.acc_seg: 91.5658
2023-01-11 02:58:01,381 - mmseg - INFO - Iter [37500/40000]	lr: 3.752e-06, eta: 0:52:10, time: 1.245, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1037, decode.acc_seg: 89.3896, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1279, mix.decode.acc_seg: 90.1127, masked.decode.loss_seg: 0.1626, masked.decode.acc_seg: 91.4701
2023-01-11 02:59:03,673 - mmseg - INFO - Iter [37550/40000]	lr: 3.676e-06, eta: 0:51:07, time: 1.246, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0963, decode.acc_seg: 90.7843, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1067, mix.decode.acc_seg: 92.6687, masked.decode.loss_seg: 0.1634, masked.decode.acc_seg: 90.8522
2023-01-11 03:00:06,206 - mmseg - INFO - Iter [37600/40000]	lr: 3.601e-06, eta: 0:50:05, time: 1.251, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0948, decode.acc_seg: 89.7606, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1145, mix.decode.acc_seg: 91.5677, masked.decode.loss_seg: 0.1577, masked.decode.acc_seg: 91.6075
2023-01-11 03:01:08,723 - mmseg - INFO - Iter [37650/40000]	lr: 3.527e-06, eta: 0:49:02, time: 1.250, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0870, decode.acc_seg: 87.8874, src.loss_imnet_feat_dist: 0.0993, mix.decode.loss_seg: 0.1100, mix.decode.acc_seg: 90.8501, masked.decode.loss_seg: 0.1454, masked.decode.acc_seg: 91.9600
2023-01-11 03:02:10,764 - mmseg - INFO - Iter [37700/40000]	lr: 3.452e-06, eta: 0:48:00, time: 1.241, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1002, decode.acc_seg: 88.1448, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1263, mix.decode.acc_seg: 89.8713, masked.decode.loss_seg: 0.1606, masked.decode.acc_seg: 91.1939
2023-01-11 03:03:13,265 - mmseg - INFO - Iter [37750/40000]	lr: 3.376e-06, eta: 0:46:57, time: 1.250, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0922, decode.acc_seg: 88.0902, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1041, mix.decode.acc_seg: 89.6259, masked.decode.loss_seg: 0.1535, masked.decode.acc_seg: 91.6125
2023-01-11 03:04:15,695 - mmseg - INFO - Iter [37800/40000]	lr: 3.301e-06, eta: 0:45:54, time: 1.249, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1036, decode.acc_seg: 89.8487, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1213, mix.decode.acc_seg: 90.8197, masked.decode.loss_seg: 0.1642, masked.decode.acc_seg: 90.9404
2023-01-11 03:05:18,154 - mmseg - INFO - Iter [37850/40000]	lr: 3.227e-06, eta: 0:44:52, time: 1.249, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1108, decode.acc_seg: 89.4463, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1189, mix.decode.acc_seg: 90.6668, masked.decode.loss_seg: 0.1593, masked.decode.acc_seg: 91.7046
2023-01-11 03:06:20,217 - mmseg - INFO - Iter [37900/40000]	lr: 3.152e-06, eta: 0:43:49, time: 1.241, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1070, decode.acc_seg: 87.5499, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1167, mix.decode.acc_seg: 89.6399, masked.decode.loss_seg: 0.1544, masked.decode.acc_seg: 91.6033
2023-01-11 03:07:22,289 - mmseg - INFO - Iter [37950/40000]	lr: 3.076e-06, eta: 0:42:46, time: 1.241, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1018, decode.acc_seg: 90.3986, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1146, mix.decode.acc_seg: 91.6311, masked.decode.loss_seg: 0.1497, masked.decode.acc_seg: 91.5870
2023-01-11 03:08:24,232 - mmseg - INFO - Exp name: 230110_1355_230110_1343_gta2cs_dacs_a999_fdthings_rcs001_cpl_m32-07-spta_daformer_sepaspp_mitb5_poly10warm_s0_2feea_f2bea
2023-01-11 03:08:24,232 - mmseg - INFO - Iter [38000/40000]	lr: 3.001e-06, eta: 0:41:44, time: 1.239, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1045, decode.acc_seg: 87.8888, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1156, mix.decode.acc_seg: 90.7558, masked.decode.loss_seg: 0.1607, masked.decode.acc_seg: 91.0851
2023-01-11 03:09:30,196 - mmseg - INFO - Iter [38050/40000]	lr: 2.927e-06, eta: 0:40:41, time: 1.319, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0994, decode.acc_seg: 86.8313, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1144, mix.decode.acc_seg: 89.4594, masked.decode.loss_seg: 0.1607, masked.decode.acc_seg: 91.6602
2023-01-11 03:10:32,257 - mmseg - INFO - Iter [38100/40000]	lr: 2.852e-06, eta: 0:39:39, time: 1.241, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1056, decode.acc_seg: 87.2631, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1243, mix.decode.acc_seg: 89.4095, masked.decode.loss_seg: 0.1641, masked.decode.acc_seg: 91.4807
2023-01-11 03:11:34,311 - mmseg - INFO - Iter [38150/40000]	lr: 2.776e-06, eta: 0:38:36, time: 1.241, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0935, decode.acc_seg: 88.8972, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1125, mix.decode.acc_seg: 89.8010, masked.decode.loss_seg: 0.1559, masked.decode.acc_seg: 91.3729
2023-01-11 03:12:36,597 - mmseg - INFO - Iter [38200/40000]	lr: 2.701e-06, eta: 0:37:33, time: 1.246, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1081, decode.acc_seg: 88.4016, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1204, mix.decode.acc_seg: 91.1653, masked.decode.loss_seg: 0.1594, masked.decode.acc_seg: 91.2316
2023-01-11 03:13:38,527 - mmseg - INFO - Iter [38250/40000]	lr: 2.627e-06, eta: 0:36:31, time: 1.239, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1110, decode.acc_seg: 88.7645, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1231, mix.decode.acc_seg: 90.2803, masked.decode.loss_seg: 0.1578, masked.decode.acc_seg: 90.6735
2023-01-11 03:14:40,558 - mmseg - INFO - Iter [38300/40000]	lr: 2.552e-06, eta: 0:35:28, time: 1.241, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0974, decode.acc_seg: 88.2909, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1156, mix.decode.acc_seg: 90.0082, masked.decode.loss_seg: 0.1538, masked.decode.acc_seg: 91.1611
2023-01-11 03:15:42,839 - mmseg - INFO - Iter [38350/40000]	lr: 2.476e-06, eta: 0:34:26, time: 1.246, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0976, decode.acc_seg: 89.6675, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1219, mix.decode.acc_seg: 91.4844, masked.decode.loss_seg: 0.1697, masked.decode.acc_seg: 91.3334
2023-01-11 03:16:44,674 - mmseg - INFO - Iter [38400/40000]	lr: 2.401e-06, eta: 0:33:23, time: 1.237, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1112, decode.acc_seg: 88.2006, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1179, mix.decode.acc_seg: 91.1445, masked.decode.loss_seg: 0.1650, masked.decode.acc_seg: 90.7411
2023-01-11 03:17:46,817 - mmseg - INFO - Iter [38450/40000]	lr: 2.327e-06, eta: 0:32:20, time: 1.243, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1147, decode.acc_seg: 88.9202, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1170, mix.decode.acc_seg: 90.4790, masked.decode.loss_seg: 0.1589, masked.decode.acc_seg: 90.8732
2023-01-11 03:18:48,815 - mmseg - INFO - Iter [38500/40000]	lr: 2.252e-06, eta: 0:31:18, time: 1.240, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1135, decode.acc_seg: 87.0468, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1104, mix.decode.acc_seg: 88.8423, masked.decode.loss_seg: 0.1677, masked.decode.acc_seg: 90.9493
2023-01-11 03:19:51,370 - mmseg - INFO - Iter [38550/40000]	lr: 2.176e-06, eta: 0:30:15, time: 1.251, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0997, decode.acc_seg: 88.7871, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1160, mix.decode.acc_seg: 90.8374, masked.decode.loss_seg: 0.1490, masked.decode.acc_seg: 91.3305
2023-01-11 03:20:53,363 - mmseg - INFO - Iter [38600/40000]	lr: 2.101e-06, eta: 0:29:12, time: 1.240, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1028, decode.acc_seg: 87.2860, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1123, mix.decode.acc_seg: 89.2665, masked.decode.loss_seg: 0.1537, masked.decode.acc_seg: 91.0540
2023-01-11 03:21:55,615 - mmseg - INFO - Iter [38650/40000]	lr: 2.026e-06, eta: 0:28:10, time: 1.245, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1000, decode.acc_seg: 88.2788, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1059, mix.decode.acc_seg: 90.4717, masked.decode.loss_seg: 0.1551, masked.decode.acc_seg: 91.4677
2023-01-11 03:22:57,926 - mmseg - INFO - Iter [38700/40000]	lr: 1.952e-06, eta: 0:27:07, time: 1.246, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1226, decode.acc_seg: 88.0949, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1081, mix.decode.acc_seg: 90.1210, masked.decode.loss_seg: 0.1586, masked.decode.acc_seg: 91.2670
2023-01-11 03:24:00,110 - mmseg - INFO - Iter [38750/40000]	lr: 1.877e-06, eta: 0:26:05, time: 1.244, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1043, decode.acc_seg: 88.8389, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1265, mix.decode.acc_seg: 90.2561, masked.decode.loss_seg: 0.1600, masked.decode.acc_seg: 90.8354
2023-01-11 03:25:02,442 - mmseg - INFO - Iter [38800/40000]	lr: 1.801e-06, eta: 0:25:02, time: 1.247, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1088, decode.acc_seg: 87.7494, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1144, mix.decode.acc_seg: 90.7688, masked.decode.loss_seg: 0.1447, masked.decode.acc_seg: 91.7535
2023-01-11 03:26:04,786 - mmseg - INFO - Iter [38850/40000]	lr: 1.726e-06, eta: 0:23:59, time: 1.247, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1017, decode.acc_seg: 88.3274, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1111, mix.decode.acc_seg: 90.6291, masked.decode.loss_seg: 0.1726, masked.decode.acc_seg: 90.4797
2023-01-11 03:27:07,106 - mmseg - INFO - Iter [38900/40000]	lr: 1.652e-06, eta: 0:22:57, time: 1.246, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1008, decode.acc_seg: 89.6266, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1164, mix.decode.acc_seg: 90.2165, masked.decode.loss_seg: 0.1581, masked.decode.acc_seg: 91.2619
2023-01-11 03:28:09,557 - mmseg - INFO - Iter [38950/40000]	lr: 1.577e-06, eta: 0:21:54, time: 1.249, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1012, decode.acc_seg: 88.6835, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1067, mix.decode.acc_seg: 90.0715, masked.decode.loss_seg: 0.1670, masked.decode.acc_seg: 90.9169
2023-01-11 03:29:11,739 - mmseg - INFO - Exp name: 230110_1355_230110_1343_gta2cs_dacs_a999_fdthings_rcs001_cpl_m32-07-spta_daformer_sepaspp_mitb5_poly10warm_s0_2feea_f2bea
2023-01-11 03:29:11,739 - mmseg - INFO - Iter [39000/40000]	lr: 1.501e-06, eta: 0:20:52, time: 1.244, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1036, decode.acc_seg: 88.0504, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1049, mix.decode.acc_seg: 89.9798, masked.decode.loss_seg: 0.1609, masked.decode.acc_seg: 90.6640
2023-01-11 03:30:17,852 - mmseg - INFO - Iter [39050/40000]	lr: 1.426e-06, eta: 0:19:49, time: 1.322, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1016, decode.acc_seg: 89.1695, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1135, mix.decode.acc_seg: 90.3826, masked.decode.loss_seg: 0.1589, masked.decode.acc_seg: 91.2020
2023-01-11 03:31:20,125 - mmseg - INFO - Iter [39100/40000]	lr: 1.352e-06, eta: 0:18:46, time: 1.245, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0908, decode.acc_seg: 88.0782, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1082, mix.decode.acc_seg: 90.6682, masked.decode.loss_seg: 0.1674, masked.decode.acc_seg: 90.5131
2023-01-11 03:32:22,470 - mmseg - INFO - Iter [39150/40000]	lr: 1.277e-06, eta: 0:17:44, time: 1.247, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1014, decode.acc_seg: 89.7035, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1038, mix.decode.acc_seg: 92.2699, masked.decode.loss_seg: 0.1533, masked.decode.acc_seg: 91.2398
2023-01-11 03:33:24,939 - mmseg - INFO - Iter [39200/40000]	lr: 1.201e-06, eta: 0:16:41, time: 1.249, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0953, decode.acc_seg: 89.7926, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1261, mix.decode.acc_seg: 89.9624, masked.decode.loss_seg: 0.1640, masked.decode.acc_seg: 90.4036
2023-01-11 03:34:27,115 - mmseg - INFO - Iter [39250/40000]	lr: 1.126e-06, eta: 0:15:39, time: 1.244, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0977, decode.acc_seg: 89.7946, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1130, mix.decode.acc_seg: 91.0728, masked.decode.loss_seg: 0.1578, masked.decode.acc_seg: 90.9436
2023-01-11 03:35:29,179 - mmseg - INFO - Iter [39300/40000]	lr: 1.052e-06, eta: 0:14:36, time: 1.241, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1086, decode.acc_seg: 89.1522, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1178, mix.decode.acc_seg: 91.2425, masked.decode.loss_seg: 0.1667, masked.decode.acc_seg: 90.9440
2023-01-11 03:36:31,416 - mmseg - INFO - Iter [39350/40000]	lr: 9.765e-07, eta: 0:13:33, time: 1.245, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1189, decode.acc_seg: 87.4839, src.loss_imnet_feat_dist: 0.0968, mix.decode.loss_seg: 0.1110, mix.decode.acc_seg: 90.0575, masked.decode.loss_seg: 0.1515, masked.decode.acc_seg: 91.4298
2023-01-11 03:37:33,789 - mmseg - INFO - Iter [39400/40000]	lr: 9.015e-07, eta: 0:12:31, time: 1.247, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1104, decode.acc_seg: 88.7796, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1155, mix.decode.acc_seg: 90.9343, masked.decode.loss_seg: 0.1485, masked.decode.acc_seg: 91.3227
2023-01-11 03:38:36,229 - mmseg - INFO - Iter [39450/40000]	lr: 8.265e-07, eta: 0:11:28, time: 1.249, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1110, decode.acc_seg: 88.9112, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1125, mix.decode.acc_seg: 90.0282, masked.decode.loss_seg: 0.1512, masked.decode.acc_seg: 91.1171
2023-01-11 03:39:38,956 - mmseg - INFO - Iter [39500/40000]	lr: 7.515e-07, eta: 0:10:26, time: 1.255, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0967, decode.acc_seg: 90.0426, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1093, mix.decode.acc_seg: 91.4599, masked.decode.loss_seg: 0.1642, masked.decode.acc_seg: 90.6350
2023-01-11 03:40:41,276 - mmseg - INFO - Iter [39550/40000]	lr: 6.765e-07, eta: 0:09:23, time: 1.246, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1009, decode.acc_seg: 89.2345, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1130, mix.decode.acc_seg: 90.7926, masked.decode.loss_seg: 0.1601, masked.decode.acc_seg: 90.7474
2023-01-11 03:41:43,705 - mmseg - INFO - Iter [39600/40000]	lr: 6.015e-07, eta: 0:08:20, time: 1.249, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1081, decode.acc_seg: 87.2507, src.loss_imnet_feat_dist: 0.0925, mix.decode.loss_seg: 0.1222, mix.decode.acc_seg: 90.1441, masked.decode.loss_seg: 0.1547, masked.decode.acc_seg: 90.8971
2023-01-11 03:42:46,197 - mmseg - INFO - Iter [39650/40000]	lr: 5.265e-07, eta: 0:07:18, time: 1.250, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0963, decode.acc_seg: 88.8205, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1111, mix.decode.acc_seg: 90.1224, masked.decode.loss_seg: 0.1559, masked.decode.acc_seg: 90.9461
2023-01-11 03:43:48,553 - mmseg - INFO - Iter [39700/40000]	lr: 4.515e-07, eta: 0:06:15, time: 1.247, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1059, decode.acc_seg: 87.8774, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1168, mix.decode.acc_seg: 90.4668, masked.decode.loss_seg: 0.1568, masked.decode.acc_seg: 91.0900
2023-01-11 03:44:50,416 - mmseg - INFO - Iter [39750/40000]	lr: 3.765e-07, eta: 0:05:13, time: 1.237, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0940, decode.acc_seg: 88.6403, src.loss_imnet_feat_dist: 0.0957, mix.decode.loss_seg: 0.1066, mix.decode.acc_seg: 89.8300, masked.decode.loss_seg: 0.1594, masked.decode.acc_seg: 91.0073
2023-01-11 03:45:52,301 - mmseg - INFO - Iter [39800/40000]	lr: 3.015e-07, eta: 0:04:10, time: 1.238, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1070, decode.acc_seg: 88.7012, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1149, mix.decode.acc_seg: 89.9465, masked.decode.loss_seg: 0.1586, masked.decode.acc_seg: 90.9054
2023-01-11 03:46:54,376 - mmseg - INFO - Iter [39850/40000]	lr: 2.265e-07, eta: 0:03:07, time: 1.241, data_time: 0.011, memory: 9807, decode.loss_seg: 0.0946, decode.acc_seg: 88.2426, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1046, mix.decode.acc_seg: 90.3555, masked.decode.loss_seg: 0.1571, masked.decode.acc_seg: 90.5603
2023-01-11 03:47:56,533 - mmseg - INFO - Iter [39900/40000]	lr: 1.515e-07, eta: 0:02:05, time: 1.243, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1019, decode.acc_seg: 88.9715, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1172, mix.decode.acc_seg: 90.1102, masked.decode.loss_seg: 0.1643, masked.decode.acc_seg: 90.8247
2023-01-11 03:48:58,815 - mmseg - INFO - Iter [39950/40000]	lr: 7.650e-08, eta: 0:01:02, time: 1.246, data_time: 0.011, memory: 9807, decode.loss_seg: 0.1093, decode.acc_seg: 88.4938, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1196, mix.decode.acc_seg: 90.7613, masked.decode.loss_seg: 0.1649, masked.decode.acc_seg: 90.3756
2023-01-11 03:51:21,159 - mmseg - INFO - per class results:
2023-01-11 03:51:21,223 - mmseg - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      road     | 96.88 | 99.32 |
|    sidewalk   | 76.57 | 82.42 |
|    building   | 89.95 |  95.5 |
|      wall     | 56.56 | 70.34 |
|     fence     | 45.11 | 49.17 |
|      pole     | 50.45 | 57.91 |
| traffic light | 55.59 | 75.33 |
|  traffic sign | 61.09 |  65.3 |
|   vegetation  | 90.35 | 95.96 |
|    terrain    |  50.5 |  59.3 |
|      sky      | 92.34 | 98.95 |
|     person    | 72.27 | 84.49 |
|     rider     | 46.75 | 74.06 |
|      car      | 92.13 | 96.09 |
|     truck     | 73.79 | 90.73 |
|      bus      | 76.89 | 82.75 |
|     train     | 69.52 | 73.16 |
|   motorcycle  | 58.39 | 73.67 |
|    bicycle    | 62.57 | 74.37 |
+---------------+-------+-------+
2023-01-11 03:51:21,223 - mmseg - INFO - Summary:
2023-01-11 03:51:21,224 - mmseg - INFO - 
+-------+-------+-------+
|  aAcc |  mIoU |  mAcc |
+-------+-------+-------+
| 94.35 | 69.35 | 78.89 |
+-------+-------+-------+
2023-01-11 03:51:21,227 - mmseg - INFO - Saving checkpoint at 40000 iterations
2023-01-11 03:51:39,425 - mmseg - INFO - Exp name: 230110_1355_230110_1343_gta2cs_dacs_a999_fdthings_rcs001_cpl_m32-07-spta_daformer_sepaspp_mitb5_poly10warm_s0_2feea_f2bea
2023-01-11 03:51:39,713 - mmseg - INFO - Iter [500/40000]	lr: 1.500e-09, eta: 0:00:00, time: 1.249, data_time: 0.011, memory: 9807, aAcc: 0.9435, mIoU: 0.6935, mAcc: 0.7889, IoU.road: 0.9688, IoU.sidewalk: 0.7657, IoU.building: 0.8995, IoU.wall: 0.5656, IoU.fence: 0.4511, IoU.pole: 0.5045, IoU.traffic light: 0.5559, IoU.traffic sign: 0.6109, IoU.vegetation: 0.9035, IoU.terrain: 0.5050, IoU.sky: 0.9234, IoU.person: 0.7227, IoU.rider: 0.4675, IoU.car: 0.9213, IoU.truck: 0.7379, IoU.bus: 0.7689, IoU.train: 0.6952, IoU.motorcycle: 0.5839, IoU.bicycle: 0.6257, Acc.road: 0.9932, Acc.sidewalk: 0.8242, Acc.building: 0.9550, Acc.wall: 0.7034, Acc.fence: 0.4917, Acc.pole: 0.5791, Acc.traffic light: 0.7533, Acc.traffic sign: 0.6530, Acc.vegetation: 0.9596, Acc.terrain: 0.5930, Acc.sky: 0.9895, Acc.person: 0.8449, Acc.rider: 0.7406, Acc.car: 0.9609, Acc.truck: 0.9073, Acc.bus: 0.8275, Acc.train: 0.7316, Acc.motorcycle: 0.7367, Acc.bicycle: 0.7437, decode.loss_seg: 0.1101, decode.acc_seg: 88.3530, src.loss_imnet_feat_dist: nan, mix.decode.loss_seg: 0.1297, mix.decode.acc_seg: 90.2608, masked.decode.loss_seg: 0.1666, masked.decode.acc_seg: 90.7040
